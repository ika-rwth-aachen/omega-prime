{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Omega-Prime: Data Model, Data Format and Python Library for Handling Ground Truth Road Traffic Data","text":"<p>Data Model, Format and Python Library for ground truth road traffic data containing information on dynamic objects, map and environmental factors optimized for representing urban traffic. The repository contains:</p>"},{"location":"#data-model-and-specification","title":"Data Model and Specification","text":"<p>see Data Model &amp; Specification</p> <ul> <li>\ud83c\udf0d Data Model: What signals exist and how these are defined.</li> <li>\ud83e\uddfe Data Format Specification: How to exchange and store those signals.</li> </ul>"},{"location":"#python-library","title":"Python Library","text":"<ul> <li>\ud83d\udd28 Create omega-prime files from many sources (see Tutorials/Introduction):<ul> <li>ASAM OSI GroundTruth trace (e.g., output of esmini),  Table of moving object data (e.g., csv data), ASAM OpenDRIVE map</li> <li>LevelXData datasets through lxd-io</li> <li>Extend yourself by subclassing DatasetConverter</li> <li>Use omega-prime-trajdata to convert motion prediction datasets into omega-prime </li> </ul> </li> <li>\ud83d\uddfa\ufe0f Map Association: Associate Object Location with Lanes from OpenDRIVE or OSI Maps (see Tutorials/Locator)</li> <li>\ud83d\udcfa Plotting of data: interactive top view plots using altair</li> <li>\u2705 Validation of data: check if your data conforms to the omega-prime specification (e.g., correct yaw) using pandera</li> <li>\ud83d\udcd0 Interpolation of data: bring your data into a fixed frequency</li> <li>\ud83d\udcc8 Metrics: compute interaction metrics like PET, TTC, THW (see Tutorials/Metrics)<ul> <li>Predicted and observed timegaps based on driving tubes (see ./omega_prime/metrics.py)</li> <li>2D-birds-eye-view visibility with omega-prime-visibility</li> </ul> </li> <li>\ud83d\ude80 Fast Processing directly on DataFrames using polars, polars-st</li> <li>\u2328\ufe0f CLI to convert, validate and visualize omega-prime files</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p><code>pip install omega-prime</code></p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>This package is developed as part of the SYNERGIES project.</p> <p></p> <p>Funded by the European Union. Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or European Climate, Infrastructure and Environment Executive Agency (CINEA). Neither the European Union nor the granting authority can be held responsible for them. </p> <p></p>"},{"location":"#notice","title":"Notice","text":"<p>The project is open-sourced and maintained by the Institute for Automotive Engineering (ika) at RWTH Aachen University. We cover a wide variety of research topics within our Vehicle Intelligence &amp; Automated Driving domain. If you would like to learn more about how we can support your automated driving or robotics efforts, feel free to reach out to us! opensource@ika.rwth-aachen.de</p>"},{"location":"api/","title":"API","text":""},{"location":"api/#omega_prime.recording.Recording","title":"<code>Recording</code>","text":"<p>Class representing a continuous traffic observation. Usually corresponds to one omega-prime file.</p> <p>Internally, the Recording uses a Polars DataFrame to store moving object data. Each row in the DataFrame represents the state of a moving object at a specific timestamp.</p> <p>Attributes:</p> Name Type Description <code>df</code> <code>DataFrame</code> <p>Polars DataFrame containing the moving object data.</p> <code>map</code> <code>MapOsi | MapOsiCenterline | MapOdr | None</code> <p>Map associated with the recording.</p> <code>projections</code> <code>dict</code> <p>Projection metadata with structure <code>{\"proj_string\": str | None, None: ProjectionOffset | None, int: ProjectionOffset | None}</code>.</p> <code>traffic_light_states</code> <code>dict</code> <p>Dictionary mapping timestamps to traffic light states.</p> <code>host_vehicle_idx</code> <code>int | None</code> <p>Index of the host vehicle, if applicable.</p> Source code in <code>omega_prime/recording.py</code> <pre><code>class Recording:\n    \"\"\"Class representing a continuous traffic observation. Usually corresponds to one omega-prime file.\n\n    Internally, the Recording uses a Polars DataFrame to store moving object data. Each row in the DataFrame\n    represents the state of a moving object at a specific timestamp.\n\n    Attributes:\n        df (pl.DataFrame): Polars DataFrame containing the moving object data.\n        map (MapOsi | MapOsiCenterline | MapOdr | None): Map associated with the recording.\n        projections (dict): Projection metadata with structure\n            `{\"proj_string\": str | None, None: ProjectionOffset | None, int: ProjectionOffset | None}`.\n        traffic_light_states (dict): Dictionary mapping timestamps to traffic light states.\n        host_vehicle_idx (int | None): Index of the host vehicle, if applicable.\n    \"\"\"\n\n    _MovingObjectClass: typing.ClassVar = MovingObject\n\n    @staticmethod\n    def _offset_components(\n        offset: ProjectionOffset | None,\n    ) -&gt; tuple[float, float, float, float]:\n        \"Extract components from a ProjectionOffset, returning zeros if the offset is None.\"\n        if offset is None:\n            return 0.0, 0.0, 0.0, 0.0\n        return offset.x, offset.y, offset.z, offset.yaw\n\n    @staticmethod\n    def _encode_projections(\n        projections: dict[typing.Any, typing.Any],\n    ) -&gt; bytes:\n        \"Encode projection metadata into a JSON string and then to bytes\"\n        if not projections:\n            return b\"\"\n\n        def _serialize_offset(offset: ProjectionOffset | None):\n            if offset is None:\n                return None\n            return {\"x\": offset.x, \"y\": offset.y, \"z\": offset.z, \"yaw\": offset.yaw}\n\n        payload = {\n            \"proj_string\": projections.get(\"proj_string\"),\n            \"offsets\": [\n                {\n                    \"total_nanos\": ts,\n                    \"offset\": _serialize_offset(offset),\n                }\n                for ts, offset in projections.items()\n                if ts != \"proj_string\"\n            ],\n        }\n        return json.dumps(payload).encode()\n\n    @staticmethod\n    def _decode_projections(\n        raw: bytes | str | None,\n    ) -&gt; dict[typing.Any, typing.Any]:\n        \"Decode projection metadata from bytes or string to a dictionary.\"\n        if raw in (None, b\"\", \"\"):\n            return {}\n        if isinstance(raw, bytes):\n            raw = raw.decode()\n        payload = json.loads(raw)\n        result: dict[typing.Any, typing.Any] = {\"proj_string\": payload.get(\"proj_string\")}\n        for entry in payload.get(\"offsets\", []):\n            offset_data = entry.get(\"offset\")\n            offset = ProjectionOffset(**offset_data) if offset_data is not None else None\n            ts = entry.get(\"total_nanos\")\n            key = None if ts is None else int(ts)\n            result[key] = offset\n        return result\n\n    @staticmethod\n    def _validate_projections_schema(\n        projections: dict[typing.Any, typing.Any] | None,\n    ) -&gt; dict[typing.Any, typing.Any]:\n        \"\"\"\n        Validate the schema of the projections dictionary, ensuring correct types and structure.\n        Projection metadata with structure:\n            `{\"proj_string\": str | None, None: ProjectionOffset | None, int: ProjectionOffset | None}`\n        \"\"\"\n        if projections is None:\n            return {}\n        if not isinstance(projections, dict):\n            raise TypeError(\"`projections` must be a dictionary.\")\n\n        validated: dict[typing.Any, typing.Any] = {}\n        if \"proj_string\" in projections:\n            validated[\"proj_string\"] = projections[\"proj_string\"]\n\n        for key, value in projections.items():\n            if key == \"proj_string\":\n                continue\n\n            if key is not None and not isinstance(key, int):\n                raise TypeError(\"Projection keys must be integers, `None`, or `proj_string`.\")\n\n            if value is not None and not isinstance(value, ProjectionOffset):\n                raise TypeError(\"Projection values must be `ProjectionOffset` or `None`.\")\n\n            validated[key] = value\n\n        return validated\n\n    def _projection_for_timestamp(self, total_nanos: int) -&gt; tuple[str | None, ProjectionOffset | None]:\n        source_proj_string = self.projections.get(\"proj_string\")\n        if source_proj_string is None:\n            source_proj_string = getattr(self.map, \"proj_string\", None)\n\n        if total_nanos in self.projections:\n            offset = self.projections[total_nanos]\n        elif None in self.projections:\n            offset = self.projections[None]\n        else:\n            offset = None\n\n        return source_proj_string, offset\n\n    @staticmethod\n    def get_moving_object_ground_truth(\n        nanos: int,\n        df: pl.DataFrame,\n        host_vehicle_idx: int | None = None,\n        validate: bool = False,\n    ) -&gt; betterosi.GroundTruth:\n        if validate:\n            recording_moving_object_schema.validate(df, lazy=True)\n\n        def get_object(row):\n            return betterosi.MovingObject(\n                id=betterosi.Identifier(value=row[\"idx\"]),\n                type=betterosi.MovingObjectType(row[\"type\"]),\n                base=betterosi.BaseMoving(\n                    dimension=betterosi.Dimension3D(length=row[\"length\"], width=row[\"width\"], height=row[\"width\"]),\n                    position=betterosi.Vector3D(x=row[\"x\"], y=row[\"y\"], z=row[\"z\"]),\n                    orientation=betterosi.Orientation3D(roll=row[\"roll\"], pitch=row[\"pitch\"], yaw=row[\"yaw\"]),\n                    velocity=betterosi.Vector3D(x=row[\"vel_x\"], y=row[\"vel_y\"], z=row[\"vel_z\"]),\n                    acceleration=betterosi.Vector3D(x=row[\"acc_x\"], y=row[\"acc_y\"], z=row[\"acc_z\"]),\n                ),\n                vehicle_classification=betterosi.MovingObjectVehicleClassification(\n                    type=row[\"subtype\"], role=row[\"role\"]\n                ),\n            )\n\n        mvs = [get_object(r) for r in df.iter_rows(named=True)]\n        gt = betterosi.GroundTruth(\n            version=betterosi.InterfaceVersion(version_major=3, version_minor=7, version_patch=9),\n            timestamp=betterosi.Timestamp(seconds=int(nanos // int(1e9)), nanos=int(nanos % int(1e9))),\n            host_vehicle_id=(\n                betterosi.Identifier(value=0)\n                if host_vehicle_idx is None\n                else betterosi.Identifier(value=host_vehicle_idx)\n            ),\n            moving_object=mvs,\n        )\n        return gt\n\n    @staticmethod\n    def _ensure_polars_dataframe(df: typing.Any) -&gt; pl.DataFrame:\n        \"Ensure that the input data is a Polars DataFrame with the correct schema, converting if necessary.\"\n        if isinstance(df, pl.DataFrame):\n            return df\n        return pl.DataFrame(df, schema_overrides=polars_schema)\n\n    @staticmethod\n    def _build_frame_mapping(df: pl.DataFrame) -&gt; tuple[dict[int, int], pl.DataFrame]:\n        \"Build a mapping from `total_nanos` to frame numbers and return both the mapping and a DataFrame for joining.\"\n        nanos2frame = {n: i for i, n in enumerate(df[\"total_nanos\"].unique())}\n        mapping = pl.DataFrame(\n            {\n                \"total_nanos\": list(nanos2frame.keys()),\n                \"frame\": list(nanos2frame.values()),\n            },\n            schema=dict(total_nanos=polars_schema[\"total_nanos\"], frame=pl.UInt32),\n        )\n        return nanos2frame, mapping\n\n    @staticmethod\n    def _attach_frame_column(df: pl.DataFrame, mapping: pl.DataFrame) -&gt; pl.DataFrame:\n        if \"frame\" in df.columns:\n            df = df.drop(\"frame\")\n        return df.join(mapping, on=\"total_nanos\", how=\"left\")\n\n    @staticmethod\n    def _ensure_motion_norm_columns(df: pl.DataFrame) -&gt; pl.DataFrame:\n        exprs = []\n        if \"vel\" not in df.columns:\n            exprs.append((pl.col(\"vel_x\") ** 2 + pl.col(\"vel_y\") ** 2).sqrt().alias(\"vel\"))\n        if \"acc\" not in df.columns:\n            exprs.append((pl.col(\"acc_x\") ** 2 + pl.col(\"acc_y\") ** 2).sqrt().alias(\"acc\"))\n        if exprs:\n            df = df.with_columns(*exprs)\n        return df\n\n    def __init__(\n        self,\n        df,\n        map=None,\n        projections=None,\n        host_vehicle_idx: int | None = None,\n        validate=False,\n        traffic_light_states: dict | None = None,\n    ):\n        \"Initialize a Recording instance.\"\n        df = self._ensure_polars_dataframe(df)\n        if \"total_nanos\" not in df.columns:\n            raise ValueError(\"df must contain column `total_nanos`.\")\n        nanos2frame, mapping = self._build_frame_mapping(df)\n        df = self._attach_frame_column(df, mapping)\n        df = self._ensure_polars_dataframe(df)\n        if validate:\n            recording_moving_object_schema.validate(df, lazy=True)\n\n        super().__init__()\n        self.nanos2frame = nanos2frame\n\n        df = self._ensure_motion_norm_columns(df)\n        self.projections = self._validate_projections_schema(projections)\n        self.traffic_light_states = traffic_light_states if traffic_light_states is not None else {}\n\n        df = bbx_to_polygon(df)\n\n        self._df = df\n        self.map = map\n        self._moving_objects = None\n        self.host_vehicle_idx = host_vehicle_idx\n        self.mapsegment = None\n\n    @property\n    def df(self):\n        return self._df\n\n    @property\n    def host_vehicle(self):\n        return self.moving_objects.get(self.host_vehicle_idx, None)\n\n    @property\n    def moving_objects(self):\n        if self._moving_objects is None:\n            self._mv_df = (\n                self._df.group_by(\"idx\")\n                .agg(\n                    pl.col(\"length\", \"width\", \"height\").mean(),\n                    pl.col(\"type\", \"subtype\", \"role\").median(),\n                    pl.col(\"frame\").min().alias(\"birth\"),\n                    pl.col(\"frame\").max().alias(\"end\"),\n                    pl.col(\"total_nanos\").min().alias(\"t_birth\"),\n                    pl.col(\"total_nanos\").max().alias(\"t_end\"),\n                )\n                .with_columns(\n                    pl.col(\"type\").map_elements(lambda x: betterosi.MovingObjectType(x), return_dtype=object),\n                    pl.col(\"subtype\").map_elements(\n                        lambda x: (betterosi.MovingObjectVehicleClassificationType(x) if x != -1 else None),\n                        return_dtype=object,\n                    ),\n                    pl.col(\"role\").map_elements(\n                        lambda x: (betterosi.MovingObjectVehicleClassificationRole(x).name if x != -1 else None),\n                        return_dtype=object,\n                    ),\n                )\n            )\n            self._moving_objects = {int(idx): self._MovingObjectClass(self, idx) for idx in self._df[\"idx\"].unique()}\n\n        return self._moving_objects\n\n    def _df_with_original_pose_for_export(self, df: pl.DataFrame | None = None) -&gt; pl.DataFrame:\n        \"\"\"\n        Return a DataFrame with original pose columns (`x_original`, `y_original`, `z_original`, `yaw_original`)\n        for export, if they exist. This is used to ensure that the original pose information is preserved when\n        exporting to formats like Parquet or MCAP,\n        even if the main `x`, `y`, `z`, and `yaw` columns have been modified by projections.\n        \"\"\"\n        df_export = self._df if df is None else df\n        original_to_base = {\n            \"x_original\": \"x\",\n            \"y_original\": \"y\",\n            \"z_original\": \"z\",\n            \"yaw_original\": \"yaw\",\n        }\n        overwrite_exprs = [\n            pl.col(original_col).alias(base_col)\n            for original_col, base_col in original_to_base.items()\n            if original_col in df_export.columns\n        ]\n        if overwrite_exprs:\n            df_export = df_export.with_columns(*overwrite_exprs)\n        return df_export\n\n    def to_osi_gts(self) -&gt; list[betterosi.GroundTruth]:\n        first_iteration = True\n        df_export = self._df_with_original_pose_for_export()\n        for [nanos], group_df in df_export.sort([\"total_nanos\"]).group_by(\"total_nanos\", maintain_order=True):\n            gt = self.get_moving_object_ground_truth(\n                nanos, group_df, host_vehicle_idx=self.host_vehicle_idx, validate=False\n            )\n            source_proj_string, proj_offset = self._projection_for_timestamp(int(nanos))\n            if source_proj_string is not None:\n                gt.proj_string = source_proj_string\n            if proj_offset is not None:\n                gt.proj_frame_offset = betterosi.GroundTruthProjFrameOffset(\n                    position=betterosi.Vector3D(x=proj_offset.x, y=proj_offset.y, z=proj_offset.z),\n                    yaw=proj_offset.yaw,\n                )\n            if first_iteration:\n                first_iteration = False\n                if self.map is not None and isinstance(self.map, MapOsi | MapOsiCenterline):\n                    gt.lane_boundary = [b._osi for b in self.map.lane_boundaries.values()]\n                    gt.lane = [l._osi for l in self.map.lanes.values()]\n            if nanos in self.traffic_light_states:\n                gt.traffic_light = self.traffic_light_states[nanos]\n            yield gt\n\n    @classmethod\n    def from_osi_gts(cls, gts: list[betterosi.GroundTruth], **kwargs):\n        projs: dict[typing.Any, typing.Any] = {\"proj_string\": None}\n        traffic_light_states = {}\n\n        gts, tmp_gts = itertools.tee(gts, 2)\n        first_gt = next(tmp_gts)\n        if first_gt.host_vehicle_id is not None:\n            host_vehicle_idx = first_gt.host_vehicle_id.value\n        else:\n            host_vehicle_idx = None\n\n        def get_gts():\n            for i, gt in enumerate(gts):\n                total_nanos = gt.timestamp.seconds * 1_000_000_000 + gt.timestamp.nanos\n                if gt.proj_frame_offset is not None and gt.proj_frame_offset.position is None:\n                    raise ValueError(\n                        f\"Offset of {i}th ground truth message (total_nanos={total_nanos}) is set without position.\"\n                    )\n\n                projs[total_nanos] = (\n                    ProjectionOffset(\n                        x=gt.proj_frame_offset.position.x,\n                        y=gt.proj_frame_offset.position.y,\n                        z=gt.proj_frame_offset.position.z,\n                        yaw=gt.proj_frame_offset.yaw,\n                    )\n                    if gt.proj_frame_offset is not None\n                    else None\n                )\n\n                if gt.proj_string is not None:\n                    normalized_proj_string = gt.proj_string.strip()\n                    if normalized_proj_string:\n                        if projs[\"proj_string\"] is None:\n                            projs[\"proj_string\"] = normalized_proj_string\n                        elif projs[\"proj_string\"] != normalized_proj_string:\n                            raise ValueError(\n                                f\"Conflicting projection strings: {projs['proj_string']} vs {normalized_proj_string} at gt index {i} (total_nanos={total_nanos}).\"\n                            )\n\n                traffic_light_states[total_nanos] = gt.traffic_light\n\n                for mv in gt.moving_object:\n                    yield dict(\n                        total_nanos=total_nanos,\n                        idx=mv.id.value,\n                        x=mv.base.position.x,\n                        y=mv.base.position.y,\n                        z=mv.base.position.z,\n                        vel_x=mv.base.velocity.x,\n                        vel_y=mv.base.velocity.y,\n                        vel_z=mv.base.velocity.z,\n                        acc_x=mv.base.acceleration.x,\n                        acc_y=mv.base.acceleration.y,\n                        acc_z=mv.base.acceleration.z,\n                        length=mv.base.dimension.length,\n                        width=mv.base.dimension.width,\n                        height=mv.base.dimension.height,\n                        roll=mv.base.orientation.roll,\n                        pitch=mv.base.orientation.pitch,\n                        yaw=mv.base.orientation.yaw,\n                        type=mv.type,\n                        role=(\n                            mv.vehicle_classification.role if mv.type == betterosi.MovingObjectType.TYPE_VEHICLE else -1\n                        ),\n                        subtype=(\n                            mv.vehicle_classification.type if mv.type == betterosi.MovingObjectType.TYPE_VEHICLE else -1\n                        ),\n                    )\n\n        df_mv = pl.DataFrame(get_gts(), schema=polars_schema).sort([\"total_nanos\", \"idx\"])\n        return cls(\n            df_mv,\n            projections=projs,\n            host_vehicle_idx=host_vehicle_idx,\n            traffic_light_states=traffic_light_states,\n            **kwargs,\n        )\n\n    def to_mcap(self, filepath):\n        \"Store Recording as an MCAP file.\"\n        if Path(filepath).suffix != \".mcap\":\n            raise ValueError()\n        with betterosi.Writer(filepath) as w:\n            for gt in self.to_osi_gts():\n                w.add(gt)\n            if isinstance(self.map, MapOdr):\n                w.add(self.map.to_osi(), topic=\"ground_truth_map\", log_time=0)\n            elif (\n                self.map is not None and not isinstance(self.map, MapOsi) and not isinstance(self.map, MapOsiCenterline)\n            ):\n                warn(f\"The map {self.map} could not be saved to `mcap`\")\n\n    @classmethod\n    def from_parquet(cls, filename, parse_map: bool = False, step_size: float = 0.01, **kwargs):\n        t = pq.read_table(filename)\n        df = pl.DataFrame(t, schema_overrides=polars_schema)\n        host_vehicle_idx = None\n        projections: dict[typing.Any, typing.Any] = {}\n        map = None\n        metadata = t.schema.metadata or {}\n        if metadata:\n            if b\"host_vehicle_idx\" in metadata:\n                host_vehicle_idx = int(metadata[b\"host_vehicle_idx\"].decode())\n\n            projections = cls._decode_projections(metadata.get(b\"projections_json\"))\n\n            map_parsing = {}\n            for MC in MAP_CLASSES:\n                if MC._binary_json_identifier in metadata:\n                    try:\n                        map = MC._from_binary_json(\n                            metadata,\n                            parse_map=parse_map,\n                            step_size=step_size,\n                        )\n                    except Exception as e:\n                        map_parsing[MC.__name__] = str(e)\n                    else:\n                        if map is not None:\n                            break\n\n        return cls(\n            df,\n            map=map,\n            host_vehicle_idx=host_vehicle_idx,\n            projections=projections,\n            **kwargs,\n        )\n\n    def to_parquet(self, filename):\n        \"Store Recording as a Parquet file.\"\n        metadata = {}\n        if self.host_vehicle_idx is not None:\n            metadata[b\"host_vehicle_idx\"] = str(self.host_vehicle_idx).encode()\n        proj_meta = {}\n        encoded_projections = self._encode_projections(self.projections)\n        if encoded_projections:\n            proj_meta[b\"projections_json\"] = encoded_projections\n        df_export = self._df_with_original_pose_for_export()\n        to_drop = [\"frame\"]\n        optional_cols = [\n            \"polygon\",\n            \"global_lat\",\n            \"global_lon\",\n            \"global_alt\",\n            \"global_yaw\",\n            \"proj_string\",\n            \"x_original\",\n            \"y_original\",\n            \"z_original\",\n            \"yaw_original\",\n        ]\n        to_drop.extend([c for c in optional_cols if c in df_export.columns])\n        t = pyarrow.table(df_export.drop(*to_drop))\n        map_meta = self.map._to_binary_json() if self.map is not None else {}\n\n        t = t.cast(t.schema.with_metadata(metadata | proj_meta | map_meta))\n        pq.write_table(t, filename)\n\n    @classmethod\n    def from_file(\n        cls,\n        filepath,\n        map_path: str | None = None,\n        validate: bool = False,\n        parse_map: bool = False,\n        step_size: float = 0.01,\n        apply_proj: bool = True,\n        **kwargs,\n    ) -&gt; \"Recording\":\n        \"\"\"Load a Recording from a file. Supports `.parquet`, `.osi` and `.mcap` files.\n\n        Parameters:\n            filepath (str): Path to the input file.\n            map_path (str | None): Optional path to a map file. If None, the map will be loaded from the recording if available.\n            validate (bool): Whether to validate the data against the schema.\n            parse_map (bool): Whether to create python objects from the map data or just load it.\n            step_size (float): Step size for map parsing, if applicable (Used for ASAM OpenDRIVE).\n            apply_proj (bool): Whether to apply projection transformations to the recording's moving object data.\n\n        Returns:\n            Recording (Recording): The loaded Recording object.\n        \"\"\"\n        if filepath is None and map_path is None:\n            raise ValueError(\"Either `filepath` or `map_path` must be provided.\")\n\n        if filepath is not None and Path(filepath).suffix == \".parquet\":\n            r = cls.from_parquet(filepath, parse_map=parse_map, validate=validate, step_size=step_size)\n        elif filepath is not None:\n            gts = betterosi.read(filepath, return_ground_truth=True, mcap_return_betterosi=True)\n            r = cls.from_osi_gts(gts, validate=validate)\n        if map_path is None and r.map is not None:\n            return r\n\n        map_path = Path(map_path if map_path is not None else filepath)\n        map_parsing = {}\n        map = None\n        for MC in MAP_CLASSES:\n            if map_path.suffix in MC._supported_file_suffixes:\n                try:\n                    map = MC.from_file(map_path, parse_map=parse_map, **kwargs)\n                except Exception as e:\n                    map_parsing[MC.__name__] = str(e)\n                else:\n                    break\n        if map is not None:\n            r.map = map\n        elif r.map is None:\n            warn(f\"No map could be found: {map_parsing}\")\n\n        if r.projections and apply_proj:\n            try:\n                r.apply_projections()\n            except Exception:\n                warn(\"Failed to apply projections.\")\n        return r\n\n    def to_file(self, filepath):\n        \"Store Recording to a file based on its suffix (`.parquet`, `.mcap`).\"\n        suffix = Path(filepath).suffix.lower()\n        if suffix == \".parquet\":\n            self.to_parquet(filepath)\n            return\n        if suffix == \".mcap\":\n            self.to_mcap(filepath)\n            return\n        raise ValueError(f\"Unsupported file suffix `{suffix}`. Expected one of: `.parquet`, `.mcap`.\")\n\n    def apply_projections(self):\n        \"\"\"\n        Apply projection transformations to the recording's moving object data based on the provided projection metadata\n        and the map's projection. This method updates the `x`, `y`, and `z` columns of the recording's DataFrame\n        according to the specified projections and transforms the coordinates to the target CRS if necessary.\n        The original coordinates before applying projections are stored in `x_original`, `y_original`, and `z_original`\n        columns to preserve the original pose information for export or reference.\n        \"\"\"\n        if self._df.height == 0:\n            return self\n\n        source_proj_string = self.projections.get(\"proj_string\")\n        if source_proj_string is None:\n            self.map.parse()\n            source_proj_string = getattr(self.map, \"proj_string\", None)\n\n        if source_proj_string is None:\n            raise ValueError(\"No proj_string information available on the recording or attached map.\")\n\n        frame_projections: list[dict[str, typing.Any]] = []\n        for ts, offset in self.projections.items():\n            if ts in (None, \"proj_string\"):\n                continue\n            ox, oy, oz, oyaw = self._offset_components(offset)\n            frame_projections.append(\n                dict(\n                    total_nanos=int(ts),\n                    offset_x=ox,\n                    offset_y=oy,\n                    offset_z=oz,\n                    offset_yaw=oyaw,\n                )\n            )\n\n        df = self._df\n\n        default_offset = self.projections.get(None)\n        dox, doy, doz, doyaw = self._offset_components(default_offset)\n\n        if frame_projections:\n            proj_df = pl.DataFrame(\n                frame_projections,\n                schema={\n                    \"total_nanos\": polars_schema[\"total_nanos\"],\n                    \"offset_x\": pl.Float64,\n                    \"offset_y\": pl.Float64,\n                    \"offset_z\": pl.Float64,\n                    \"offset_yaw\": pl.Float64,\n                },\n            )\n            df = df.join(proj_df, on=\"total_nanos\", how=\"left\")\n            df = df.with_columns(\n                pl.lit(source_proj_string).alias(\"proj_string\"),\n                pl.col(\"offset_x\").fill_null(dox).alias(\"offset_x\"),\n                pl.col(\"offset_y\").fill_null(doy).alias(\"offset_y\"),\n                pl.col(\"offset_z\").fill_null(doz).alias(\"offset_z\"),\n                pl.col(\"offset_yaw\").fill_null(doyaw).alias(\"offset_yaw\"),\n            )\n\n        else:\n            df = df.with_columns(\n                pl.lit(source_proj_string).alias(\"proj_string\"),\n                pl.lit(dox).alias(\"offset_x\"),\n                pl.lit(doy).alias(\"offset_y\"),\n                pl.lit(doz).alias(\"offset_z\"),\n                pl.lit(doyaw).alias(\"offset_yaw\"),\n            )\n        source_crs = pyproj.CRS.from_string(source_proj_string)\n\n        if df.select(pl.col(\"proj_string\").is_null().any()).item():\n            raise ValueError(\"Some rows do not have a projection string assigned.\")\n\n        # Store original values before applying offsets, when it is the first projection\n        if not any(col in df.columns for col in [\"x_original\", \"y_original\", \"z_original\"]):\n            df = df.with_columns(\n                pl.col(\"x\").alias(\"x_original\"),\n                pl.col(\"y\").alias(\"y_original\"),\n                pl.col(\"z\").alias(\"z_original\"),\n            )\n\n        # Update main columns with offset values\n        df = df.with_columns(\n            (\n                pl.col(\"x\") * pl.col(\"offset_yaw\").cos() - pl.col(\"y\") * pl.col(\"offset_yaw\").sin() + pl.col(\"offset_x\")\n            ).alias(\"x\"),\n            (\n                pl.col(\"x\") * pl.col(\"offset_yaw\").sin() + pl.col(\"y\") * pl.col(\"offset_yaw\").cos() + pl.col(\"offset_y\")\n            ).alias(\"y\"),\n            (pl.col(\"z\") + pl.col(\"offset_z\")).alias(\"z\"),\n        )\n\n        self.map.parse()\n        target_crs = self.map.projection\n        if not target_crs:\n            raise ValueError(\"Map does not have a valid projection defined.\")\n\n        # Apply 2D proj string transformation\n        transformer = pyproj.Transformer.from_crs(source_crs, target_crs)\n        x_tgt, y_tgt = transformer.transform(df[\"x\"].to_numpy(), df[\"y\"].to_numpy())\n        df = df.with_columns(pl.Series(name=\"x\", values=x_tgt), pl.Series(name=\"y\", values=y_tgt))\n\n        # From map world to map local\n        if self.map.proj_offset:\n            m_ox, m_oy, m_oz, m_oyaw = self._offset_components(self.map.proj_offset)\n            df = df.with_columns(\n                ((pl.col(\"x\") - m_ox) * np.cos(m_oyaw) + (pl.col(\"y\") - m_oy) * np.sin(m_oyaw)).alias(\"x\"),\n                ((pl.col(\"y\") - m_oy) * np.cos(m_oyaw) - (pl.col(\"x\") - m_ox) * np.sin(m_oyaw)).alias(\"y\"),\n                (pl.col(\"z\") - m_oz).alias(\"z\"),\n            )\n\n        df = bbx_to_polygon(df)\n\n        # Remove temporary projection columns\n        df = df.drop(\"proj_string\", \"offset_x\", \"offset_y\", \"offset_z\", \"offset_yaw\")\n\n        self._df = df\n        return self\n\n    def interpolate(self, new_nanos: list[int] | None = None, hz: float | None = None):\n        \"Interpolate the recording to new timestamps or a given frequency.\"\n        df = self._df\n        nanos_min, nanos_max, frame_min, frame_max = df.select(\n            nanos_min=pl.col(\"total_nanos\").min(),\n            nanos_max=pl.col(\"total_nanos\").max(),\n            frame_min=pl.col(\"frame\").min(),\n            frame_max=pl.col(\"frame\").max(),\n        ).row(0)\n        if new_nanos is None:\n            if hz is None:\n                new_nanos = np.linspace(nanos_min, nanos_max, frame_max - frame_min, dtype=int)\n            else:\n                step = 1e9 / hz\n                new_nanos = np.arange(start=nanos_min, stop=nanos_max + 1, step=step, dtype=int)\n        else:\n            new_nanos = np.array(new_nanos)\n        new_dfs = []\n        for [idx], track_df in df.group_by(\"idx\"):\n            track_data = {}\n            track_new_nanos = new_nanos[\n                np.logical_and(\n                    track_df[\"total_nanos\"].min() &lt;= new_nanos,\n                    track_df[\"total_nanos\"].max() &gt;= new_nanos,\n                )\n            ]\n            for c in [\n                \"x\",\n                \"y\",\n                \"z\",\n                \"vel_x\",\n                \"vel_y\",\n                \"vel_z\",\n                \"acc_x\",\n                \"acc_y\",\n                \"acc_z\",\n                \"length\",\n                \"width\",\n                \"height\",\n            ]:\n                track_data[c] = np.interp(track_new_nanos, track_df[\"total_nanos\"], track_df[c])\n            for c in [\"type\", \"subtype\", \"role\"]:\n                track_data[c] = nearest_interp(\n                    track_new_nanos,\n                    track_df[\"total_nanos\"].to_numpy(),\n                    track_df[c].to_numpy(),\n                )\n            for c in [\"roll\", \"pitch\", \"yaw\"]:\n                # Unwrap angles to handle discontinuities, then interpolate, then wrap back to [-\u03c0, \u03c0]\n                unwrapped_angles = np.unwrap(track_df[c])\n                interpolated = np.interp(track_new_nanos, track_df[\"total_nanos\"], unwrapped_angles)\n                track_data[c] = np.mod(interpolated + np.pi, 2 * np.pi) - np.pi\n            new_track_df = pl.DataFrame(track_data)\n            new_track_df = new_track_df.with_columns(\n                pl.Series(\n                    name=\"idx\",\n                    values=np.ones_like(track_new_nanos) * idx,\n                    dtype=polars_schema[\"idx\"],\n                ),\n                pl.Series(\n                    name=\"total_nanos\",\n                    values=track_new_nanos,\n                    dtype=polars_schema[\"total_nanos\"],\n                ),\n            )\n            new_dfs.append(new_track_df)\n        new_df = pl.concat(new_dfs)\n        return self.__init__(df=new_df, map=self.map, host_vehicle_idx=self.host_vehicle_idx)\n\n    def _create_legend(self, ax):\n        handles, labels = ax.get_legend_handles_labels()\n        host_label = f\"{self.host_vehicle_idx} - HV\"\n\n        def sort_key(item):\n            label = item[1]\n            if label == host_label:\n                return (-1, -1)\n            try:\n                return (0, int(label))\n            except ValueError:\n                return (0, float(\"inf\"))  # non-numeric labels go last\n\n        items = sorted(zip(handles, labels), key=sort_key)\n        handles, labels = zip(*items)\n        ax.legend(handles, labels, loc=\"center left\", bbox_to_anchor=(1, 0.5))\n        return ax\n\n    def plot(self, ax=None, legend=False, mvs_plt_type: str = \"scatter\") -&gt; plt.Axes:\n        \"Generate a static plot of the recording using Matplotlib. Plots the map (if available), moving objects, and traffic light states.\"\n        if ax is None:\n            fig, ax = plt.subplots(1, 1)\n            ax.set_aspect(1)\n        if self.map:\n            self.map.plot(ax)\n        self.plot_mvs(ax=ax, mvs_plt_type=mvs_plt_type)\n        self.plot_tl(ax=ax)\n        if legend:\n            ax = self._create_legend(ax)\n        return ax\n\n    def plot_mvs(self, ax=None, legend=False, mvs_plt_type: str = \"scatter\"):\n        \"Generate a static plot of the moving objects in the recording using Matplotlib.\"\n        if ax is None:\n            fig, ax = plt.subplots(1, 1)\n            ax.set_aspect(1)\n        plot_fn = {\"scatter\": ax.scatter, \"plot\": ax.plot}.get(mvs_plt_type)\n        if plot_fn is None:\n            raise ValueError(\"`mvs_plt_type` must be one of: 'scatter', 'plot'.\")\n\n        plot_df = self._df[\"idx\", \"x\", \"y\"]\n        base_kwargs = {\"alpha\": 0.5}\n        for [idx], mv in plot_df.group_by(\"idx\"):\n            if idx == self.host_vehicle_idx:\n                ax.plot(*mv[\"x\", \"y\"], c=\"red\", label=f\"{idx} - HV\")\n                continue\n            plot_fn(*mv[\"x\", \"y\"], label=str(idx), **base_kwargs)\n\n        if legend:\n            ax = self._create_legend(ax)\n        return ax\n\n    def plot_tl(self, ax=None):\n        \"Generate a static plot of the traffic lights in the recording using Matplotlib.\"\n        if ax is None:\n            fig, ax = plt.subplots(1, 1)\n            ax.set_aspect(1)\n        tl_dict = {}\n        for tl_states in self.traffic_light_states:\n            for tl in self.traffic_light_states[tl_states]:\n                if tl.id.value not in tl_dict.keys():\n                    tl_dict[tl.id.value] = tl\n\n        for tl in tl_dict:\n            try:\n                x = tl_dict[tl].base.position.x\n                y = tl_dict[tl].base.position.y\n                ax.plot(\n                    x,\n                    y,\n                    marker=\"s\",\n                    label=f\"Traffic Light {tl_dict[tl].id.value}\",\n                    c=\"blue\",\n                    alpha=0.7,\n                    markersize=2,\n                )\n            except AttributeError as e:\n                print(f\"Warning: Skipping traffic light {tl.id.value} due to missing position data: {e}\")\n                continue\n        return ax\n\n    def plot_frame(self, frame: int, ax=None):\n        \"Generate a static plot of a specific frame in the recording using Matplotlib.\"\n        ax = self.plot(ax=ax)\n        self.plot_mv_frame(ax, frame=frame)\n        return ax\n\n    def plot_mv_frame(self, ax: plt.Axes, frame: int):\n        polys = self._df.filter(pl.col(\"frame\") == frame)[\"polygon\"]\n        for p in polys:\n            ax.add_patch(PltPolygon(p.exterior.coords, fc=\"red\"))\n\n    def plot_altair(\n        self,\n        start_frame: int = 0,\n        end_frame: int = -1,\n        plot_map: bool = True,\n        plot_map_polys: bool = True,\n        metric_column: str | None = None,\n        plot_wedges: bool = True,\n        idx=None,\n        height: float | None = None,\n        width: float | None = None,\n    ) -&gt; alt.Chart:\n        \"Generate an interactive plot of the recording using Altair.\"\n        if end_frame != -1:\n            df = self._df.filter(pl.col(\"frame\") &lt; end_frame, pl.col(\"frame\") &gt;= start_frame)\n        else:\n            df = self._df.filter(pl.col(\"frame\") &gt;= start_frame)\n\n        [frame_min], [frame_max] = df.select(\n            pl.col(\"frame\").min().alias(\"min\"),\n            pl.col(\"frame\").max().alias(\"max\"),\n        )[0]\n        slider = alt.binding_range(min=frame_min, max=frame_max, step=1, name=\"frame\")\n        op_var = alt.param(value=0, bind=slider)\n\n        df = df.with_columns(\n            pl.concat_str(\n                pl.col(\"type\").map_elements(lambda x: betterosi.MovingObjectType(x).name, return_dtype=pl.String),\n                pl.col(\"subtype\").map_elements(\n                    lambda x: betterosi.MovingObjectVehicleClassificationType(x).name,\n                    return_dtype=pl.String,\n                ),\n                separator=\"-\",\n            ).alias(\"type\")\n        )\n        buffer = pl.col(\"length\").max()\n        xmin, xmax, ymin, ymax = df.select(\n            (pl.col(\"x\").min() - buffer).alias(\"xmin\"),\n            (pl.col(\"x\").max() + buffer).alias(\"xmax\"),\n            (pl.col(\"y\").min() - buffer).alias(\"ymin\"),\n            (pl.col(\"y\").max() + buffer).alias(\"ymax\"),\n        ).row(0)\n        pov_df = pl.DataFrame({\"polygon\": [shapely.Polygon([[xmax, ymax], [xmax, ymin], [xmin, ymin], [xmin, ymax]])]})\n        pov_df = pov_df.select(geometry=st.from_shapely(\"polygon\"))\n        pov = alt.Chart({\"values\": pov_df.st.to_dicts()}).mark_geoshape(fillOpacity=0, filled=False, opacity=0)\n\n        plots = [pov]\n        if plot_map and self.map is not None:\n            plots.append(self.map.plot_altair(recording=self, plot_polys=plot_map_polys))\n\n        mv_dict = {\"values\": df[\"geometry\", \"idx\", \"frame\", \"type\"].st.to_dicts()}\n        plots.append(\n            alt.Chart(mv_dict)\n            .mark_geoshape()\n            .encode(\n                color=(\n                    alt.when(alt.FieldEqualPredicate(equal=self.host_vehicle_idx or -1, field=\"properties.idx\"))\n                    .then(alt.value(\"red\"))\n                    .when(alt.FieldEqualPredicate(equal=-1 if idx is None else idx, field=\"properties.idx\"))\n                    .then(alt.value(\"red\"))\n                    .otherwise(alt.value(\"blue\"))\n                ),\n                tooltip=[\"properties.idx:N\", \"properties.frame:N\", \"properties.type:O\"],\n            )\n            .transform_filter(alt.FieldEqualPredicate(field=\"properties.frame\", equal=op_var))\n        )\n        if plot_wedges:\n            wedges_df = df[\"idx\", \"frame\", \"type\", \"x\", \"y\", \"yaw\", \"length\"].with_columns(\n                pl.col(\"yaw\").degrees().alias(\"deg\"),\n                (pl.col(\"length\") / 4).alias(\"size\"),\n            )\n            plots.append(\n                alt.Chart(wedges_df)\n                .mark_point(shape=\"wedge\", color=\"white\", strokeWidth=2)\n                .encode(\n                    alt.Longitude(\"x:Q\"),\n                    alt.Latitude(\"y:Q\"),\n                    alt.Angle(\"deg\").scale(domain=[180, -180], range=[-90, 270]),\n                    alt.Size(\"size\", legend=None),\n                    tooltip=[\"idx:N\", \"frame:N\", \"type:O\"],\n                )\n                .transform_filter(alt.FieldEqualPredicate(field=\"frame\", equal=op_var))\n            )\n\n        view = (\n            alt.layer(*plots)\n            .properties(\n                title=\"Map\",\n                **({\"height\": height} if height is not None else {}),\n                **({\"width\": width} if width is not None else {}),\n            )\n            .project(\"identity\", reflectY=True)\n        )\n\n        if metric_column is not None and idx is not None:\n            metric = (\n                df[\"idx\", metric_column, \"frame\"]\n                .filter(idx=idx)\n                .plot.line(x=\"frame\", y=metric_column, color=alt.value(\"red\"))\n                .properties(title=f\"{metric_column} of object {idx}\")\n            )\n            vertline = (\n                alt.Chart()\n                .mark_rule()\n                .encode(\n                    x=alt.datum(\n                        op_var,\n                        type=\"quantitative\",\n                        scale=alt.Scale(domain=[frame_min, frame_max]),\n                    )\n                )\n            )\n            view = view | (metric + vertline)\n        return view.add_params(op_var)\n\n    def create_mapsegments(self):\n        if isinstance(self.map, MapOsiCenterline):\n            self.mapsegment = MapOsiCenterlineSegmentation(self)\n            self.mapsegment.init_intersections()\n</code></pre>"},{"location":"api/#omega_prime.recording.Recording.__init__","title":"<code>__init__(df, map=None, projections=None, host_vehicle_idx=None, validate=False, traffic_light_states=None)</code>","text":"<p>Initialize a Recording instance.</p> Source code in <code>omega_prime/recording.py</code> <pre><code>def __init__(\n    self,\n    df,\n    map=None,\n    projections=None,\n    host_vehicle_idx: int | None = None,\n    validate=False,\n    traffic_light_states: dict | None = None,\n):\n    \"Initialize a Recording instance.\"\n    df = self._ensure_polars_dataframe(df)\n    if \"total_nanos\" not in df.columns:\n        raise ValueError(\"df must contain column `total_nanos`.\")\n    nanos2frame, mapping = self._build_frame_mapping(df)\n    df = self._attach_frame_column(df, mapping)\n    df = self._ensure_polars_dataframe(df)\n    if validate:\n        recording_moving_object_schema.validate(df, lazy=True)\n\n    super().__init__()\n    self.nanos2frame = nanos2frame\n\n    df = self._ensure_motion_norm_columns(df)\n    self.projections = self._validate_projections_schema(projections)\n    self.traffic_light_states = traffic_light_states if traffic_light_states is not None else {}\n\n    df = bbx_to_polygon(df)\n\n    self._df = df\n    self.map = map\n    self._moving_objects = None\n    self.host_vehicle_idx = host_vehicle_idx\n    self.mapsegment = None\n</code></pre>"},{"location":"api/#omega_prime.recording.Recording.apply_projections","title":"<code>apply_projections()</code>","text":"<p>Apply projection transformations to the recording's moving object data based on the provided projection metadata and the map's projection. This method updates the <code>x</code>, <code>y</code>, and <code>z</code> columns of the recording's DataFrame according to the specified projections and transforms the coordinates to the target CRS if necessary. The original coordinates before applying projections are stored in <code>x_original</code>, <code>y_original</code>, and <code>z_original</code> columns to preserve the original pose information for export or reference.</p> Source code in <code>omega_prime/recording.py</code> <pre><code>def apply_projections(self):\n    \"\"\"\n    Apply projection transformations to the recording's moving object data based on the provided projection metadata\n    and the map's projection. This method updates the `x`, `y`, and `z` columns of the recording's DataFrame\n    according to the specified projections and transforms the coordinates to the target CRS if necessary.\n    The original coordinates before applying projections are stored in `x_original`, `y_original`, and `z_original`\n    columns to preserve the original pose information for export or reference.\n    \"\"\"\n    if self._df.height == 0:\n        return self\n\n    source_proj_string = self.projections.get(\"proj_string\")\n    if source_proj_string is None:\n        self.map.parse()\n        source_proj_string = getattr(self.map, \"proj_string\", None)\n\n    if source_proj_string is None:\n        raise ValueError(\"No proj_string information available on the recording or attached map.\")\n\n    frame_projections: list[dict[str, typing.Any]] = []\n    for ts, offset in self.projections.items():\n        if ts in (None, \"proj_string\"):\n            continue\n        ox, oy, oz, oyaw = self._offset_components(offset)\n        frame_projections.append(\n            dict(\n                total_nanos=int(ts),\n                offset_x=ox,\n                offset_y=oy,\n                offset_z=oz,\n                offset_yaw=oyaw,\n            )\n        )\n\n    df = self._df\n\n    default_offset = self.projections.get(None)\n    dox, doy, doz, doyaw = self._offset_components(default_offset)\n\n    if frame_projections:\n        proj_df = pl.DataFrame(\n            frame_projections,\n            schema={\n                \"total_nanos\": polars_schema[\"total_nanos\"],\n                \"offset_x\": pl.Float64,\n                \"offset_y\": pl.Float64,\n                \"offset_z\": pl.Float64,\n                \"offset_yaw\": pl.Float64,\n            },\n        )\n        df = df.join(proj_df, on=\"total_nanos\", how=\"left\")\n        df = df.with_columns(\n            pl.lit(source_proj_string).alias(\"proj_string\"),\n            pl.col(\"offset_x\").fill_null(dox).alias(\"offset_x\"),\n            pl.col(\"offset_y\").fill_null(doy).alias(\"offset_y\"),\n            pl.col(\"offset_z\").fill_null(doz).alias(\"offset_z\"),\n            pl.col(\"offset_yaw\").fill_null(doyaw).alias(\"offset_yaw\"),\n        )\n\n    else:\n        df = df.with_columns(\n            pl.lit(source_proj_string).alias(\"proj_string\"),\n            pl.lit(dox).alias(\"offset_x\"),\n            pl.lit(doy).alias(\"offset_y\"),\n            pl.lit(doz).alias(\"offset_z\"),\n            pl.lit(doyaw).alias(\"offset_yaw\"),\n        )\n    source_crs = pyproj.CRS.from_string(source_proj_string)\n\n    if df.select(pl.col(\"proj_string\").is_null().any()).item():\n        raise ValueError(\"Some rows do not have a projection string assigned.\")\n\n    # Store original values before applying offsets, when it is the first projection\n    if not any(col in df.columns for col in [\"x_original\", \"y_original\", \"z_original\"]):\n        df = df.with_columns(\n            pl.col(\"x\").alias(\"x_original\"),\n            pl.col(\"y\").alias(\"y_original\"),\n            pl.col(\"z\").alias(\"z_original\"),\n        )\n\n    # Update main columns with offset values\n    df = df.with_columns(\n        (\n            pl.col(\"x\") * pl.col(\"offset_yaw\").cos() - pl.col(\"y\") * pl.col(\"offset_yaw\").sin() + pl.col(\"offset_x\")\n        ).alias(\"x\"),\n        (\n            pl.col(\"x\") * pl.col(\"offset_yaw\").sin() + pl.col(\"y\") * pl.col(\"offset_yaw\").cos() + pl.col(\"offset_y\")\n        ).alias(\"y\"),\n        (pl.col(\"z\") + pl.col(\"offset_z\")).alias(\"z\"),\n    )\n\n    self.map.parse()\n    target_crs = self.map.projection\n    if not target_crs:\n        raise ValueError(\"Map does not have a valid projection defined.\")\n\n    # Apply 2D proj string transformation\n    transformer = pyproj.Transformer.from_crs(source_crs, target_crs)\n    x_tgt, y_tgt = transformer.transform(df[\"x\"].to_numpy(), df[\"y\"].to_numpy())\n    df = df.with_columns(pl.Series(name=\"x\", values=x_tgt), pl.Series(name=\"y\", values=y_tgt))\n\n    # From map world to map local\n    if self.map.proj_offset:\n        m_ox, m_oy, m_oz, m_oyaw = self._offset_components(self.map.proj_offset)\n        df = df.with_columns(\n            ((pl.col(\"x\") - m_ox) * np.cos(m_oyaw) + (pl.col(\"y\") - m_oy) * np.sin(m_oyaw)).alias(\"x\"),\n            ((pl.col(\"y\") - m_oy) * np.cos(m_oyaw) - (pl.col(\"x\") - m_ox) * np.sin(m_oyaw)).alias(\"y\"),\n            (pl.col(\"z\") - m_oz).alias(\"z\"),\n        )\n\n    df = bbx_to_polygon(df)\n\n    # Remove temporary projection columns\n    df = df.drop(\"proj_string\", \"offset_x\", \"offset_y\", \"offset_z\", \"offset_yaw\")\n\n    self._df = df\n    return self\n</code></pre>"},{"location":"api/#omega_prime.recording.Recording.from_file","title":"<code>from_file(filepath, map_path=None, validate=False, parse_map=False, step_size=0.01, apply_proj=True, **kwargs)</code>  <code>classmethod</code>","text":"<p>Load a Recording from a file. Supports <code>.parquet</code>, <code>.osi</code> and <code>.mcap</code> files.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to the input file.</p> required <code>map_path</code> <code>str | None</code> <p>Optional path to a map file. If None, the map will be loaded from the recording if available.</p> <code>None</code> <code>validate</code> <code>bool</code> <p>Whether to validate the data against the schema.</p> <code>False</code> <code>parse_map</code> <code>bool</code> <p>Whether to create python objects from the map data or just load it.</p> <code>False</code> <code>step_size</code> <code>float</code> <p>Step size for map parsing, if applicable (Used for ASAM OpenDRIVE).</p> <code>0.01</code> <code>apply_proj</code> <code>bool</code> <p>Whether to apply projection transformations to the recording's moving object data.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>Recording</code> <code>Recording</code> <p>The loaded Recording object.</p> Source code in <code>omega_prime/recording.py</code> <pre><code>@classmethod\ndef from_file(\n    cls,\n    filepath,\n    map_path: str | None = None,\n    validate: bool = False,\n    parse_map: bool = False,\n    step_size: float = 0.01,\n    apply_proj: bool = True,\n    **kwargs,\n) -&gt; \"Recording\":\n    \"\"\"Load a Recording from a file. Supports `.parquet`, `.osi` and `.mcap` files.\n\n    Parameters:\n        filepath (str): Path to the input file.\n        map_path (str | None): Optional path to a map file. If None, the map will be loaded from the recording if available.\n        validate (bool): Whether to validate the data against the schema.\n        parse_map (bool): Whether to create python objects from the map data or just load it.\n        step_size (float): Step size for map parsing, if applicable (Used for ASAM OpenDRIVE).\n        apply_proj (bool): Whether to apply projection transformations to the recording's moving object data.\n\n    Returns:\n        Recording (Recording): The loaded Recording object.\n    \"\"\"\n    if filepath is None and map_path is None:\n        raise ValueError(\"Either `filepath` or `map_path` must be provided.\")\n\n    if filepath is not None and Path(filepath).suffix == \".parquet\":\n        r = cls.from_parquet(filepath, parse_map=parse_map, validate=validate, step_size=step_size)\n    elif filepath is not None:\n        gts = betterosi.read(filepath, return_ground_truth=True, mcap_return_betterosi=True)\n        r = cls.from_osi_gts(gts, validate=validate)\n    if map_path is None and r.map is not None:\n        return r\n\n    map_path = Path(map_path if map_path is not None else filepath)\n    map_parsing = {}\n    map = None\n    for MC in MAP_CLASSES:\n        if map_path.suffix in MC._supported_file_suffixes:\n            try:\n                map = MC.from_file(map_path, parse_map=parse_map, **kwargs)\n            except Exception as e:\n                map_parsing[MC.__name__] = str(e)\n            else:\n                break\n    if map is not None:\n        r.map = map\n    elif r.map is None:\n        warn(f\"No map could be found: {map_parsing}\")\n\n    if r.projections and apply_proj:\n        try:\n            r.apply_projections()\n        except Exception:\n            warn(\"Failed to apply projections.\")\n    return r\n</code></pre>"},{"location":"api/#omega_prime.recording.Recording.interpolate","title":"<code>interpolate(new_nanos=None, hz=None)</code>","text":"<p>Interpolate the recording to new timestamps or a given frequency.</p> Source code in <code>omega_prime/recording.py</code> <pre><code>def interpolate(self, new_nanos: list[int] | None = None, hz: float | None = None):\n    \"Interpolate the recording to new timestamps or a given frequency.\"\n    df = self._df\n    nanos_min, nanos_max, frame_min, frame_max = df.select(\n        nanos_min=pl.col(\"total_nanos\").min(),\n        nanos_max=pl.col(\"total_nanos\").max(),\n        frame_min=pl.col(\"frame\").min(),\n        frame_max=pl.col(\"frame\").max(),\n    ).row(0)\n    if new_nanos is None:\n        if hz is None:\n            new_nanos = np.linspace(nanos_min, nanos_max, frame_max - frame_min, dtype=int)\n        else:\n            step = 1e9 / hz\n            new_nanos = np.arange(start=nanos_min, stop=nanos_max + 1, step=step, dtype=int)\n    else:\n        new_nanos = np.array(new_nanos)\n    new_dfs = []\n    for [idx], track_df in df.group_by(\"idx\"):\n        track_data = {}\n        track_new_nanos = new_nanos[\n            np.logical_and(\n                track_df[\"total_nanos\"].min() &lt;= new_nanos,\n                track_df[\"total_nanos\"].max() &gt;= new_nanos,\n            )\n        ]\n        for c in [\n            \"x\",\n            \"y\",\n            \"z\",\n            \"vel_x\",\n            \"vel_y\",\n            \"vel_z\",\n            \"acc_x\",\n            \"acc_y\",\n            \"acc_z\",\n            \"length\",\n            \"width\",\n            \"height\",\n        ]:\n            track_data[c] = np.interp(track_new_nanos, track_df[\"total_nanos\"], track_df[c])\n        for c in [\"type\", \"subtype\", \"role\"]:\n            track_data[c] = nearest_interp(\n                track_new_nanos,\n                track_df[\"total_nanos\"].to_numpy(),\n                track_df[c].to_numpy(),\n            )\n        for c in [\"roll\", \"pitch\", \"yaw\"]:\n            # Unwrap angles to handle discontinuities, then interpolate, then wrap back to [-\u03c0, \u03c0]\n            unwrapped_angles = np.unwrap(track_df[c])\n            interpolated = np.interp(track_new_nanos, track_df[\"total_nanos\"], unwrapped_angles)\n            track_data[c] = np.mod(interpolated + np.pi, 2 * np.pi) - np.pi\n        new_track_df = pl.DataFrame(track_data)\n        new_track_df = new_track_df.with_columns(\n            pl.Series(\n                name=\"idx\",\n                values=np.ones_like(track_new_nanos) * idx,\n                dtype=polars_schema[\"idx\"],\n            ),\n            pl.Series(\n                name=\"total_nanos\",\n                values=track_new_nanos,\n                dtype=polars_schema[\"total_nanos\"],\n            ),\n        )\n        new_dfs.append(new_track_df)\n    new_df = pl.concat(new_dfs)\n    return self.__init__(df=new_df, map=self.map, host_vehicle_idx=self.host_vehicle_idx)\n</code></pre>"},{"location":"api/#omega_prime.recording.Recording.plot","title":"<code>plot(ax=None, legend=False, mvs_plt_type='scatter')</code>","text":"<p>Generate a static plot of the recording using Matplotlib. Plots the map (if available), moving objects, and traffic light states.</p> Source code in <code>omega_prime/recording.py</code> <pre><code>def plot(self, ax=None, legend=False, mvs_plt_type: str = \"scatter\") -&gt; plt.Axes:\n    \"Generate a static plot of the recording using Matplotlib. Plots the map (if available), moving objects, and traffic light states.\"\n    if ax is None:\n        fig, ax = plt.subplots(1, 1)\n        ax.set_aspect(1)\n    if self.map:\n        self.map.plot(ax)\n    self.plot_mvs(ax=ax, mvs_plt_type=mvs_plt_type)\n    self.plot_tl(ax=ax)\n    if legend:\n        ax = self._create_legend(ax)\n    return ax\n</code></pre>"},{"location":"api/#omega_prime.recording.Recording.plot_altair","title":"<code>plot_altair(start_frame=0, end_frame=-1, plot_map=True, plot_map_polys=True, metric_column=None, plot_wedges=True, idx=None, height=None, width=None)</code>","text":"<p>Generate an interactive plot of the recording using Altair.</p> Source code in <code>omega_prime/recording.py</code> <pre><code>def plot_altair(\n    self,\n    start_frame: int = 0,\n    end_frame: int = -1,\n    plot_map: bool = True,\n    plot_map_polys: bool = True,\n    metric_column: str | None = None,\n    plot_wedges: bool = True,\n    idx=None,\n    height: float | None = None,\n    width: float | None = None,\n) -&gt; alt.Chart:\n    \"Generate an interactive plot of the recording using Altair.\"\n    if end_frame != -1:\n        df = self._df.filter(pl.col(\"frame\") &lt; end_frame, pl.col(\"frame\") &gt;= start_frame)\n    else:\n        df = self._df.filter(pl.col(\"frame\") &gt;= start_frame)\n\n    [frame_min], [frame_max] = df.select(\n        pl.col(\"frame\").min().alias(\"min\"),\n        pl.col(\"frame\").max().alias(\"max\"),\n    )[0]\n    slider = alt.binding_range(min=frame_min, max=frame_max, step=1, name=\"frame\")\n    op_var = alt.param(value=0, bind=slider)\n\n    df = df.with_columns(\n        pl.concat_str(\n            pl.col(\"type\").map_elements(lambda x: betterosi.MovingObjectType(x).name, return_dtype=pl.String),\n            pl.col(\"subtype\").map_elements(\n                lambda x: betterosi.MovingObjectVehicleClassificationType(x).name,\n                return_dtype=pl.String,\n            ),\n            separator=\"-\",\n        ).alias(\"type\")\n    )\n    buffer = pl.col(\"length\").max()\n    xmin, xmax, ymin, ymax = df.select(\n        (pl.col(\"x\").min() - buffer).alias(\"xmin\"),\n        (pl.col(\"x\").max() + buffer).alias(\"xmax\"),\n        (pl.col(\"y\").min() - buffer).alias(\"ymin\"),\n        (pl.col(\"y\").max() + buffer).alias(\"ymax\"),\n    ).row(0)\n    pov_df = pl.DataFrame({\"polygon\": [shapely.Polygon([[xmax, ymax], [xmax, ymin], [xmin, ymin], [xmin, ymax]])]})\n    pov_df = pov_df.select(geometry=st.from_shapely(\"polygon\"))\n    pov = alt.Chart({\"values\": pov_df.st.to_dicts()}).mark_geoshape(fillOpacity=0, filled=False, opacity=0)\n\n    plots = [pov]\n    if plot_map and self.map is not None:\n        plots.append(self.map.plot_altair(recording=self, plot_polys=plot_map_polys))\n\n    mv_dict = {\"values\": df[\"geometry\", \"idx\", \"frame\", \"type\"].st.to_dicts()}\n    plots.append(\n        alt.Chart(mv_dict)\n        .mark_geoshape()\n        .encode(\n            color=(\n                alt.when(alt.FieldEqualPredicate(equal=self.host_vehicle_idx or -1, field=\"properties.idx\"))\n                .then(alt.value(\"red\"))\n                .when(alt.FieldEqualPredicate(equal=-1 if idx is None else idx, field=\"properties.idx\"))\n                .then(alt.value(\"red\"))\n                .otherwise(alt.value(\"blue\"))\n            ),\n            tooltip=[\"properties.idx:N\", \"properties.frame:N\", \"properties.type:O\"],\n        )\n        .transform_filter(alt.FieldEqualPredicate(field=\"properties.frame\", equal=op_var))\n    )\n    if plot_wedges:\n        wedges_df = df[\"idx\", \"frame\", \"type\", \"x\", \"y\", \"yaw\", \"length\"].with_columns(\n            pl.col(\"yaw\").degrees().alias(\"deg\"),\n            (pl.col(\"length\") / 4).alias(\"size\"),\n        )\n        plots.append(\n            alt.Chart(wedges_df)\n            .mark_point(shape=\"wedge\", color=\"white\", strokeWidth=2)\n            .encode(\n                alt.Longitude(\"x:Q\"),\n                alt.Latitude(\"y:Q\"),\n                alt.Angle(\"deg\").scale(domain=[180, -180], range=[-90, 270]),\n                alt.Size(\"size\", legend=None),\n                tooltip=[\"idx:N\", \"frame:N\", \"type:O\"],\n            )\n            .transform_filter(alt.FieldEqualPredicate(field=\"frame\", equal=op_var))\n        )\n\n    view = (\n        alt.layer(*plots)\n        .properties(\n            title=\"Map\",\n            **({\"height\": height} if height is not None else {}),\n            **({\"width\": width} if width is not None else {}),\n        )\n        .project(\"identity\", reflectY=True)\n    )\n\n    if metric_column is not None and idx is not None:\n        metric = (\n            df[\"idx\", metric_column, \"frame\"]\n            .filter(idx=idx)\n            .plot.line(x=\"frame\", y=metric_column, color=alt.value(\"red\"))\n            .properties(title=f\"{metric_column} of object {idx}\")\n        )\n        vertline = (\n            alt.Chart()\n            .mark_rule()\n            .encode(\n                x=alt.datum(\n                    op_var,\n                    type=\"quantitative\",\n                    scale=alt.Scale(domain=[frame_min, frame_max]),\n                )\n            )\n        )\n        view = view | (metric + vertline)\n    return view.add_params(op_var)\n</code></pre>"},{"location":"api/#omega_prime.recording.Recording.plot_frame","title":"<code>plot_frame(frame, ax=None)</code>","text":"<p>Generate a static plot of a specific frame in the recording using Matplotlib.</p> Source code in <code>omega_prime/recording.py</code> <pre><code>def plot_frame(self, frame: int, ax=None):\n    \"Generate a static plot of a specific frame in the recording using Matplotlib.\"\n    ax = self.plot(ax=ax)\n    self.plot_mv_frame(ax, frame=frame)\n    return ax\n</code></pre>"},{"location":"api/#omega_prime.recording.Recording.plot_mvs","title":"<code>plot_mvs(ax=None, legend=False, mvs_plt_type='scatter')</code>","text":"<p>Generate a static plot of the moving objects in the recording using Matplotlib.</p> Source code in <code>omega_prime/recording.py</code> <pre><code>def plot_mvs(self, ax=None, legend=False, mvs_plt_type: str = \"scatter\"):\n    \"Generate a static plot of the moving objects in the recording using Matplotlib.\"\n    if ax is None:\n        fig, ax = plt.subplots(1, 1)\n        ax.set_aspect(1)\n    plot_fn = {\"scatter\": ax.scatter, \"plot\": ax.plot}.get(mvs_plt_type)\n    if plot_fn is None:\n        raise ValueError(\"`mvs_plt_type` must be one of: 'scatter', 'plot'.\")\n\n    plot_df = self._df[\"idx\", \"x\", \"y\"]\n    base_kwargs = {\"alpha\": 0.5}\n    for [idx], mv in plot_df.group_by(\"idx\"):\n        if idx == self.host_vehicle_idx:\n            ax.plot(*mv[\"x\", \"y\"], c=\"red\", label=f\"{idx} - HV\")\n            continue\n        plot_fn(*mv[\"x\", \"y\"], label=str(idx), **base_kwargs)\n\n    if legend:\n        ax = self._create_legend(ax)\n    return ax\n</code></pre>"},{"location":"api/#omega_prime.recording.Recording.plot_tl","title":"<code>plot_tl(ax=None)</code>","text":"<p>Generate a static plot of the traffic lights in the recording using Matplotlib.</p> Source code in <code>omega_prime/recording.py</code> <pre><code>def plot_tl(self, ax=None):\n    \"Generate a static plot of the traffic lights in the recording using Matplotlib.\"\n    if ax is None:\n        fig, ax = plt.subplots(1, 1)\n        ax.set_aspect(1)\n    tl_dict = {}\n    for tl_states in self.traffic_light_states:\n        for tl in self.traffic_light_states[tl_states]:\n            if tl.id.value not in tl_dict.keys():\n                tl_dict[tl.id.value] = tl\n\n    for tl in tl_dict:\n        try:\n            x = tl_dict[tl].base.position.x\n            y = tl_dict[tl].base.position.y\n            ax.plot(\n                x,\n                y,\n                marker=\"s\",\n                label=f\"Traffic Light {tl_dict[tl].id.value}\",\n                c=\"blue\",\n                alpha=0.7,\n                markersize=2,\n            )\n        except AttributeError as e:\n            print(f\"Warning: Skipping traffic light {tl.id.value} due to missing position data: {e}\")\n            continue\n    return ax\n</code></pre>"},{"location":"api/#omega_prime.recording.Recording.to_file","title":"<code>to_file(filepath)</code>","text":"<p>Store Recording to a file based on its suffix (<code>.parquet</code>, <code>.mcap</code>).</p> Source code in <code>omega_prime/recording.py</code> <pre><code>def to_file(self, filepath):\n    \"Store Recording to a file based on its suffix (`.parquet`, `.mcap`).\"\n    suffix = Path(filepath).suffix.lower()\n    if suffix == \".parquet\":\n        self.to_parquet(filepath)\n        return\n    if suffix == \".mcap\":\n        self.to_mcap(filepath)\n        return\n    raise ValueError(f\"Unsupported file suffix `{suffix}`. Expected one of: `.parquet`, `.mcap`.\")\n</code></pre>"},{"location":"api/#omega_prime.recording.Recording.to_mcap","title":"<code>to_mcap(filepath)</code>","text":"<p>Store Recording as an MCAP file.</p> Source code in <code>omega_prime/recording.py</code> <pre><code>def to_mcap(self, filepath):\n    \"Store Recording as an MCAP file.\"\n    if Path(filepath).suffix != \".mcap\":\n        raise ValueError()\n    with betterosi.Writer(filepath) as w:\n        for gt in self.to_osi_gts():\n            w.add(gt)\n        if isinstance(self.map, MapOdr):\n            w.add(self.map.to_osi(), topic=\"ground_truth_map\", log_time=0)\n        elif (\n            self.map is not None and not isinstance(self.map, MapOsi) and not isinstance(self.map, MapOsiCenterline)\n        ):\n            warn(f\"The map {self.map} could not be saved to `mcap`\")\n</code></pre>"},{"location":"api/#omega_prime.recording.Recording.to_parquet","title":"<code>to_parquet(filename)</code>","text":"<p>Store Recording as a Parquet file.</p> Source code in <code>omega_prime/recording.py</code> <pre><code>def to_parquet(self, filename):\n    \"Store Recording as a Parquet file.\"\n    metadata = {}\n    if self.host_vehicle_idx is not None:\n        metadata[b\"host_vehicle_idx\"] = str(self.host_vehicle_idx).encode()\n    proj_meta = {}\n    encoded_projections = self._encode_projections(self.projections)\n    if encoded_projections:\n        proj_meta[b\"projections_json\"] = encoded_projections\n    df_export = self._df_with_original_pose_for_export()\n    to_drop = [\"frame\"]\n    optional_cols = [\n        \"polygon\",\n        \"global_lat\",\n        \"global_lon\",\n        \"global_alt\",\n        \"global_yaw\",\n        \"proj_string\",\n        \"x_original\",\n        \"y_original\",\n        \"z_original\",\n        \"yaw_original\",\n    ]\n    to_drop.extend([c for c in optional_cols if c in df_export.columns])\n    t = pyarrow.table(df_export.drop(*to_drop))\n    map_meta = self.map._to_binary_json() if self.map is not None else {}\n\n    t = t.cast(t.schema.with_metadata(metadata | proj_meta | map_meta))\n    pq.write_table(t, filename)\n</code></pre>"},{"location":"api/#omega_prime.map.Map","title":"<code>Map</code>  <code>dataclass</code>","text":"<p>Base class for Map representations</p> Source code in <code>omega_prime/map.py</code> <pre><code>@dataclass(repr=False)\nclass Map:\n    \"\"\"Base class for Map representations\"\"\"\n\n    lane_boundaries: dict[Any, LaneBoundary]\n    lanes: dict[Any:Lane]\n\n    _supported_file_suffixes = [\".osi\", \".mcap\"]\n    _binary_json_identifier = b\"osi\"\n\n    def plot(self, ax: plt.Axes | None = None):\n        if ax is None:\n            fig, ax = plt.subplots(1, 1)\n            ax.set_aspect(1)\n        for l in self.lanes.values():\n            l.plot(ax)\n        for b in self.lane_boundaries.values():\n            b.plot(ax)\n\n    @classmethod\n    def from_file(cls, filepath, parse_map=True, **kwargs):\n        \"Create a Map instance from a file.\"\n        first_gt = next(betterosi.read(filepath, return_ground_truth=True, mcap_return_betterosi=True))\n        return cls.create(first_gt, **kwargs)\n\n    def plot_altair(self, recording=None, plot_polys=True):\n        arbitrary_lane = next(iter(self.lanes.values()))\n        plot_polys = hasattr(arbitrary_lane, \"polygon\") and arbitrary_lane.polygon is not None and plot_polys\n\n        if not hasattr(self, \"_plot_dict\"):\n            if plot_polys:\n                shapely_series = pl.Series(\n                    name=\"shapely\", values=[l.polygon.simplify(0.1) for l in self.lanes.values()]\n                )\n            else:\n                shapely_series = pl.Series(\n                    name=\"shapely\", values=[l.centerline.simplify(0.1) for l in self.lanes.values()]\n                )\n\n            map_df = pl.DataFrame(\n                [\n                    shapely_series,\n                    pl.Series(name=\"idx\", values=[i for i, _ in enumerate(self.lanes.keys())]),\n                    pl.Series(name=\"type\", values=[o.type.name for o in self.lanes.values()]),\n                    pl.Series(name=\"subtype\", values=[o.subtype.name for o in self.lanes.values()]),\n                    pl.Series(name=\"on_intersection\", values=[o.on_intersection for o in self.lanes.values()]),\n                ]\n            )\n            map_df = map_df.with_columns(geometry=st.from_shapely(\"shapely\")).drop(\"shapely\")\n\n            if recording is not None:\n                buffer = 5\n                [xmin], [xmax], [ymin], [ymax] = recording._df.select(\n                    (pl.col(\"x\").min() - buffer).alias(\"xmin\"),\n                    (pl.col(\"x\").max() + buffer).alias(\"xmax\"),\n                    (pl.col(\"y\").min() - buffer).alias(\"ymin\"),\n                    (pl.col(\"y\").max() + buffer).alias(\"ymax\"),\n                )[0]\n\n                pov_df = pl.DataFrame(\n                    {\"polygon\": [shapely.Polygon([[xmax, ymax], [xmax, ymin], [xmin, ymin], [xmin, ymax]])]}\n                )\n                pov_df = pov_df.select(geometry=st.from_shapely(\"polygon\"))\n                map_df = map_df.with_columns(\n                    pl.col(\"geometry\").st.intersection(pl.lit(pov_df[\"geometry\"])),\n                )\n            self._plot_dict = {\"values\": map_df.st.to_dicts()}\n\n        c = (\n            alt.Chart(self._plot_dict)\n            .mark_geoshape(fillOpacity=0.4, filled=True if plot_polys else False)\n            .encode(\n                tooltip=[\n                    \"properties.idx:N\",\n                    \"properties.type:O\",\n                    \"properties.subtype:O\",\n                    \"properties.on_intersection:O\",\n                ],\n                color=(\n                    alt.when(alt.FieldEqualPredicate(equal=True, field=\"properties.on_intersection\"))\n                    .then(alt.value(\"black\"))\n                    .otherwise(alt.value(\"green\"))\n                ),\n            )\n        )\n        if recording is None:\n            return c.properties(title=\"Map\").project(\"identity\", reflectY=True)\n        else:\n            return c\n\n    def map_to_centerline_mcap(self, output_mcap_path: Path = None) -&gt; betterosi.GroundTruth:\n        \"\"\"\n        Convert an Map to a MapOsiCenterline and save it as an MCAP file if the output path is provided.\n        It returns the generated GroundTruth object from the generated MapOsiCenterline.\n\n        Args:\n            output_mcap_path: Path where the MCAP file will be saved\n        Returns:\n            betterosi.GroundTruth: The generated GroundTruth object\n        \"\"\"\n\n        # Create a mapping from XodrLaneId to a simple integer ID\n        lane_id_mapping = {}\n        for idx, lane_idx in enumerate(self.lanes.keys()):\n            lane_id_mapping[lane_idx] = idx\n\n        # Create betterosi.Lane objects for each lane\n        osi_lanes = []\n        for lane in self.lanes.values():\n            if not lane.centerline.is_valid or lane.centerline.is_empty:\n                logging.warning(f\"Warning: Skipping invalid lane {lane.idx}\")\n                continue\n\n            # Check for NaN/inf coordinates\n            coords = np.array(lane.centerline.coords)\n            if not np.isfinite(coords).all():\n                logging.warning(f\"Warning: Lane {lane.idx} has non-finite coordinates, skipping\")\n                continue\n\n            if len(coords) &lt; 2:\n                logging.warning(f\"Warning: Lane {lane.idx} has insufficient points, skipping\")\n                continue\n            # Get centerline coordinates\n            centerline_coords = list(shapely.simplify(lane.centerline, 0.1).coords)\n            if not len(centerline_coords) &gt; 1:\n                centerline_coords = list(lane.centerline.coords)\n                if not len(centerline_coords) &gt; 1:\n                    # skip lanes with insufficient centerline points\n                    logging.warning(f\"Warning: Skipping lane {lane.idx} due to insufficient centerline points\")\n                    continue\n\n            centerline = [betterosi.Vector3D(x=float(x), y=float(y), z=0.0) for x, y in centerline_coords]\n\n            assert len(centerline_coords) &gt; 1\n            # Create lane pairing for successor/predecessor relationships\n            lane_pairings = []\n\n            # Get all unique combinations of predecessors and successors\n            predecessors = [pred_id for pred_id in lane.predecessor_ids if pred_id in lane_id_mapping]\n            successors = [succ_id for succ_id in lane.successor_ids if succ_id in lane_id_mapping]\n\n            # If there are no predecessors or successors, create a single pairing with None values\n            if predecessors or successors:\n                # Create pairings for all combinations\n                if not predecessors:\n                    predecessors = [None]\n                if not successors:\n                    successors = [None]\n\n                for pred_id in predecessors:\n                    for succ_id in successors:\n                        lane_pairings.append(\n                            betterosi.LaneClassificationLanePairing(\n                                antecessor_lane_id=betterosi.Identifier(value=lane_id_mapping[pred_id])\n                                if pred_id is not None\n                                else None,\n                                successor_lane_id=betterosi.Identifier(value=lane_id_mapping[succ_id])\n                                if succ_id is not None\n                                else None,\n                            )\n                        )\n\n            # Create the OSI lane\n            osi_lane = betterosi.Lane(\n                id=betterosi.Identifier(value=lane_id_mapping[lane.idx]),\n                classification=betterosi.LaneClassification(\n                    centerline=centerline,\n                    centerline_is_driving_direction=True,\n                    type=lane.type,\n                    subtype=lane.subtype,\n                    lane_pairing=lane_pairings,\n                ),\n            )\n            osi_lanes.append(osi_lane)\n\n        # Create a GroundTruth with only the lanes (no moving objects, no lane boundaries)\n        ground_truth = betterosi.GroundTruth(\n            version=betterosi.InterfaceVersion(\n                version_major=3,\n                version_minor=7,\n                version_patch=0,\n            ),\n            timestamp=betterosi.Timestamp(\n                seconds=0,\n                nanos=0,\n            ),\n            lane=osi_lanes,\n        )\n\n        # Save to MCAP file if output path is provided\n        if output_mcap_path is None:\n            logging.warning(\"No output path provided for MCAP file\")\n        else:\n            # Convert string to Path if needed\n            output_mcap_path = Path(output_mcap_path)\n\n            if output_mcap_path.is_dir():\n                output_mcap_path = output_mcap_path / \"map_to_centerline.mcap\"\n            elif not output_mcap_path.suffix == \".mcap\":\n                logging.warning(f\"Output path must be a directory or .mcap file: {output_mcap_path}\")\n                return ground_truth\n\n            with betterosi.Writer(output_mcap_path) as writer:\n                writer.add(ground_truth, topic=\"ground_truth_map\", log_time=0)\n            logging.info(f\"Successfully saved map with {len(osi_lanes)} lanes to {output_mcap_path}\")\n\n        return ground_truth\n\n    def align_predecessor_and_successor_relations(self):\n        \"\"\"\n        Ensure that predecessor and successor relationships between lanes are consistent.\n        If lane A lists lane B as a successor, then lane B should list lane A as a predecessor, and vice versa.\n        \"\"\"\n        for lane in self.lanes.values():\n            for succ_id in lane.successor_ids:\n                if succ_id in self.lanes:\n                    succ_lane = self.lanes[succ_id]\n                    if lane.idx not in succ_lane.predecessor_ids:\n                        succ_lane.predecessor_ids.append(lane.idx)\n            for pred_id in lane.predecessor_ids:\n                if pred_id in self.lanes:\n                    pred_lane = self.lanes[pred_id]\n                    if lane.idx not in pred_lane.successor_ids:\n                        pred_lane.successor_ids.append(lane.idx)\n\n    @classmethod\n    def create(cls, *args, **kwargs):\n        raise NotImplementedError()\n\n    def __post_init__(self):\n        self.setup_lanes_and_boundaries()\n\n    def setup_lanes_and_boundaries(self):\n        raise NotImplementedError()\n\n    def _to_binary_json(self):\n        raise NotImplementedError()\n\n    @classmethod\n    def _from_binary_json(cls, d, **kwargs):\n        raise NotImplementedError()\n</code></pre>"},{"location":"api/#omega_prime.map.Map.align_predecessor_and_successor_relations","title":"<code>align_predecessor_and_successor_relations()</code>","text":"<p>Ensure that predecessor and successor relationships between lanes are consistent. If lane A lists lane B as a successor, then lane B should list lane A as a predecessor, and vice versa.</p> Source code in <code>omega_prime/map.py</code> <pre><code>def align_predecessor_and_successor_relations(self):\n    \"\"\"\n    Ensure that predecessor and successor relationships between lanes are consistent.\n    If lane A lists lane B as a successor, then lane B should list lane A as a predecessor, and vice versa.\n    \"\"\"\n    for lane in self.lanes.values():\n        for succ_id in lane.successor_ids:\n            if succ_id in self.lanes:\n                succ_lane = self.lanes[succ_id]\n                if lane.idx not in succ_lane.predecessor_ids:\n                    succ_lane.predecessor_ids.append(lane.idx)\n        for pred_id in lane.predecessor_ids:\n            if pred_id in self.lanes:\n                pred_lane = self.lanes[pred_id]\n                if lane.idx not in pred_lane.successor_ids:\n                    pred_lane.successor_ids.append(lane.idx)\n</code></pre>"},{"location":"api/#omega_prime.map.Map.from_file","title":"<code>from_file(filepath, parse_map=True, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a Map instance from a file.</p> Source code in <code>omega_prime/map.py</code> <pre><code>@classmethod\ndef from_file(cls, filepath, parse_map=True, **kwargs):\n    \"Create a Map instance from a file.\"\n    first_gt = next(betterosi.read(filepath, return_ground_truth=True, mcap_return_betterosi=True))\n    return cls.create(first_gt, **kwargs)\n</code></pre>"},{"location":"api/#omega_prime.map.Map.map_to_centerline_mcap","title":"<code>map_to_centerline_mcap(output_mcap_path=None)</code>","text":"<p>Convert an Map to a MapOsiCenterline and save it as an MCAP file if the output path is provided. It returns the generated GroundTruth object from the generated MapOsiCenterline.</p> <p>Parameters:</p> Name Type Description Default <code>output_mcap_path</code> <code>Path</code> <p>Path where the MCAP file will be saved</p> <code>None</code> <p>Returns:     betterosi.GroundTruth: The generated GroundTruth object</p> Source code in <code>omega_prime/map.py</code> <pre><code>def map_to_centerline_mcap(self, output_mcap_path: Path = None) -&gt; betterosi.GroundTruth:\n    \"\"\"\n    Convert an Map to a MapOsiCenterline and save it as an MCAP file if the output path is provided.\n    It returns the generated GroundTruth object from the generated MapOsiCenterline.\n\n    Args:\n        output_mcap_path: Path where the MCAP file will be saved\n    Returns:\n        betterosi.GroundTruth: The generated GroundTruth object\n    \"\"\"\n\n    # Create a mapping from XodrLaneId to a simple integer ID\n    lane_id_mapping = {}\n    for idx, lane_idx in enumerate(self.lanes.keys()):\n        lane_id_mapping[lane_idx] = idx\n\n    # Create betterosi.Lane objects for each lane\n    osi_lanes = []\n    for lane in self.lanes.values():\n        if not lane.centerline.is_valid or lane.centerline.is_empty:\n            logging.warning(f\"Warning: Skipping invalid lane {lane.idx}\")\n            continue\n\n        # Check for NaN/inf coordinates\n        coords = np.array(lane.centerline.coords)\n        if not np.isfinite(coords).all():\n            logging.warning(f\"Warning: Lane {lane.idx} has non-finite coordinates, skipping\")\n            continue\n\n        if len(coords) &lt; 2:\n            logging.warning(f\"Warning: Lane {lane.idx} has insufficient points, skipping\")\n            continue\n        # Get centerline coordinates\n        centerline_coords = list(shapely.simplify(lane.centerline, 0.1).coords)\n        if not len(centerline_coords) &gt; 1:\n            centerline_coords = list(lane.centerline.coords)\n            if not len(centerline_coords) &gt; 1:\n                # skip lanes with insufficient centerline points\n                logging.warning(f\"Warning: Skipping lane {lane.idx} due to insufficient centerline points\")\n                continue\n\n        centerline = [betterosi.Vector3D(x=float(x), y=float(y), z=0.0) for x, y in centerline_coords]\n\n        assert len(centerline_coords) &gt; 1\n        # Create lane pairing for successor/predecessor relationships\n        lane_pairings = []\n\n        # Get all unique combinations of predecessors and successors\n        predecessors = [pred_id for pred_id in lane.predecessor_ids if pred_id in lane_id_mapping]\n        successors = [succ_id for succ_id in lane.successor_ids if succ_id in lane_id_mapping]\n\n        # If there are no predecessors or successors, create a single pairing with None values\n        if predecessors or successors:\n            # Create pairings for all combinations\n            if not predecessors:\n                predecessors = [None]\n            if not successors:\n                successors = [None]\n\n            for pred_id in predecessors:\n                for succ_id in successors:\n                    lane_pairings.append(\n                        betterosi.LaneClassificationLanePairing(\n                            antecessor_lane_id=betterosi.Identifier(value=lane_id_mapping[pred_id])\n                            if pred_id is not None\n                            else None,\n                            successor_lane_id=betterosi.Identifier(value=lane_id_mapping[succ_id])\n                            if succ_id is not None\n                            else None,\n                        )\n                    )\n\n        # Create the OSI lane\n        osi_lane = betterosi.Lane(\n            id=betterosi.Identifier(value=lane_id_mapping[lane.idx]),\n            classification=betterosi.LaneClassification(\n                centerline=centerline,\n                centerline_is_driving_direction=True,\n                type=lane.type,\n                subtype=lane.subtype,\n                lane_pairing=lane_pairings,\n            ),\n        )\n        osi_lanes.append(osi_lane)\n\n    # Create a GroundTruth with only the lanes (no moving objects, no lane boundaries)\n    ground_truth = betterosi.GroundTruth(\n        version=betterosi.InterfaceVersion(\n            version_major=3,\n            version_minor=7,\n            version_patch=0,\n        ),\n        timestamp=betterosi.Timestamp(\n            seconds=0,\n            nanos=0,\n        ),\n        lane=osi_lanes,\n    )\n\n    # Save to MCAP file if output path is provided\n    if output_mcap_path is None:\n        logging.warning(\"No output path provided for MCAP file\")\n    else:\n        # Convert string to Path if needed\n        output_mcap_path = Path(output_mcap_path)\n\n        if output_mcap_path.is_dir():\n            output_mcap_path = output_mcap_path / \"map_to_centerline.mcap\"\n        elif not output_mcap_path.suffix == \".mcap\":\n            logging.warning(f\"Output path must be a directory or .mcap file: {output_mcap_path}\")\n            return ground_truth\n\n        with betterosi.Writer(output_mcap_path) as writer:\n            writer.add(ground_truth, topic=\"ground_truth_map\", log_time=0)\n        logging.info(f\"Successfully saved map with {len(osi_lanes)} lanes to {output_mcap_path}\")\n\n    return ground_truth\n</code></pre>"},{"location":"api/#omega_prime.map.MapOsi","title":"<code>MapOsi</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Map</code></p> <p>Map representation based on ASAM OSI GroundTruth</p> Source code in <code>omega_prime/map.py</code> <pre><code>@dataclass(repr=False)\nclass MapOsi(Map):\n    \"Map representation based on ASAM OSI GroundTruth\"\n\n    _osi: betterosi.GroundTruth\n\n    @classmethod\n    def create(cls, gt: betterosi.GroundTruth):\n        if len(gt.lane_boundary) == 0:\n            raise RuntimeError(\"Empty Map\")\n        return cls(\n            _osi=gt,\n            lane_boundaries={b.id.value: LaneBoundaryOsi.create(b) for b in gt.lane_boundary},\n            lanes={\n                l.idx: l\n                for l in [LaneOsi.create(l) for l in gt.lane if len(l.classification.right_lane_boundary_id) &gt; 0]\n            },\n        )\n\n    def __post_init__(self):\n        self.setup_lanes_and_boundaries()\n\n    def setup_lanes_and_boundaries(self):\n        for b in self.lane_boundaries.values():\n            b._map = self\n        map_osi_id2idx = {l._osi.id.value: l.idx for l in self.lanes.values()}\n        for l in self.lanes.values():\n            l.successor_ids = [map_osi_id2idx[i] for i in l.successor_ids if i in map_osi_id2idx]\n            l.predecessor_ids = [map_osi_id2idx[i] for i in l.predecessor_ids if i in map_osi_id2idx]\n            l._map = self\n            l.set_boundaries()\n            l.set_polygon()\n\n    def _to_binary_json(self):\n        d = json.loads(self._osi.to_json())\n        if \"movingObject\" in d:\n            del d[\"movingObject\"]\n        return {b\"osi\": json.dumps(d).encode()}\n\n    @classmethod\n    def _from_binary_json(cls, d, **kwargs):\n        gt = betterosi.GroundTruth().from_json(d[b\"osi\"].decode())\n        if len(gt.lane_boundary) &gt; 0:\n            return cls.create(gt)\n        else:\n            return None\n</code></pre>"},{"location":"api/#omega_prime.map.MapOsiCenterline","title":"<code>MapOsiCenterline</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Map</code></p> <p>Map representation based on ASAM OSI GroundTruth defining only the centerlines of lanes and nothing else. Does not conform to the omega-prime specification for Map.</p> Source code in <code>omega_prime/map.py</code> <pre><code>@dataclass(repr=False)\nclass MapOsiCenterline(Map):\n    \"Map representation based on ASAM OSI GroundTruth defining only the centerlines of lanes and nothing else. Does not conform to the omega-prime specification for Map.\"\n\n    _osi: betterosi.GroundTruth\n    lanes: dict[int, LaneOsiCenterline]\n\n    @classmethod\n    def create(cls, gt: betterosi.GroundTruth, split_lanes: bool = False, split_lanes_length: float = 10, **kwargs):\n        if len(gt.lane) == 0:\n            raise RuntimeError(\"No Map\")\n        c = cls(\n            _osi=gt,\n            lanes={l.idx: l for l in [LaneOsiCenterline.create(l) for l in gt.lane]},\n            lane_boundaries={},\n        )\n        if split_lanes:\n            c._split(split_lanes_length)\n        return c\n\n    def setup_lanes_and_boundaries(self):\n        map_osi_id2idx = {l._osi.id.value: l.idx for l in self.lanes.values()}\n        for l in self.lanes.values():\n            l.successor_ids = [map_osi_id2idx[int(i)] for i in l.successor_ids if int(i) in map_osi_id2idx]\n            l.predecessor_ids = [map_osi_id2idx[int(i)] for i in l.predecessor_ids if int(i) in map_osi_id2idx]\n        for l in self.lanes.values():\n            l._map = self\n\n        # Sometimes a presuccessor lane is not set as a successor lane in the other lane, therefore we need to check where this is the case and add it\n        self.align_predecessor_and_successor_relations()\n\n    def _split(self, max_len: float):\n        \"\"\"\n        Split lanes into segments of maximum length.\n\n        This method post-processes the map by splitting lane centerlines that exceed\n        the specified maximum length into smaller segments. It updates lane connections\n        accordingly and removes connections between segments that are too far apart.\n\n        Args:\n            max_len (float): Maximum length allowed for each lane segment.\n        \"\"\"\n        warn(\"The Postprocessing is ACTIVE! The lanes will be split into segments!!!\")\n        lanes_or = self.lanes\n        lanes_new = {}\n        idx_count = 0\n\n        for lane in tqdm(lanes_or.values()):\n            if lane.centerline.length &gt; max_len:\n                # Split the lane's centerline into segments of maximum length\n                segments = split_linestring(lane.centerline, max_len)\n            else:\n                segments = [lane.centerline]\n\n            # Create new lane objects for each segment\n            segment_lanes = []\n            for i, segment in enumerate(segments):\n                # Create a copy of the lane with modified centerline\n                # new_lane = copy.deepcopy(lane)\n\n                new_lane = LaneOsiCenterline(\n                    _osi=lane._osi,\n                    idx=OsiLaneId(road_id=idx_count, lane_id=idx_count),\n                    centerline=segment,\n                    type=lane.type,\n                    subtype=lane.subtype,\n                    successor_ids=[],\n                    predecessor_ids=[],\n                )\n\n                segment_lanes.append(new_lane)\n                lanes_new[new_lane.idx.lane_id] = new_lane\n                idx_count += 1\n\n            for i, new_lane in enumerate(segment_lanes):\n                if len(segments) == 1:\n                    # If only one segment, keep original predecessors and successors\n                    new_lane.predecessor_ids = lane.predecessor_ids\n                    new_lane.successor_ids = lane.successor_ids\n                elif i == 0:\n                    # First segment: keep original predecessors, connect to next segment\n                    new_lane.predecessor_ids = lane.predecessor_ids\n                    new_lane.successor_ids = [segment_lanes[i + 1].idx]\n                elif i == len(segments) - 1:\n                    # Last segment: connect to previous segment, keep original successors\n                    new_lane.predecessor_ids = [segment_lanes[i - 1].idx]\n                    new_lane.successor_ids = lane.successor_ids\n                else:\n                    # Middle segments: connect to both neighbors\n                    new_lane.predecessor_ids = [segment_lanes[i - 1].idx]\n                    new_lane.successor_ids = [segment_lanes[i + 1].idx]\n\n            # Update references in other lanes' predecessors/successors\n            for other_lane in lanes_or.values():\n                if lane.idx in other_lane.successor_ids:\n                    # Replace reference to original lane with first segment\n                    idx = other_lane.successor_ids.index(lane.idx)\n                    other_lane.successor_ids[idx] = segment_lanes[0].idx\n                if lane.idx in other_lane.predecessor_ids:\n                    # Replace reference to original lane with last segment\n                    idx = other_lane.predecessor_ids.index(lane.idx)\n                    other_lane.predecessor_ids[idx] = segment_lanes[-1].idx\n\n        # Replace original lanes with segmented lanes\n\n        # Do a check for the predecessor and successor: Check if the distance between the centerlines is greater than the max_len --&gt; if yes, then remove the connection\n        for lane in lanes_new.values():\n            if lane.predecessor_ids:\n                for pre in lane.predecessor_ids:\n                    pre_to_remove = []\n                    if lanes_new[pre.lane_id].centerline.distance(lane.centerline) &gt; max_len:\n                        pre_to_remove.append(pre)\n                        try:\n                            lanes_new[pre.lane_id].successor_ids.remove(lane.idx)\n                        except ValueError:\n                            pass  # If the successor is not in the list, ignore\n\n                    for pre in pre_to_remove:\n                        try:\n                            lanes_new[lane.idx.lane_id].predecessor_ids.remove(pre)\n                        except ValueError:\n                            pass  # If the predecessor is not in the list, ignore\n            if lane.successor_ids:\n                for suc in lane.successor_ids:\n                    suc_to_remove = []\n                    if lanes_new[suc.lane_id].centerline.distance(lane.centerline) &gt; max_len:\n                        suc_to_remove.append(suc)\n                        try:\n                            lanes_new[suc.lane_id].predecessor_ids.remove(lane.idx)\n                        except ValueError:\n                            pass  # If the predecessor is not in the list, ignore\n\n                    for suc in suc_to_remove:\n                        try:\n                            lanes_new[lane.idx.lane_id].successor_ids.remove(suc)\n                        except ValueError:\n                            pass\n\n        self.lanes = {lane.idx: lane for lane in lanes_new.values()}\n        for lane in self.lanes.values():\n            lane._map = self\n        return self\n\n    def _to_binary_json(self):\n        d = json.loads(self._osi.to_json())\n        if \"movingObject\" in d:\n            del d[\"movingObject\"]\n        return {b\"osi\": json.dumps(d).encode()}\n\n    @classmethod\n    def _from_binary_json(cls, d, **kwargs):\n        gt = betterosi.GroundTruth().from_json(d[b\"osi\"].decode())\n        return cls.create(gt)\n</code></pre>"},{"location":"api/#omega_prime.map.split_linestring","title":"<code>split_linestring(line, max_length)</code>","text":"<p>Split a LineString into segments of maximum length.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <p>shapely LineString to split</p> required <code>max_length</code> <p>Maximum length of each segment</p> required <p>Returns:</p> Type Description <p>List of LineString segments</p> Source code in <code>omega_prime/map.py</code> <pre><code>def split_linestring(line, max_length):\n    \"\"\"\n    Split a LineString into segments of maximum length.\n\n    Args:\n        line: shapely LineString to split\n        max_length: Maximum length of each segment\n\n    Returns:\n        List of LineString segments\n    \"\"\"\n    segments = []\n\n    # If line is already short enough, return it as is\n    if line.length &lt;= max_length:\n        return [line]\n\n    # Number of segments needed\n    n_segments = int(np.ceil(line.length / max_length))\n\n    # Get evenly spaced points along the line\n    points = [line.interpolate(i / n_segments, normalized=True) for i in range(n_segments + 1)]\n\n    # Create line segments\n    for i in range(n_segments):\n        segment_coords = [points[i].coords[0], points[i + 1].coords[0]]\n        segments.append(shapely.LineString(segment_coords))\n\n    return segments\n</code></pre>"},{"location":"api/#omega_prime.map_odr.MapOdr","title":"<code>MapOdr</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Map</code></p> Source code in <code>omega_prime/map_odr.py</code> <pre><code>@dataclass(repr=False)\nclass MapOdr(Map):\n    odr_xml: str\n    name: str\n    step_size: float = 0.01\n    _xodr_map: PyxodrRoadNetwork | None = None\n    proj_string: str | None = None\n    proj_offset: ProjectionOffset | None = None\n    projection: pyproj.CRS | None = None\n    _supported_file_suffixes = [\".xodr\", \".mcap\", \".odr\"]\n    _binary_json_identifier = b\"xodr\"\n\n    @property\n    def xodr_map(self):\n        if self._xodr_map is None:\n            self.parse()\n        return self._xodr_map\n\n    @classmethod\n    def from_file(\n        cls,\n        filename,\n        topics: list[str] = [\"/ground_truth_map\", \"ground_truth_map\"],\n        parse_map: bool = False,\n        is_odr_xml: bool = False,\n        is_mcap: bool = False,\n        step_size=0.01,\n        ignored_lane_types: set[str] = set([]),\n        **kwargs,\n    ):\n        if Path(filename).suffix in [\".xodr\", \".odr\"] or is_odr_xml:\n            with open(filename) as f:\n                odr_xml = f.read()\n            return cls.create(\n                odr_xml=odr_xml,\n                name=Path(filename).stem,\n                step_size=step_size,\n                parse_map=parse_map,\n                ignored_lane_types=ignored_lane_types,\n            )\n        if Path(filename).suffix in [\".mcap\"] or is_mcap:\n            map = next(iter(betterosi.read(filename, mcap_topics=topics, mcap_return_betterosi=False)))\n            return cls.create(\n                odr_xml=map.open_drive_xml_content, name=map.map_reference, step_size=step_size, parse_map=parse_map\n            )\n\n    @property\n    def lanes(self):\n        if self._lanes is None:\n            self.parse()\n        return self._lanes\n\n    @lanes.setter\n    def lanes(self, val):\n        self._lanes = val\n\n    @property\n    def lane_boundaries(self):\n        if self._lane_boundaries is None:\n            self.parse()\n        return self._lane_boundaries\n\n    @lane_boundaries.setter\n    def lane_boundaries(self, val):\n        self._lane_boundaries = val\n\n    @classmethod\n    def create(cls, odr_xml, name, step_size=0.01, parse_map: bool = False, ignored_lane_types: set[str] = set([])):\n        self = cls(odr_xml=odr_xml, name=name, step_size=step_size, lanes={}, lane_boundaries={})\n        self._lane_boundaries = None\n        self._lanes = None\n        self.ignored_lane_types = ignored_lane_types\n        if parse_map:\n            self.parse()\n        return self\n\n    def parse(self):\n        rn = RoadNetwork(self.odr_xml, resolution=self.step_size, ignored_lane_types=self.ignored_lane_types)\n\n        lane_boundaries = {}\n        lanes = {}\n\n        # Extract projection information from XML tree\n        proj_string = None\n        proj_offset = None\n        projection = None\n\n        # Get the header element from XML\n        header = rn.tree.find(\"header\")\n        if header is not None:\n            # Get geoReference if it exists\n            geo_ref = header.find(\"geoReference\")\n            if geo_ref is not None and geo_ref.text:\n                proj_string = geo_ref.text.strip()\n                try:\n                    projection = pyproj.CRS.from_proj4(proj_string)\n                except pyproj.exceptions.CRSError as e:\n                    logger.warning(f\"Failed to parse projection string: {e}\")\n\n            # Get offset if it exists\n            offset = header.find(\"offset\")\n            if offset is not None:\n                try:\n                    proj_offset = ProjectionOffset(\n                        x=float(offset.get(\"x\", \"0\")),\n                        y=float(offset.get(\"y\", \"0\")),\n                        z=float(offset.get(\"z\", \"0\")),\n                        yaw=float(offset.get(\"hdg\", \"0\")),\n                    )\n                except (ValueError, TypeError) as e:\n                    logger.warning(f\"Failed to parse offset: {e}\")\n\n        for road in rn.get_roads():\n            lane_idx = 0\n            for lane_section_id, lane_section in enumerate(road.lane_sections):\n                for lane in lane_section.lanes:\n                    boundary_line = getattr(lane, \"boundary_line\", None)\n                    if boundary_line is None or not len(boundary_line):\n                        logger.warning(\n                            f\"Skipping road {road.id} / lane_section {lane_section_id} / lane {lane.id}: missing boundary_line\"\n                        )\n                        continue\n\n                    try:\n                        left_boundary = LaneBoundaryXodr.create(\n                            lane, road.id, lane.id, lane_section_id, \"left\", lane_idx=lane_idx\n                        )\n                        right_boundary = LaneBoundaryXodr.create(\n                            lane, road.id, lane.id, lane_section_id, \"right\", lane_idx=lane_idx\n                        )\n                    except Exception as e:\n                        logger.error(\n                            f\"Failed to create boundaries for road {road.id} / lane_section {lane_section_id} / lane {lane.id}: {e}\"\n                        )\n                        continue\n\n                    lane_boundaries[left_boundary.idx] = left_boundary\n                    lane_boundaries[right_boundary.idx] = right_boundary\n\n                    try:\n                        lane_obj = LaneXodr.create(lane, road, lane_section_id, lane_idx)\n                        lanes[lane_obj.idx] = lane_obj\n                    except Exception as e:\n                        logger.error(\n                            f\"Failed to create lane object for road {road.id} / lane_section {lane_section_id} / lane {lane.id}: {e}\"\n                        )\n\n                    lane_idx += 1\n\n        self._xodr_map = rn\n        self.lane_boundaries = lane_boundaries\n        self.lanes = lanes\n        self.proj_string = proj_string\n        self.proj_offset = proj_offset\n        self.projection = projection\n        for lane in self.lanes.values():\n            lane._map = self\n            lane._set_boundaries()\n            lane._set_polygon()\n        for b in self._lane_boundaries.values():\n            b._map = self\n\n        return self\n\n    def setup_lanes_and_boundaries(self):\n        pass\n\n    def to_file(self, filename: str | Path):\n        \"\"\"Export the current MapOdr to a .xodr file.\"\"\"\n        if isinstance(filename, str):\n            filename = Path(filename)\n\n        if filename.is_dir():\n            filename = filename / f\"{self.name}.xodr\"\n\n        if filename.suffix == \"\":\n            filename = filename.with_suffix(\".xodr\")\n\n        with open(filename, \"w\") as f:\n            f.write(self.odr_xml)\n\n    def to_osi(self):\n        return MapAsamOpenDrive(map_reference=self.name, open_drive_xml_content=self.odr_xml)\n\n    def _to_binary_json(self):\n        return {b\"xodr\": self.odr_xml.encode(), b\"xodr_name\": self.name.encode()}\n\n    @classmethod\n    def _from_binary_json(cls, d, parse_map: bool = False, step_size: float = 0.01):\n        return cls.create(\n            odr_xml=d[b\"xodr\"].decode(),\n            name=d[b\"xodr_name\"].decode(),\n            parse_map=parse_map,\n            step_size=step_size,\n        )\n</code></pre>"},{"location":"api/#omega_prime.map_odr.MapOdr.to_file","title":"<code>to_file(filename)</code>","text":"<p>Export the current MapOdr to a .xodr file.</p> Source code in <code>omega_prime/map_odr.py</code> <pre><code>def to_file(self, filename: str | Path):\n    \"\"\"Export the current MapOdr to a .xodr file.\"\"\"\n    if isinstance(filename, str):\n        filename = Path(filename)\n\n    if filename.is_dir():\n        filename = filename / f\"{self.name}.xodr\"\n\n    if filename.suffix == \"\":\n        filename = filename.with_suffix(\".xodr\")\n\n    with open(filename, \"w\") as f:\n        f.write(self.odr_xml)\n</code></pre>"},{"location":"api/#omega_prime.locator.Locator","title":"<code>Locator</code>  <code>dataclass</code>","text":"Source code in <code>omega_prime/locator.py</code> <pre><code>@dataclass(repr=False)\nclass Locator:\n    all_lanes: Any  # array of all lanes\n    external2internal_laneid: dict[Any, int] = field(init=False)\n    internal2external_laneid: list[Any] = field(init=False)\n    lane_point_distances: list = field(init=False)\n    str_tree: shapely.STRtree = field(init=False)\n    extended_centerlines: list[shapely.LineString] = field(init=False)\n\n    g: nx.DiGraph = field(init=False)  # Lane Relation Graph\n\n    @classmethod\n    def from_map(cls, map):\n        all_lanes = list(map.lanes.values())\n        return cls(all_lanes=all_lanes)\n\n    def __post_init__(self):\n        # Create mapping with lane_id as key\n        self.external2internal_laneid = {l.idx: i for i, l in enumerate(self.all_lanes)}\n        self.internal2external_laneid = [l.idx for l in self.all_lanes]\n\n        self.extended_centerlines = [ShapelyTrajectoryTools.extend_linestring(l.centerline) for l in self.all_lanes]\n        if hasattr(self.all_lanes[0], \"polygon\") and self.all_lanes[0].polygon is not None:\n            self.str_tree = shapely.STRtree([l.polygon for l in self.all_lanes])\n        else:\n            self.str_tree = shapely.STRtree([l.centerline for l in self.all_lanes])\n        self.lane_point_distances = [\n            np.unique(shapely.line_locate_point(cl, shapely.points(cl.coords))) for cl in self.extended_centerlines\n        ]\n        self.g = self._get_routing_graph()\n\n    def get_route(self, start_id, end_id):\n        return nx.shortest_path(self.g, start_id, end_id)\n\n    def sts2xys(self, sts):\n        xys = np.zeros((len(sts.s), 2), dtype=float) * np.nan\n        l_ids = np.array([self.external2internal_laneid[i] for i in sts.roadlane_id.values])\n        for l_id in set(l_ids):\n            point_idxs = np.argwhere(l_ids == l_id)[:, 0]\n            rel_sts = sts.isel(dict(time=point_idxs))\n            l = self.extended_centerlines[l_id]\n            xys[point_idxs, 0], xys[point_idxs, 1] = ShapelyTrajectoryTools.st2xy(\n                l, rel_sts.s.values + ShapelyTrajectoryTools.l_append, rel_sts.t.values\n            )\n        return xys\n\n    def xys2sts(self, xys, polygons=None):\n        if isinstance(xys, np.ndarray) and xys.ndim == 2:\n            assert xys.shape[1] == 2\n            xys = shapely.points(xys)\n        lat_distances, lon_distances = self._xys2sts(xys, polygons)\n        single_lane_association = self.get_single_lane_association(lat_distances)\n        sla = np.zeros(len(single_lane_association), dtype=tuple)\n        for i, v in enumerate(single_lane_association):\n            sla[i] = v\n        sts = xr.Dataset(\n            {\n                \"s\": (\"time\", [lon_distances[lidx][i] for i, lidx in enumerate(single_lane_association)]),\n                \"t\": (\"time\", [lat_distances[lidx][i] for i, lidx in enumerate(single_lane_association)]),\n                \"roadlane_id\": (\"time\", sla),\n            }\n        )\n        return sts\n\n    def xys2lane_sts(self, lane_id, xys, internal_id=False):\n        # xys should be an array of shapely objects or an array of points with dim (n_points, 2)\n        # return (n_points, 2) where ret[:,0] is s and ret[:,1] is t\n        if isinstance(xys, np.ndarray) and xys.ndim == 2:\n            assert xys.shape[1] == 2\n            xys = shapely.points(xys)\n        lid = self.external2internal_laneid[lane_id] if not internal_id else lane_id\n        lane_point_distances = self.lane_point_distances[lid]\n        sts = ShapelyTrajectoryTools.xy2st(\n            self.extended_centerlines[lid], x_or_xy=xys, line_point_distances=lane_point_distances\n        )\n        sts[:, 0] -= ShapelyTrajectoryTools.l_append\n        return sts\n\n    def _xys2sts(self, xys, polygons=None):\n        # xys should be an array of shapely objects or an array of points with dim (n_points, 2)\n        if isinstance(xys, np.ndarray) and xys.ndim == 2:\n            assert xys.shape[1] == 2\n            xys = shapely.points(xys)\n        else:\n            xys = np.array(xys)\n        if polygons is None:\n            polygons = xys\n        lon_distances = defaultdict(lambda: np.nan * np.ones((len(xys),)))\n        lat_distances = defaultdict(lambda: np.nan * np.ones((len(xys),)))\n        point_idxs, intersection_lane_ids = self.str_tree.query(polygons, predicate=\"intersects\")\n        for l_id in set(intersection_lane_ids):\n            lps = point_idxs[intersection_lane_ids == l_id]\n            (\n                lon_distances[self.internal2external_laneid[l_id]][lps],\n                lat_distances[self.internal2external_laneid[l_id]][lps],\n            ) = self.xys2lane_sts(l_id, xys[lps], internal_id=True).T\n        try:\n            no_associations = np.where(np.all(np.isnan(np.stack(list(lon_distances.values()))), axis=0))[0]\n        except ValueError:\n            # no arrays to stack\n            no_associations = np.arange(len(xys))\n        if hasattr(self.all_lanes[0], \"polygon\") and self.all_lanes[0].polygon is not None:\n            no_asscociation_idxs, intersection_lane_ids = self.str_tree.query_nearest(polygons[no_associations])\n        else:\n            # Create an empty numpy array for no_asscociation_idxs\n            no_asscociation_idxs = np.array([])\n            intersection_lane_ids = np.array([])\n            if len(no_associations) &gt; 0:\n                for idx, poly in enumerate(polygons[no_associations]):\n                    # Returns the indxes of all centerlines that are in range\n                    nearby_idx = self.query_centerlines(poly, range_percentage=0.1)\n                    # Connect the no_assosciation_idxs with the intersection_lane_ids\n                    no_asscociation_idxs = np.append(no_asscociation_idxs, [idx] * len(nearby_idx))\n                    intersection_lane_ids = np.append(intersection_lane_ids, nearby_idx)\n\n        # Need a convertion from float values to int values. This is because the shapely STRtree query_nearest returns float values\n        no_asscociation_idxs = no_asscociation_idxs.astype(int)\n        intersection_lane_ids = intersection_lane_ids.astype(int)\n        for l_id in set(intersection_lane_ids):\n            lps = no_associations[no_asscociation_idxs[intersection_lane_ids == l_id]]\n            (\n                lon_distances[self.internal2external_laneid[l_id]][lps],\n                lat_distances[self.internal2external_laneid[l_id]][lps],\n            ) = self.xys2lane_sts(l_id, xys[lps], internal_id=True).T\n\n        no_asscociation_new = np.where(np.all(np.isnan(np.stack(list(lon_distances.values()))), axis=0))[0]\n\n        assert len(no_asscociation_new) == 0\n        return lat_distances, lon_distances\n\n    def locate_mv(self, mv, use_polygon: bool = False):\n        mv.polygon\n        moving = mv._df.filter(pl.any_horizontal((pl.col(\"x\", \"y\").diff() != 0).fill_null(True)).alias(\"is_moving\"))[\n            \"total_nanos\", \"x\", \"y\", \"polygon\"\n        ]\n        xrd = (\n            self.xys2sts(moving[\"x\", \"y\"].to_numpy(), polygons=moving[\"polygon\"] if use_polygon else None)\n            .assign_coords({\"time\": moving[\"total_nanos\"].to_numpy()})\n            .set_coords(\"time\")\n        )\n        if moving.height &lt; mv._df.height:\n            xrd = xrd.sel({\"time\": mv._df[\"total_nanos\"].to_numpy()}, method=\"ffill\", drop=True)\n            xrd[\"time\"] = mv._df[\"total_nanos\"].to_numpy()\n        return xrd\n\n    def query_centerlines(self, point, range_percentage=0.1):\n        \"\"\"\n        Query the nearest centerline and all centerlines within a range percentage.\n\n        :param point: A shapely Point object representing the query location.\n        :param range_percentage: The range as a percentage of the total length of the nearest centerline. Default is 0.1 (10%).\n        :return: A NDArray with all the Lane Idx in the Range.\n        \"\"\"\n        # Query the nearest centerline\n        nearest_idx = self.str_tree.query_nearest(point)\n        nearest_centerline = self.extended_centerlines[nearest_idx[0]]\n\n        # Calculate the range based on the nearest centerline's length\n        range_distance = nearest_centerline.distance(point) * (1 + range_percentage)\n\n        # Create a buffer around the point\n        buffer = point.buffer(range_distance)\n\n        # Query all centerlines within the buffer\n        nearby_idxs = self.str_tree.query(buffer, predicate=\"intersects\")\n\n        # If there was no intersection, return the nearest centerline\n        if nearby_idxs.size == 0:\n            return nearest_idx\n\n        return nearby_idxs\n\n    def _get_routing_graph(self):\n        all_lanes = self.all_lanes\n        str_tree = self.str_tree\n        external2internal_laneid = self.external2internal_laneid\n        g = nx.DiGraph()\n        for lid, lane in enumerate(all_lanes):\n            g.add_node(lid, lane=lane)\n            for external_pid in lane.predecessor_ids:\n                try:\n                    g.add_edge(lid, external2internal_laneid[external_pid], label=LaneRelation.predecessor)\n                except KeyError:\n                    pass\n            for external_sid in lane.successor_ids:\n                try:\n                    g.add_edge(lid, external2internal_laneid[external_sid], label=LaneRelation.successor)\n                except KeyError:\n                    pass\n            if lane.right_boundary is None or lane.left_boundary is None:\n                continue\n            right_neigbours = [\n                int(i) for i in str_tree.query(lane.right_boundary.polyline, predicate=\"covered_by\") if int(i) != lid\n            ]\n            left_neigbours = [\n                int(i) for i in str_tree.query(lane.left_boundary.polyline, predicate=\"covered_by\") if int(i) != lid\n            ]\n            for rn in right_neigbours:\n                g.add_edge(lid, rn, label=LaneRelation.neighbour_right)\n            for ln in left_neigbours:\n                g.add_edge(lid, ln, label=LaneRelation.neighbour_left)\n        return g\n\n    def get_single_lane_association(\n        self, traveler_lane_intersections: dict[Any, Any], overlaps: None | dict[Any, float] = None\n    ):\n        \"\"\"\n        filter traveling path of traveler, so that traveler is not assigned to lanes that are only reachable through a merging or crossing relation\n        return format: road, lane\n        \"\"\"\n        import networkx as nx\n\n        g = nx.Graph()\n        nodes = defaultdict(list)\n        for external_lid, v in traveler_lane_intersections.items():\n            for timeidx in np.where(~np.isnan(v))[0]:\n                nodes[timeidx].append(self.external2internal_laneid[external_lid])\n        nodes_per_time = [nodes[i] for i in range(len(nodes))]\n        g.add_node(\"start\", pos=(-1, -1))\n        g.add_node(\"end\", pos=(len(nodes_per_time), -1))\n        for i, nodes_of_time in enumerate(nodes_per_time[:-1]):\n            for n in nodes_of_time:\n                for next_n in nodes_per_time[i + 1]:\n                    g.add_node((n, i), pos=(i, n))\n                    g.add_node((next_n, i + 1), pos=(i + 1, next_n))\n                    try:\n                        if n == next_n:\n                            if overlaps is None:\n                                weight = 1\n                            else:\n                                weight = 1 - overlaps[self.internal2external_laneid[n]][i + 1]\n                        elif any(\n                            [\n                                LaneRelation.neighbour_left in o or LaneRelation.neighbour_right in o\n                                for o in self.g.get_edge_data(n, next_n)[\"label\"]\n                                + self.g.get_edge_data(next_n, n)[\"label\"]\n                            ]\n                        ):\n                            weight = 2\n                        elif self.g.get_edge_data(n, next_n)[\"label\"] in [\n                            LaneRelation.predecessor,\n                            LaneRelation.successor,\n                        ] or self.g.get_edge_data(n, next_n)[\"label\"] in [\n                            LaneRelation.predecessor,\n                            LaneRelation.successor,\n                        ]:\n                            weight = 2\n                        else:\n                            weight = 3\n                    except Exception:\n                        weight = 4\n                    g.add_edge((n, i), (next_n, i + 1), weight=weight)\n        for n in nodes_per_time[0]:\n            g.add_edge(\"start\", (n, 0), weight=1)\n        for n in nodes_per_time[-1]:\n            g.add_edge((n, len(nodes_per_time) - 1), \"end\", weight=1)\n        sp = nx.shortest_path(g, \"start\", \"end\", weight=\"weight\")[1:-1]\n        fixed_traveler_path = [self.internal2external_laneid[o[0]] for o in sp]\n\n        overlaps = [traveler_lane_intersections[lid][i] for i, lid in enumerate(fixed_traveler_path)]\n        assert not np.any(np.isnan(overlaps))\n        return fixed_traveler_path\n\n    def __repr__(self):\n        return f\"Locator({len(self.all_lanes)} lanes)&lt;{id(self)}&gt;\"\n\n    def update_lane_ids_dict(self):\n        self.external2internal_laneid = {l.idx: i for i, l in enumerate(self.all_lanes)}\n        self.internal2external_laneid = [l.idx for l in self.all_lanes]\n</code></pre>"},{"location":"api/#omega_prime.locator.Locator.get_single_lane_association","title":"<code>get_single_lane_association(traveler_lane_intersections, overlaps=None)</code>","text":"<p>filter traveling path of traveler, so that traveler is not assigned to lanes that are only reachable through a merging or crossing relation return format: road, lane</p> Source code in <code>omega_prime/locator.py</code> <pre><code>def get_single_lane_association(\n    self, traveler_lane_intersections: dict[Any, Any], overlaps: None | dict[Any, float] = None\n):\n    \"\"\"\n    filter traveling path of traveler, so that traveler is not assigned to lanes that are only reachable through a merging or crossing relation\n    return format: road, lane\n    \"\"\"\n    import networkx as nx\n\n    g = nx.Graph()\n    nodes = defaultdict(list)\n    for external_lid, v in traveler_lane_intersections.items():\n        for timeidx in np.where(~np.isnan(v))[0]:\n            nodes[timeidx].append(self.external2internal_laneid[external_lid])\n    nodes_per_time = [nodes[i] for i in range(len(nodes))]\n    g.add_node(\"start\", pos=(-1, -1))\n    g.add_node(\"end\", pos=(len(nodes_per_time), -1))\n    for i, nodes_of_time in enumerate(nodes_per_time[:-1]):\n        for n in nodes_of_time:\n            for next_n in nodes_per_time[i + 1]:\n                g.add_node((n, i), pos=(i, n))\n                g.add_node((next_n, i + 1), pos=(i + 1, next_n))\n                try:\n                    if n == next_n:\n                        if overlaps is None:\n                            weight = 1\n                        else:\n                            weight = 1 - overlaps[self.internal2external_laneid[n]][i + 1]\n                    elif any(\n                        [\n                            LaneRelation.neighbour_left in o or LaneRelation.neighbour_right in o\n                            for o in self.g.get_edge_data(n, next_n)[\"label\"]\n                            + self.g.get_edge_data(next_n, n)[\"label\"]\n                        ]\n                    ):\n                        weight = 2\n                    elif self.g.get_edge_data(n, next_n)[\"label\"] in [\n                        LaneRelation.predecessor,\n                        LaneRelation.successor,\n                    ] or self.g.get_edge_data(n, next_n)[\"label\"] in [\n                        LaneRelation.predecessor,\n                        LaneRelation.successor,\n                    ]:\n                        weight = 2\n                    else:\n                        weight = 3\n                except Exception:\n                    weight = 4\n                g.add_edge((n, i), (next_n, i + 1), weight=weight)\n    for n in nodes_per_time[0]:\n        g.add_edge(\"start\", (n, 0), weight=1)\n    for n in nodes_per_time[-1]:\n        g.add_edge((n, len(nodes_per_time) - 1), \"end\", weight=1)\n    sp = nx.shortest_path(g, \"start\", \"end\", weight=\"weight\")[1:-1]\n    fixed_traveler_path = [self.internal2external_laneid[o[0]] for o in sp]\n\n    overlaps = [traveler_lane_intersections[lid][i] for i, lid in enumerate(fixed_traveler_path)]\n    assert not np.any(np.isnan(overlaps))\n    return fixed_traveler_path\n</code></pre>"},{"location":"api/#omega_prime.locator.Locator.query_centerlines","title":"<code>query_centerlines(point, range_percentage=0.1)</code>","text":"<p>Query the nearest centerline and all centerlines within a range percentage.</p> <p>:param point: A shapely Point object representing the query location. :param range_percentage: The range as a percentage of the total length of the nearest centerline. Default is 0.1 (10%). :return: A NDArray with all the Lane Idx in the Range.</p> Source code in <code>omega_prime/locator.py</code> <pre><code>def query_centerlines(self, point, range_percentage=0.1):\n    \"\"\"\n    Query the nearest centerline and all centerlines within a range percentage.\n\n    :param point: A shapely Point object representing the query location.\n    :param range_percentage: The range as a percentage of the total length of the nearest centerline. Default is 0.1 (10%).\n    :return: A NDArray with all the Lane Idx in the Range.\n    \"\"\"\n    # Query the nearest centerline\n    nearest_idx = self.str_tree.query_nearest(point)\n    nearest_centerline = self.extended_centerlines[nearest_idx[0]]\n\n    # Calculate the range based on the nearest centerline's length\n    range_distance = nearest_centerline.distance(point) * (1 + range_percentage)\n\n    # Create a buffer around the point\n    buffer = point.buffer(range_distance)\n\n    # Query all centerlines within the buffer\n    nearby_idxs = self.str_tree.query(buffer, predicate=\"intersects\")\n\n    # If there was no intersection, return the nearest centerline\n    if nearby_idxs.size == 0:\n        return nearest_idx\n\n    return nearby_idxs\n</code></pre>"},{"location":"api/#omega_prime.locator.get_lane_centerline","title":"<code>get_lane_centerline(right_border, left_border)</code>","text":"<p>middle line between (interpolated) boundaries, oriented in direction of lane</p> Source code in <code>omega_prime/locator.py</code> <pre><code>def get_lane_centerline(right_border: shapely.LineString, left_border: shapely.LineString) -&gt; shapely.LineString:\n    \"\"\"middle line between (interpolated) boundaries, oriented in direction of lane\"\"\"\n    ses = np.unique(\n        np.concatenate(\n            [\n                shapely.line_locate_point(left_border, shapely.points(right_border.coords), normalized=True),\n                shapely.line_locate_point(right_border, shapely.points(left_border.coords), normalized=True),\n            ]\n        )\n    )\n\n    points = np.zeros((len(ses), 2))\n    for i, (rbp, lbp) in enumerate(\n        zip(right_border.interpolate(ses, normalized=True), left_border.interpolate(ses, normalized=True))\n    ):\n        points[i, :] = shapely.MultiPoint([rbp, lbp]).minimum_rotated_rectangle.centroid.coords\n\n    # TODO some smoothing operation could be helpful\n    cl = shapely.LineString(points)\n\n    if cl.is_empty or not cl.is_valid:\n        raise RuntimeError(\"Could not compute centerline for lane!\")\n    return cl\n</code></pre>"},{"location":"api/#omega_prime.converters.converter.DatasetConverter","title":"<code>DatasetConverter</code>","text":"<p>               Bases: <code>ABC</code></p> Source code in <code>omega_prime/converters/converter.py</code> <pre><code>class DatasetConverter(ABC):\n    def __init__(self, dataset_path: str, out_path: str = \"./\", n_workers=1) -&gt; None:\n        self._dataset_path = Path(dataset_path)\n        self._out_path = Path(out_path)\n        self.n_workers = n_workers\n        self.len = None\n\n    @abstractmethod\n    def get_source_recordings(self) -&gt; list:\n        \"\"\"\n        Abstract method to get a list of the source recordings.\n        The method should be implemented in subclasses to handle specific dataset formats.\n        Returns:\n            source_recordings: List of the source recordings. Could be of any type as further processed in get_recordings.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_recordings(self, source_recording) -&gt; Iterator:\n        \"\"\"\n        Abstract method to get all recordings in a source-recording-instance of the specific dataset.\n        The method should be implemented in subclasses to handle specific dataset formats.\n        Args:\n            source_recordings: List of the source recordings. Could be of any type as returned by get_source_recordings.\n        Yields:\n            recording: Each recording in the source-recording-instance, one at a time. Could be of any type as further processed in to_omega_prime_recording and get_recording_id.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def to_omega_prime_recording(self, recording) -&gt; Recording:\n        \"\"\"\n        Abstract method to convert a raw recording into an omega prime recording instance.\n        The method should be implemented in subclasses to handle specific dataset formats.\n        Args:\n            recording: A recording of any type as returned by get_omega_prime_recordings.\n        Returns:\n            Recording: An instance of the Recording class containing the processed data.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_recording_name(self, recording) -&gt; str:\n        \"\"\"\n        Abstract method to get the name for a given recording.\n        The method should be implemented in subclasses to handle specific dataset formats.\n        Args:\n            recording: Recording of any type as returned by get_recordings.\n        Returns:\n            str: unique name of recording.\n        \"\"\"\n        pass\n\n    def convert_source_recording(\n        self, source_recording, save_as_parquet: bool = False, skip_existing: bool = False, log_file: Path | None = None\n    ) -&gt; None:\n        try:\n            for recording in self.get_recordings(source_recording):\n                out_filename = (\n                    self._out_path / f\"{self.get_recording_name(recording)}.{'parquet' if save_as_parquet else 'mcap'}\"\n                )\n                status = Status(str(source_recording), str(out_filename))\n                if not skip_existing or not out_filename.exists():\n                    Path(out_filename).parent.mkdir(exist_ok=True, parents=True)\n                    try:\n                        rec = self.to_omega_prime_recording(recording)\n                        status.set_success()\n                    except Exception as e:\n                        logger.error(\n                            f\"Error converting recording {self.get_recording_name(recording)}: {traceback.format_exc()}\"\n                        )\n                        rec = None\n                        status.set_error(str(e))\n                    else:\n                        try:\n                            if save_as_parquet:\n                                rec.to_parquet(out_filename)\n                            else:\n                                rec.to_mcap(out_filename)\n                        except Exception as e:\n                            logger.error(\n                                f\"Error saving recording {self.get_recording_name(recording)}: {traceback.format_exc()}\"\n                            )\n                            status.set_error(e)\n                else:\n                    status.set_skip()\n\n                if log_file is not None:\n                    with FileLock(log_file.with_suffix(\".csv.lock\")):\n                        status.write(log_file)\n\n        except Exception as e:\n            logger.error(f\"Error processing source recording {source_recording}: {e} - {traceback.format_exc()}\")\n            raise e\n\n    def convert(\n        self,\n        n_workers: int | None = None,\n        save_as_parquet: bool = False,\n        skip_existing: bool = False,\n        write_log: bool = False,\n    ) -&gt; None:\n        if n_workers is None:\n            n_workers = self.n_workers\n        if n_workers == -1:\n            n_workers = jb.cpu_count() - 1\n        self._out_path.mkdir(exist_ok=True, parents=True)\n        recordings = self.get_source_recordings()\n\n        # Create a log file if requested\n        log_file = None\n        if write_log:\n            log_file = self._out_path / \"conversion_log.csv\"\n            with open(log_file, \"w\", newline=\"\") as csvfile:\n                fieldnames = [\"file_path_input\", \"status\", \"file_path_output\", \"error_message\"]\n                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n                writer.writeheader()\n        if self.len is None:\n            try:\n                self.len = len(recordings)\n            except TypeError:\n                pass\n        if n_workers &gt; 1:\n            partial_fct = partial(\n                self.convert_source_recording,\n                save_as_parquet=save_as_parquet,\n                skip_existing=skip_existing,\n                log_file=log_file,\n            )\n            with tqdm_joblib(desc=\"Source Recordings\", total=self.len):\n                jb.Parallel(n_jobs=n_workers)(jb.delayed(partial_fct)(rec) for rec in recordings)\n        else:\n            for rec in tqdm(recordings, total=self.len):\n                self.convert_source_recording(\n                    rec, save_as_parquet=save_as_parquet, skip_existing=skip_existing, log_file=log_file\n                )\n\n    def yield_recordings(self) -&gt; Iterator[Recording]:\n        source_recordings = self.get_source_recordings()\n        for sr in tqdm(source_recordings, total=len(source_recordings)):\n            for recording in self.get_recordings(sr):\n                yield self.to_omega_prime_recording(recording)\n\n    @classmethod\n    def convert_cli(\n        cls,\n        dataset_path: Annotated[\n            Path,\n            typer.Argument(exists=True, dir_okay=True, file_okay=True, readable=True, help=\"Root of the dataset\"),\n        ],\n        output_path: Annotated[\n            Path,\n            typer.Argument(\n                file_okay=False, writable=True, help=\"In which folder to write the created omega-prime files\"\n            ),\n        ],\n        n_workers: Annotated[int, typer.Option(help=\"Set to -1 for n_cpus-1 workers.\")] = 1,\n        save_as_parquet: Annotated[\n            bool,\n            typer.Option(\n                help=\"If activated, omega-prime recordings will be stored as parquet files instead of mcap (use for large recordings). Will loose information in OSI that are not mandatory in omega-prime.\"\n            ),\n        ] = False,\n        skip_existing: Annotated[bool, typer.Option(help=\"Only convert not yet converted files\")] = False,\n        write_log: Annotated[bool, typer.Option(help=\"Write a log file with the conversion process\")] = False,\n    ):\n        Path(output_path).mkdir(exist_ok=True)\n        cls(dataset_path=dataset_path, out_path=output_path, n_workers=n_workers).convert(\n            save_as_parquet=save_as_parquet, skip_existing=skip_existing, write_log=write_log\n        )\n</code></pre>"},{"location":"api/#omega_prime.converters.converter.DatasetConverter.get_recording_name","title":"<code>get_recording_name(recording)</code>  <code>abstractmethod</code>","text":"<p>Abstract method to get the name for a given recording. The method should be implemented in subclasses to handle specific dataset formats. Args:     recording: Recording of any type as returned by get_recordings. Returns:     str: unique name of recording.</p> Source code in <code>omega_prime/converters/converter.py</code> <pre><code>@abstractmethod\ndef get_recording_name(self, recording) -&gt; str:\n    \"\"\"\n    Abstract method to get the name for a given recording.\n    The method should be implemented in subclasses to handle specific dataset formats.\n    Args:\n        recording: Recording of any type as returned by get_recordings.\n    Returns:\n        str: unique name of recording.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#omega_prime.converters.converter.DatasetConverter.get_recordings","title":"<code>get_recordings(source_recording)</code>  <code>abstractmethod</code>","text":"<p>Abstract method to get all recordings in a source-recording-instance of the specific dataset. The method should be implemented in subclasses to handle specific dataset formats. Args:     source_recordings: List of the source recordings. Could be of any type as returned by get_source_recordings. Yields:     recording: Each recording in the source-recording-instance, one at a time. Could be of any type as further processed in to_omega_prime_recording and get_recording_id.</p> Source code in <code>omega_prime/converters/converter.py</code> <pre><code>@abstractmethod\ndef get_recordings(self, source_recording) -&gt; Iterator:\n    \"\"\"\n    Abstract method to get all recordings in a source-recording-instance of the specific dataset.\n    The method should be implemented in subclasses to handle specific dataset formats.\n    Args:\n        source_recordings: List of the source recordings. Could be of any type as returned by get_source_recordings.\n    Yields:\n        recording: Each recording in the source-recording-instance, one at a time. Could be of any type as further processed in to_omega_prime_recording and get_recording_id.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#omega_prime.converters.converter.DatasetConverter.get_source_recordings","title":"<code>get_source_recordings()</code>  <code>abstractmethod</code>","text":"<p>Abstract method to get a list of the source recordings. The method should be implemented in subclasses to handle specific dataset formats. Returns:     source_recordings: List of the source recordings. Could be of any type as further processed in get_recordings.</p> Source code in <code>omega_prime/converters/converter.py</code> <pre><code>@abstractmethod\ndef get_source_recordings(self) -&gt; list:\n    \"\"\"\n    Abstract method to get a list of the source recordings.\n    The method should be implemented in subclasses to handle specific dataset formats.\n    Returns:\n        source_recordings: List of the source recordings. Could be of any type as further processed in get_recordings.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#omega_prime.converters.converter.DatasetConverter.to_omega_prime_recording","title":"<code>to_omega_prime_recording(recording)</code>  <code>abstractmethod</code>","text":"<p>Abstract method to convert a raw recording into an omega prime recording instance. The method should be implemented in subclasses to handle specific dataset formats. Args:     recording: A recording of any type as returned by get_omega_prime_recordings. Returns:     Recording: An instance of the Recording class containing the processed data.</p> Source code in <code>omega_prime/converters/converter.py</code> <pre><code>@abstractmethod\ndef to_omega_prime_recording(self, recording) -&gt; Recording:\n    \"\"\"\n    Abstract method to convert a raw recording into an omega prime recording instance.\n    The method should be implemented in subclasses to handle specific dataset formats.\n    Args:\n        recording: A recording of any type as returned by get_omega_prime_recordings.\n    Returns:\n        Recording: An instance of the Recording class containing the processed data.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#omega_prime.metrics.Metric","title":"<code>Metric</code>  <code>dataclass</code>","text":"<p>Class to compute metrics based on polars dataframes.</p> Source code in <code>omega_prime/metrics.py</code> <pre><code>@dataclass\nclass Metric:\n    \"\"\"Class to compute metrics based on polars dataframes.\"\"\"\n\n    compute_func: Callable[[pl.LazyFrame, ...], tuple[pl.LazyFrame, dict[str, pl.LazyFrame]]]\n    \"\"\"The function that actually computes the metric\"\"\"\n    computes_columns: list[str] = field(default_factory=list)\n    \"\"\"Names of the columns that will be added to the dataframe by this metrics\"\"\"\n    computes_properties: list[str] = field(default_factory=list)\n    \"\"\"Keys of the tables added to the properties dictionary by this metric\"\"\"\n    requires_columns: list[str] = field(default_factory=list)\n    \"\"\"Columns that must be present in the dataframe before this metric can be calculated\"\"\"\n    requires_properties: list[str] = field(default_factory=list)\n    \"\"\"Keys of tables that must be present in the properties dictionary before this metric can be calculated.\"\"\"\n    computes_intermediate_columns: list[str] = field(default_factory=list)\n    \"\"\"Same as computes_columns by these ones will not be returned in the end and are only available to other metrics\"\"\"\n    computes_intermediate_properties: list[str] = field(default_factory=list)\n    \"\"\" Same as computes_properties but these ones will not be returned in the end and are only available to other metrics.\"\"\"\n    _parameters: list = field(init=False)\n    \"\"\"All parameters of metrics that need to be set on computation\"\"\"\n\n    def compute_lazy(self, df: pl.LazyFrame, **kwargs) -&gt; tuple[pl.LazyFrame, dict[str, pl.LazyFrame]]:\n        try:\n            df, properties = self.compute_func(df, **kwargs)\n            assert isinstance(df, pl.LazyFrame)\n            assert all(p in properties for p in self.computes_properties + self.computes_intermediate_properties)\n            return df, properties\n\n        except TypeError as e:\n            raise TypeError(\n                f\"Missing parameter for Metric with compute_func {self.compute_func.__name__}: {repr(e)}\"\n            ) from e\n\n    def __post_init__(self):\n        sig = inspect.signature(self.compute_func)\n        parameters = sig.parameters\n        assert \"df\" in parameters\n        assert all(p in parameters for p in self.requires_properties)\n\n        self._parameters = [\n            v for k, v in parameters.items() if k not in [\"df\", \"args\", \"kwargs\"] + self.requires_properties\n        ]\n\n    def __call__(self, df: pl.DataFrame, **kwargs):\n        try:\n            if not isinstance(df, pl.LazyFrame):\n                df = pl.LazyFrame(df)\n            return self.compute_lazy(df, **kwargs)\n        except TypeError as e:\n            raise TypeError(\n                f\"Missing paramter for Metric with compute_func {self.compute_func.__name__}: {repr(e)}\"\n            ) from e\n</code></pre>"},{"location":"api/#omega_prime.metrics.Metric.compute_func","title":"<code>compute_func</code>  <code>instance-attribute</code>","text":"<p>The function that actually computes the metric</p>"},{"location":"api/#omega_prime.metrics.Metric.computes_columns","title":"<code>computes_columns = field(default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Names of the columns that will be added to the dataframe by this metrics</p>"},{"location":"api/#omega_prime.metrics.Metric.computes_intermediate_columns","title":"<code>computes_intermediate_columns = field(default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Same as computes_columns by these ones will not be returned in the end and are only available to other metrics</p>"},{"location":"api/#omega_prime.metrics.Metric.computes_intermediate_properties","title":"<code>computes_intermediate_properties = field(default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Same as computes_properties but these ones will not be returned in the end and are only available to other metrics.</p>"},{"location":"api/#omega_prime.metrics.Metric.computes_properties","title":"<code>computes_properties = field(default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Keys of the tables added to the properties dictionary by this metric</p>"},{"location":"api/#omega_prime.metrics.Metric.requires_columns","title":"<code>requires_columns = field(default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Columns that must be present in the dataframe before this metric can be calculated</p>"},{"location":"api/#omega_prime.metrics.Metric.requires_properties","title":"<code>requires_properties = field(default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Keys of tables that must be present in the properties dictionary before this metric can be calculated.</p>"},{"location":"api/#omega_prime.metrics.MetricManager","title":"<code>MetricManager</code>  <code>dataclass</code>","text":"Source code in <code>omega_prime/metrics.py</code> <pre><code>@dataclass\nclass MetricManager:\n    metrics: list[Metric] = field(default_factory=lambda: metrics)\n    \"\"\"List of metrics to compute\"\"\"\n    exclude_columns: list[str] = field(default_factory=list)\n    \"\"\"List of columns computed by the metrics that do not need to be computed\"\"\"\n    exclude_properties: list[str] = field(default_factory=list)\n    \"\"\"List of tables in the properties dict that do not need to be computed\"\"\"\n    _dependencies: dict[int | str, list[int | str]] = field(init=False)\n    \"\"\"Automatically derived dependencies between metrics\"\"\"\n    _ordered_metrics: list[Metric] = field(init=False)\n    \"\"\"Automatically derived execution order of metrics\"\"\"\n    _parameters: list = field(init=False)\n    \"\"\"Automatically derived list of parameters to keep\"\"\"\n\n    def __post_init__(self):\n        self._dependencies = {\n            val: [i]\n            for i, m in enumerate(self.metrics)\n            for val in [f\"column_{n}\" for n in m.computes_columns + m.computes_intermediate_columns]\n            + [f\"property_{n}\" for n in m.computes_properties + m.computes_intermediate_properties]\n        } | {\n            i: [f\"column_{n}\" for n in m.requires_columns] + [f\"property_{n}\" for n in m.requires_properties]\n            for i, m in enumerate(self.metrics)\n        }\n\n        unresovled_dependencies = {\n            k: v for k, vv in self._dependencies.items() for v in vv if v not in self._dependencies\n        }\n        if len(unresovled_dependencies) &gt; 0:\n            error_dict = {f\"self.metrics[{k}]\": v for k, v in unresovled_dependencies.items()}\n            raise RuntimeError(\n                f\"There are columns and properties required by metrics, that are never computed: {error_dict}\"\n            )\n\n        self._parameters = [v for m in self.metrics for v in m._parameters]\n\n        self.exclude_columns += [v for m in self.metrics for v in m.computes_intermediate_columns]\n        self.exclude_properties += [v for m in self.metrics for v in m.computes_intermediate_properties]\n\n        ts = graphlib.TopologicalSorter(self._dependencies)\n        self._ordered_metrics = [self.metrics[o] for o in ts.static_order() if isinstance(o, int)]\n\n    def __repr__(self):\n        return f\"computes columns: {[c for m in self._ordered_metrics for c in m.computes_columns]} - computes properties {[p for m in self._ordered_metrics for p in m.computes_properties]} - parameters {list(set([str(m) for m in self._parameters]))}\"\n\n    def compute(self, r: Recording, **kwargs) -&gt; tuple[pl.DataFrame, dict[str, pl.DataFrame]]:\n        if \"polygon\" not in r._df.columns:\n            r._df = r._add_polygons(r._df)\n        if \"geometry\" not in r._df.columns:\n            r._df = r._df.with_columns(geometry=st.from_shapely(\"polygon\"))\n\n        df = pl.LazyFrame(r._df)\n        properties = {}\n        for m in self._ordered_metrics:\n            df, new_p = m.compute_lazy(\n                df=df,\n                **{k: properties[k] for k in m.requires_properties},\n                **{k: v for k, v in kwargs.items() if k in [p.name for p in m._parameters]},\n            )\n            properties |= new_p\n        for k in self.exclude_properties:\n            del properties[k]\n        df = df.drop(self.exclude_columns)\n        res = pl.collect_all([df] + list(properties.values()))\n        df, computed_props = res[0], res[1:]\n        assert all(c in df.columns or c in self.exclude_columns for m in self.metrics for c in m.computes_columns)\n        return df, {k: v for k, v in zip(properties.keys(), computed_props)}\n\n    def plot_dependencies(self):\n        import networkx as nx\n        import matplotlib.pyplot as plt\n\n        i = 0\n        pos = {}\n        G = nx.DiGraph()\n\n        for m in self._ordered_metrics:\n            n = m.compute_func.__name__\n            pos[n] = [0, -i]\n            i += 1\n            cn = [f\"column_{c}\" for c in m.computes_columns + m.computes_intermediate_columns] + [\n                f\"property_{c}\" for c in m.computes_properties + m.computes_intermediate_properties\n            ]\n            pos |= {k: [1 + j, -i] for j, k in enumerate(cn)}\n            G.add_node(n, color=\"lightblue\")\n            for c in cn:\n                G.add_node(c, color=\"lightgreen\")\n                G.add_edge(n, c, label=\"computes\")\n            for r in [f\"column_{c}\" for c in m.requires_columns] + [f\"property_{p}\" for p in m.requires_properties]:\n                G.add_edge(r, n, label=\"required by\")\n            i += 1\n\n        # Draw nodes and edges\n        fig, ax = plt.subplots()\n        nx.draw(\n            G,\n            pos,\n            with_labels=True,\n            node_size=2000,\n            node_color=list(nx.get_node_attributes(G, \"color\").values()),\n            arrows=True,\n            font_size=8,\n            ax=ax,\n        )\n\n        return fig\n</code></pre>"},{"location":"api/#omega_prime.metrics.MetricManager.exclude_columns","title":"<code>exclude_columns = field(default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List of columns computed by the metrics that do not need to be computed</p>"},{"location":"api/#omega_prime.metrics.MetricManager.exclude_properties","title":"<code>exclude_properties = field(default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List of tables in the properties dict that do not need to be computed</p>"},{"location":"api/#omega_prime.metrics.MetricManager.metrics","title":"<code>metrics = field(default_factory=(lambda: metrics))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List of metrics to compute</p>"},{"location":"api/#omega_prime.metrics.distance_traveled","title":"<code>distance_traveled(df)</code>","text":"<p>Metric that computes the column <code>distance_traveled</code></p> Source code in <code>omega_prime/metrics.py</code> <pre><code>@metric(computes_columns=[\"distance_traveled\"])\ndef distance_traveled(df) -&gt; tuple[pl.DataFrame, dict[str, pl.DataFrame]]:\n    \"\"\"Metric that computes the column `distance_traveled`\"\"\"\n    return df.with_columns(\n        (pl.col(\"x\").diff() ** 2 + pl.col(\"y\").diff() ** 2)\n        .sqrt()\n        .fill_null(0.0)\n        .cum_sum()\n        .over(\"idx\", order_by=\"total_nanos\")\n        .alias(\"distance_traveled\"),\n    ), {}\n</code></pre>"},{"location":"api/#omega_prime.metrics.metric","title":"<code>metric(computes_columns=None, computes_properties=None, requires_columns=None, requires_properties=None, computes_intermediate_columns=None, computes_intermediate_properties=None)</code>","text":"<p>Decorator to turn a function into a Metric</p> Source code in <code>omega_prime/metrics.py</code> <pre><code>def metric(\n    computes_columns: list[str] | None = None,\n    computes_properties: list[str] | None = None,\n    requires_columns: list[str] | None = None,\n    requires_properties: list[str] | None = None,\n    computes_intermediate_columns: list[str] | None = None,\n    computes_intermediate_properties: list[str] | None = None,\n):\n    \"\"\"Decorator to turn a function into a Metric\"\"\"\n\n    def decorator(func):\n        return Metric(\n            compute_func=func,\n            computes_columns=computes_columns or [],\n            computes_properties=computes_properties or [],\n            requires_columns=requires_columns or [],\n            requires_properties=requires_properties or [],\n            computes_intermediate_columns=computes_intermediate_columns or [],\n            computes_intermediate_properties=computes_intermediate_properties or [],\n        )\n\n    return decorator\n</code></pre>"},{"location":"api/#omega_prime.metrics.p_timegaps_and_min_p_timgaps","title":"<code>p_timegaps_and_min_p_timgaps(df, /, ego_id, crossed, timegaps, time_buffer=2000000000.0)</code>","text":"<p>Metrics that computes a predicted timegap between <code>ego_id</code> and all other objects. <code>time_buffer</code> gives the timespan in which intersection of trajectories is tested. The prediction is based on constant velocity following the same trajectory as observed.</p> Source code in <code>omega_prime/metrics.py</code> <pre><code>@metric(\n    requires_columns=[\"distance_traveled\", \"vel\"],\n    requires_properties=[\"crossed\", \"timegaps\"],\n    computes_properties=[\"p_timegaps\", \"min_p_timegaps\"],\n)\ndef p_timegaps_and_min_p_timgaps(df, /, ego_id, crossed, timegaps, time_buffer=2e9):\n    \"\"\"Metrics that computes a predicted timegap between `ego_id` and all other objects. `time_buffer` gives the timespan in which intersection of trajectories is tested. The prediction is based on constant velocity following the same trajectory as observed.\"\"\"\n    p_timegaps = (\n        crossed.join(timegaps, how=\"right\", suffix=\"_overlap\", on=[\"idx\", \"idx_ego\"])\n        .with_columns(\n            pl.when(pl.col(\"total_nanos\") &gt;= pl.col(\"total_nanos_overlap\"))\n            .then((pl.col(\"total_nanos_overlap\") - pl.col(\"total_nanos\")) / 1e9)\n            .otherwise((pl.col(\"distance_traveled_overlap\") - pl.col(\"distance_traveled\")) / pl.col(\"vel\"))\n            .alias(\"time_to_overlap\"),\n            pl.when(pl.col(\"total_nanos_ego\") &gt;= pl.col(\"total_nanos_ego_overlap\"))\n            .then((pl.col(\"total_nanos_ego_overlap\") - pl.col(\"total_nanos_ego\")) / 1e9)\n            .otherwise((pl.col(\"distance_traveled_ego_overlap\") - pl.col(\"distance_traveled_ego\")) / pl.col(\"vel_ego\"))\n            .alias(\"time_to_overlap_ego\"),\n        )\n        .with_columns(\n            -(\n                pl.col(\"time_to_overlap_ego\")\n                - pl.col(\"time_to_overlap\")\n                + (pl.col(\"total_nanos_ego\") - pl.col(\"total_nanos\")) / 1e9\n            ).alias(\"p_timegap\")\n        )\n        .group_by(\"idx_ego\", \"idx\", \"total_nanos_ego\")\n        .agg(\n            pl.col(\"p_timegap\", \"total_nanos\")\n            .sort_by(pl.col(\"p_timegap\").abs(), descending=False, nulls_last=True)\n            .first()\n        )\n        .sort(\"idx_ego\", \"idx\", \"total_nanos_ego\")\n    )\n\n    min_p_timegaps = p_timegaps.group_by(\"idx_ego\", \"idx\").agg(\n        pl.col(\"p_timegap\").sort_by(pl.col(\"p_timegap\").abs(), descending=False).first()\n    )\n\n    return df, {\n        \"p_timegaps\": p_timegaps,\n        \"min_p_timegaps\": min_p_timegaps,\n    }\n</code></pre>"},{"location":"api/#omega_prime.metrics.timegaps_and_min_timgaps","title":"<code>timegaps_and_min_timgaps(df, /, ego_id, time_buffer=2000000000.0)</code>","text":"<p>Metrics that computes timegaps between <code>ego_id</code> and all other objects. <code>time_buffer</code> gives the timespan in which intersection of trajectories is tested</p> Source code in <code>omega_prime/metrics.py</code> <pre><code>@metric(\n    requires_columns=[\"distance_traveled\", \"vel\"],\n    computes_properties=[\"timegaps\", \"min_timegaps\"],\n    computes_intermediate_properties=[\"crossed\"],\n)\ndef timegaps_and_min_timgaps(df, /, ego_id, time_buffer=2e9):\n    \"\"\"Metrics that computes timegaps between `ego_id` and all other objects. `time_buffer` gives the timespan in which intersection of trajectories is tested\"\"\"\n    ego_df = df.filter(idx=ego_id)\n\n    crossed = df.join(ego_df, how=\"cross\", suffix=\"_ego\")\n\n    crossed = crossed.filter(\n        (pl.col(\"total_nanos_ego\") - time_buffer) &lt;= pl.col(\"total_nanos\"),\n        (pl.col(\"total_nanos_ego\") + time_buffer) &gt;= pl.col(\"total_nanos\"),\n        pl.col(\"idx_ego\") != pl.col(\"idx\"),\n    )\n\n    all_timegaps = (\n        crossed.filter(pl.col(\"geometry\").st.intersects(pl.col(\"geometry_ego\")))\n        .with_columns(timegap=(pl.col(\"total_nanos\") - pl.col(\"total_nanos_ego\")) / 1e9)\n        .select(\n            \"idx_ego\", \"idx\", \"total_nanos_ego\", \"total_nanos\", \"timegap\", \"distance_traveled\", \"distance_traveled_ego\"\n        )\n    )\n\n    timegaps = (\n        all_timegaps.group_by(\"idx\", \"idx_ego\", \"total_nanos_ego\")\n        .agg(\n            pl.col(\"timegap\", \"total_nanos\", \"distance_traveled\", \"distance_traveled_ego\").get(\n                pl.col(\"timegap\").abs().arg_min()\n            ),\n        )\n        .sort(\"idx_ego\", \"idx\", \"total_nanos_ego\")\n        .select(\n            \"idx_ego\", \"idx\", \"total_nanos_ego\", \"timegap\", \"total_nanos\", \"distance_traveled\", \"distance_traveled_ego\"\n        )\n    )\n    min_timegaps = timegaps.group_by(\"idx_ego\", \"idx\").agg(\n        pl.col(\"timegap\").get(pl.col(\"timegap\").abs().arg_min()).alias(\"min_timegap\")\n    )\n\n    return df, {\"timegaps\": timegaps, \"min_timegaps\": min_timegaps, \"crossed\": crossed}\n</code></pre>"},{"location":"api/#omega_prime.metrics.vel","title":"<code>vel(df)</code>","text":"<p>Metric that computes the column length of the speed vecotr <code>vel</code></p> Source code in <code>omega_prime/metrics.py</code> <pre><code>@metric(computes_columns=[\"vel\"])\ndef vel(df) -&gt; tuple[pl.DataFrame, dict[str, pl.DataFrame]]:\n    \"\"\"Metric that computes the column length of the speed vecotr `vel`\"\"\"\n    return df.with_columns(\n        (pl.col(\"vel_x\") ** 2 + pl.col(\"vel_y\") ** 2).sqrt().alias(\"vel\"),\n    ), {}\n</code></pre>"},{"location":"api/#omega_prime.mapsegment.MapSegmentType","title":"<code>MapSegmentType</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Classification of MapSegments.</p> Source code in <code>omega_prime/mapsegment.py</code> <pre><code>class MapSegmentType(Enum):\n    \"\"\"Classification of MapSegments.\"\"\"\n\n    STRAIGHT = \"straight\"\n    JUNCTION = \"junction\"\n    ROUNDABOUT = \"roundabout\"\n    RAMP_ON = \"ramp_on\"\n    RAMP_OFF = \"ramp_off\"\n    UNKNOWN = \"unknown\"\n</code></pre>"},{"location":"api/#omega_prime.mapsegment.MapSegmentation","title":"<code>MapSegmentation</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for map segmentation that handles multiple segments on a single map. Concrete implementations must define how to extract lane-specific information.</p> Source code in <code>omega_prime/mapsegment.py</code> <pre><code>class MapSegmentation(ABC):\n    \"\"\"\n    Abstract base class for map segmentation that handles multiple segments on a single map.\n    Concrete implementations must define how to extract lane-specific information.\n    \"\"\"\n\n    def __init__(self, recording, concave_hull_ratio=0.3):\n        self.map = recording.map\n        self.lanes = recording.map.lanes\n        self.trafficlight = {}\n        self.trafficlight_ids = set()\n        self.intersections = []\n        self.lane_dict = {}\n        self.lane_successors_dict = {}\n        self.lane_predecessors_dict = {}\n        self.intersecting_lanes_dict = {}\n        self.intersection_dict = {}\n        self.lane_segment_dict = {}\n        self.segments = []\n        self.concave_hull_ratio = concave_hull_ratio\n\n        segment_name = nt(\"SegmentName\", [\"lane_id\", \"segment_idx\", \"segment\"])\n        for lane in self.lanes.values():\n            self.lane_segment_dict[self._get_lane_id(lane)] = segment_name(self._get_lane_id(lane), None, None)\n\n    @abstractmethod\n    def _get_lane_id(self, lane) -&gt; Any:\n        \"\"\"Extract lane ID from a lane object. Map-type specific.\"\"\"\n        pass\n\n    @abstractmethod\n    def _get_lane_centerline(self, lane) -&gt; shapely.LineString:\n        \"\"\"Extract centerline from a lane object. Map-type specific.\"\"\"\n        pass\n\n    @abstractmethod\n    def _get_lane_successors(self, lane) -&gt; list:\n        \"\"\"Extract successor IDs from a lane object. Map-type specific.\"\"\"\n        pass\n\n    @abstractmethod\n    def _get_lane_predecessors(self, lane) -&gt; list:\n        \"\"\"Extract predecessor IDs from a lane object. Map-type specific.\"\"\"\n        pass\n\n    @abstractmethod\n    def _has_traffic_light(self, lane) -&gt; bool:\n        \"\"\"Check if lane has traffic light. Map-type specific.\"\"\"\n        pass\n\n    @abstractmethod\n    def _get_traffic_light(self, lane):\n        \"\"\"Get traffic light object from lane. Map-type specific.\"\"\"\n        pass\n\n    @abstractmethod\n    def _set_lane_on_intersection(self, lane, value: bool):\n        \"\"\"Set the on_intersection attribute for a lane. Map-type specific.\"\"\"\n        pass\n\n    @abstractmethod\n    def _set_lane_is_approaching(self, lane, value: bool):\n        \"\"\"Set the is_approaching attribute for a lane. Map-type specific.\"\"\"\n        pass\n\n    @abstractmethod\n    def _get_lane_on_intersection(self, lane) -&gt; bool:\n        \"\"\"Get the on_intersection status of a lane. Map-type specific.\"\"\"\n        pass\n\n    # Concrete methods using abstract methods\n    def create_lane_dict(self):\n        \"\"\"Returns a dictionary mapping each lane's lane_id to the lane object.\"\"\"\n        self.lane_dict = {self._get_lane_id(lane): lane for lane in self.lanes.values()}\n        return self.lane_dict\n\n    def get_lane_successors_and_predecessors(self):\n        \"\"\"Returns dictionaries mapping each lane's lane_id to its successor and predecessor lane indices.\"\"\"\n        lane_successors = {}\n        lane_predecessors = {}\n\n        for lane in self.lanes.values():\n            lane_id = self._get_lane_id(lane)\n            lane_successors[lane_id] = self._get_lane_successors(lane)\n            lane_predecessors[lane_id] = self._get_lane_predecessors(lane)\n\n        self.lane_successors_dict = lane_successors\n        self.lane_predecessors_dict = lane_predecessors\n        return lane_successors, lane_predecessors\n\n    def check_if_all_lanes_are_on_segment(self):\n        \"\"\"\n        Checks if all lanes are on a segment.\n        Returns:\n            bool: True if all lanes are on a segment, False otherwise.\n        \"\"\"\n        for lane in self.lanes.values():\n            lane_id = self._get_lane_id(lane)\n            if lane_id not in self.lane_segment_dict or self.lane_segment_dict[lane_id].segment is None:\n                return False\n        return True\n</code></pre>"},{"location":"api/#omega_prime.mapsegment.MapSegmentation.check_if_all_lanes_are_on_segment","title":"<code>check_if_all_lanes_are_on_segment()</code>","text":"<p>Checks if all lanes are on a segment. Returns:     bool: True if all lanes are on a segment, False otherwise.</p> Source code in <code>omega_prime/mapsegment.py</code> <pre><code>def check_if_all_lanes_are_on_segment(self):\n    \"\"\"\n    Checks if all lanes are on a segment.\n    Returns:\n        bool: True if all lanes are on a segment, False otherwise.\n    \"\"\"\n    for lane in self.lanes.values():\n        lane_id = self._get_lane_id(lane)\n        if lane_id not in self.lane_segment_dict or self.lane_segment_dict[lane_id].segment is None:\n            return False\n    return True\n</code></pre>"},{"location":"api/#omega_prime.mapsegment.MapSegmentation.create_lane_dict","title":"<code>create_lane_dict()</code>","text":"<p>Returns a dictionary mapping each lane's lane_id to the lane object.</p> Source code in <code>omega_prime/mapsegment.py</code> <pre><code>def create_lane_dict(self):\n    \"\"\"Returns a dictionary mapping each lane's lane_id to the lane object.\"\"\"\n    self.lane_dict = {self._get_lane_id(lane): lane for lane in self.lanes.values()}\n    return self.lane_dict\n</code></pre>"},{"location":"api/#omega_prime.mapsegment.MapSegmentation.get_lane_successors_and_predecessors","title":"<code>get_lane_successors_and_predecessors()</code>","text":"<p>Returns dictionaries mapping each lane's lane_id to its successor and predecessor lane indices.</p> Source code in <code>omega_prime/mapsegment.py</code> <pre><code>def get_lane_successors_and_predecessors(self):\n    \"\"\"Returns dictionaries mapping each lane's lane_id to its successor and predecessor lane indices.\"\"\"\n    lane_successors = {}\n    lane_predecessors = {}\n\n    for lane in self.lanes.values():\n        lane_id = self._get_lane_id(lane)\n        lane_successors[lane_id] = self._get_lane_successors(lane)\n        lane_predecessors[lane_id] = self._get_lane_predecessors(lane)\n\n    self.lane_successors_dict = lane_successors\n    self.lane_predecessors_dict = lane_predecessors\n    return lane_successors, lane_predecessors\n</code></pre>"},{"location":"api/#omega_prime.mapsegment.Segment","title":"<code>Segment</code>","text":"<p>               Bases: <code>ABC</code></p> <p>A class that represents a segment of the map</p> Source code in <code>omega_prime/mapsegment.py</code> <pre><code>class Segment(ABC):\n    \"\"\"A class that represents a segment of the map\"\"\"\n\n    def __init__(self, lanes, idx=None, concave_hull_ratio=0.3):\n        self.lanes = lanes\n        self.lane_ids = [self._get_lane_id(lane) for lane in lanes]\n        self.trafficlights = []\n        self.idx = idx\n        self.concave_hull_ratio = concave_hull_ratio\n        self.type = MapSegmentType.UNKNOWN\n\n        # Cache polygon to avoid recomputing concave hull when lanes stay unchanged\n        self._polygon_cache = None\n        self._polygon_cache_key = None\n        self._polygon_dirty = True\n        self.polygon = self.create_segment_polygon()\n\n    @abstractmethod\n    def _get_lane_id(self, lane):\n        \"\"\"Extract lane ID from a lane object. Map-type specific.\"\"\"\n        pass\n\n    @abstractmethod\n    def _get_lane_geometry(self, lane) -&gt; shapely.LineString:\n        \"\"\"Extract geometry from a lane object. Map-type specific.\"\"\"\n        pass\n\n    @abstractmethod\n    def set_trafficlight(self):\n        \"\"\"Set traffic lights for this segment. Map-type specific.\"\"\"\n        pass\n\n    def _compute_polygon_key(self):\n        return tuple((self._get_lane_id(lane), self._get_lane_geometry(lane).wkb) for lane in self.lanes)\n\n    def _compute_segment_polygon(self):\n        lane_centerline = [self._get_lane_geometry(lane) for lane in self.lanes]\n        multilinestring = shapely.MultiLineString(lane_centerline).buffer(0.1)\n        combined = shapely.unary_union(multilinestring).buffer(0.1)\n        try:\n            hull = shapely.concave_hull(combined, self.concave_hull_ratio)\n            assert not hull.is_empty\n        except (shapely.errors.GEOSException, AssertionError):\n            hull = shapely.convex_hull(combined)\n            assert not hull.is_empty\n        return hull\n\n    def _ensure_polygon(self, force=False):\n        key = self._compute_polygon_key()\n        if force or self._polygon_dirty or key != self._polygon_cache_key:\n            self._polygon_cache = self._compute_segment_polygon()\n            self._polygon_cache_key = key\n            self._polygon_dirty = False\n        return self._polygon_cache\n\n    def get_center_point(self):\n        \"Returns the center point of the segment\"\n        return self.polygon.centroid.x, self.polygon.centroid.y\n\n    def create_segment_polygon(self):\n        \"Create the Polygon of the Segment\"\n        return self._ensure_polygon()\n\n    def update_polygon(self):\n        \"Updates the Polygon of the Segment\"\n        self._polygon_dirty = True\n        self.polygon = self._ensure_polygon(force=True)\n\n    def add_lane(self, lanes, update_polygon=True):\n        \"\"\"Adds a lane to the segment.\n        If the lane is already in the segment, it will not be added again.\n\n        Args:\n            lane (list): A list of lane objects to be added to the segment.\n        \"\"\"\n        for lane in lanes:\n            if lane not in self.lanes:\n                self.lanes.append(lane)\n                self.lane_ids.append(self._get_lane_id(lane))\n\n        if update_polygon:\n            self.update_polygon()\n\n        self.set_trafficlight()\n\n    def get_timeinterval_on_segment(self, roaduser):\n        \"\"\"\n        Gets a roadsegment as input as well as a roaduser trajectory.\n        Returns the time interval of the roaduser on the segment.\n        roaduser should be a np.array with (total_nanos, x, y)\n        \"\"\"\n        if self.polygon:\n            roaduser_points = [shapely.Point(x, y) for x, y in roaduser[:, 1:3]]\n            roaduser_on_segment = np.array([self.polygon.contains(point) for point in roaduser_points])\n            if roaduser_on_segment.any():\n                indices = np.where(roaduser_on_segment)[0]\n                return roaduser[indices[0], 0], roaduser[indices[-1], 0]\n            else:\n                return None\n        else:\n            return None\n</code></pre>"},{"location":"api/#omega_prime.mapsegment.Segment.add_lane","title":"<code>add_lane(lanes, update_polygon=True)</code>","text":"<p>Adds a lane to the segment. If the lane is already in the segment, it will not be added again.</p> <p>Parameters:</p> Name Type Description Default <code>lane</code> <code>list</code> <p>A list of lane objects to be added to the segment.</p> required Source code in <code>omega_prime/mapsegment.py</code> <pre><code>def add_lane(self, lanes, update_polygon=True):\n    \"\"\"Adds a lane to the segment.\n    If the lane is already in the segment, it will not be added again.\n\n    Args:\n        lane (list): A list of lane objects to be added to the segment.\n    \"\"\"\n    for lane in lanes:\n        if lane not in self.lanes:\n            self.lanes.append(lane)\n            self.lane_ids.append(self._get_lane_id(lane))\n\n    if update_polygon:\n        self.update_polygon()\n\n    self.set_trafficlight()\n</code></pre>"},{"location":"api/#omega_prime.mapsegment.Segment.create_segment_polygon","title":"<code>create_segment_polygon()</code>","text":"<p>Create the Polygon of the Segment</p> Source code in <code>omega_prime/mapsegment.py</code> <pre><code>def create_segment_polygon(self):\n    \"Create the Polygon of the Segment\"\n    return self._ensure_polygon()\n</code></pre>"},{"location":"api/#omega_prime.mapsegment.Segment.get_center_point","title":"<code>get_center_point()</code>","text":"<p>Returns the center point of the segment</p> Source code in <code>omega_prime/mapsegment.py</code> <pre><code>def get_center_point(self):\n    \"Returns the center point of the segment\"\n    return self.polygon.centroid.x, self.polygon.centroid.y\n</code></pre>"},{"location":"api/#omega_prime.mapsegment.Segment.get_timeinterval_on_segment","title":"<code>get_timeinterval_on_segment(roaduser)</code>","text":"<p>Gets a roadsegment as input as well as a roaduser trajectory. Returns the time interval of the roaduser on the segment. roaduser should be a np.array with (total_nanos, x, y)</p> Source code in <code>omega_prime/mapsegment.py</code> <pre><code>def get_timeinterval_on_segment(self, roaduser):\n    \"\"\"\n    Gets a roadsegment as input as well as a roaduser trajectory.\n    Returns the time interval of the roaduser on the segment.\n    roaduser should be a np.array with (total_nanos, x, y)\n    \"\"\"\n    if self.polygon:\n        roaduser_points = [shapely.Point(x, y) for x, y in roaduser[:, 1:3]]\n        roaduser_on_segment = np.array([self.polygon.contains(point) for point in roaduser_points])\n        if roaduser_on_segment.any():\n            indices = np.where(roaduser_on_segment)[0]\n            return roaduser[indices[0], 0], roaduser[indices[-1], 0]\n        else:\n            return None\n    else:\n        return None\n</code></pre>"},{"location":"api/#omega_prime.mapsegment.Segment.set_trafficlight","title":"<code>set_trafficlight()</code>  <code>abstractmethod</code>","text":"<p>Set traffic lights for this segment. Map-type specific.</p> Source code in <code>omega_prime/mapsegment.py</code> <pre><code>@abstractmethod\ndef set_trafficlight(self):\n    \"\"\"Set traffic lights for this segment. Map-type specific.\"\"\"\n    pass\n</code></pre>"},{"location":"api/#omega_prime.mapsegment.Segment.update_polygon","title":"<code>update_polygon()</code>","text":"<p>Updates the Polygon of the Segment</p> Source code in <code>omega_prime/mapsegment.py</code> <pre><code>def update_polygon(self):\n    \"Updates the Polygon of the Segment\"\n    self._polygon_dirty = True\n    self.polygon = self._ensure_polygon(force=True)\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.ConnectionSegment","title":"<code>ConnectionSegment</code>","text":"<p>               Bases: <code>SegmentOsiCenterline</code></p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>class ConnectionSegment(SegmentOsiCenterline):\n    def __init__(self, lanes, idx=None, concave_hull_ratio=0.3):\n        super().__init__(lanes, idx, concave_hull_ratio=concave_hull_ratio)\n        self.type = MapSegmentType.STRAIGHT\n        self.intersection_idxs = set()\n\n    def plot(self, output_plot: Path):\n        \"\"\"Plots the Connection segment\n\n        Args:\n            output_plot (Path): Path to the output directory.\n        Returns:\n            None\n        \"\"\"\n        fig, ax = plt.subplots(1, 1)\n        ax.set_aspect(1)\n        # Add the index of the center line to the plot\n        ax.set_title(f\"Connection segment {self.idx}\")\n        for lane in self.lanes:\n            ax.plot(*np.asarray(lane.centerline.xy)[:2], color=\"blue\")\n        for lane in self.lanes:\n            m = int(np.ceil(len(lane.centerline.xy[0]) / 2))\n            ax.annotate(\n                lane.idx.lane_id,\n                xy=(lane.centerline.xy[0][m], lane.centerline.xy[1][m]),\n                fontsize=2,\n                color=\"black\",\n                zorder=3,\n            )\n        # Plot the polygon into the intersection\n        try:\n            ax.plot(*self.polygon.exterior.xy, color=\"red\", alpha=0.5, zorder=10)\n        except:\n            logging.warning(f\"Connection {self.idx} has no polygon\")\n            pass\n        ax.set_aspect(1)\n        plt.title(f\"Connection with {len(self.lanes)} lanes\")\n        plt.xlabel(\"X Coordinate\")\n        plt.ylabel(\"Y Coordinate\")\n        if output_plot is None:\n            plt.show()\n        elif isinstance(output_plot, Path) and output_plot.is_dir():\n            output_plot.mkdir(parents=True, exist_ok=True)\n            plt.savefig(output_plot / f\"Connection{self.idx}.pdf\")\n        else:\n            raise ValueError(\"output_plot must be a Path to a directory or None\")\n        plt.close()\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.ConnectionSegment.plot","title":"<code>plot(output_plot)</code>","text":"<p>Plots the Connection segment</p> <p>Parameters:</p> Name Type Description Default <code>output_plot</code> <code>Path</code> <p>Path to the output directory.</p> required <p>Returns:     None</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def plot(self, output_plot: Path):\n    \"\"\"Plots the Connection segment\n\n    Args:\n        output_plot (Path): Path to the output directory.\n    Returns:\n        None\n    \"\"\"\n    fig, ax = plt.subplots(1, 1)\n    ax.set_aspect(1)\n    # Add the index of the center line to the plot\n    ax.set_title(f\"Connection segment {self.idx}\")\n    for lane in self.lanes:\n        ax.plot(*np.asarray(lane.centerline.xy)[:2], color=\"blue\")\n    for lane in self.lanes:\n        m = int(np.ceil(len(lane.centerline.xy[0]) / 2))\n        ax.annotate(\n            lane.idx.lane_id,\n            xy=(lane.centerline.xy[0][m], lane.centerline.xy[1][m]),\n            fontsize=2,\n            color=\"black\",\n            zorder=3,\n        )\n    # Plot the polygon into the intersection\n    try:\n        ax.plot(*self.polygon.exterior.xy, color=\"red\", alpha=0.5, zorder=10)\n    except:\n        logging.warning(f\"Connection {self.idx} has no polygon\")\n        pass\n    ax.set_aspect(1)\n    plt.title(f\"Connection with {len(self.lanes)} lanes\")\n    plt.xlabel(\"X Coordinate\")\n    plt.ylabel(\"Y Coordinate\")\n    if output_plot is None:\n        plt.show()\n    elif isinstance(output_plot, Path) and output_plot.is_dir():\n        output_plot.mkdir(parents=True, exist_ok=True)\n        plt.savefig(output_plot / f\"Connection{self.idx}.pdf\")\n    else:\n        raise ValueError(\"output_plot must be a Path to a directory or None\")\n    plt.close()\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation","title":"<code>MapOsiCenterlineSegmentation</code>","text":"<p>               Bases: <code>MapSegmentation</code></p> <p>A class that identifies different segments on a OsiCenterline Map. Concrete implementation of MapSegmentation for OSI centerline maps.</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>class MapOsiCenterlineSegmentation(MapSegmentation):\n    \"\"\"\n    A class that identifies different segments on a OsiCenterline Map.\n    Concrete implementation of MapSegmentation for OSI centerline maps.\n    \"\"\"\n\n    def __init__(self, recording, lane_buffer=None, intersection_overlap_buffer=None, concave_hull_ratio=0.3):\n        super().__init__(recording, concave_hull_ratio=concave_hull_ratio)\n        self.locator = Locator.from_map(recording.map)\n        self.isolated_connections = []\n        self.G = None\n        self.lane_buffer = lane_buffer if lane_buffer is not None else 0.3\n        self.intersection_overlap_buffer = intersection_overlap_buffer if intersection_overlap_buffer is not None else 1\n        self.do_combine_intersections = True\n\n        for tl_state in recording.traffic_light_states.values():\n            for tl in tl_state:\n                if tl.id.value not in self.trafficlight_ids:\n                    self.trafficlight[tl.id.value] = tl\n                    self.trafficlight_ids.add(tl.id.value)\n\n    # Implement abstract methods for OSI centerline maps\n    def _get_lane_id(self, lane):\n        \"\"\"Extract lane ID from OSI centerline lane.\"\"\"\n        return lane.idx.lane_id\n\n    def _get_lane_centerline(self, lane) -&gt; shapely.LineString:\n        \"\"\"Extract centerline from OSI centerline lane.\"\"\"\n        return lane.centerline\n\n    def _get_lane_successors(self, lane) -&gt; list:\n        \"\"\"Extract successor IDs from OSI centerline lane.\"\"\"\n        return [succ_id.lane_id if hasattr(succ_id, \"lane_id\") else succ_id for succ_id in lane.successor_ids]\n\n    def _get_lane_predecessors(self, lane) -&gt; list:\n        \"\"\"Extract predecessor IDs from OSI centerline lane.\"\"\"\n        return [pred_id.lane_id if hasattr(pred_id, \"lane_id\") else pred_id for pred_id in lane.predecessor_ids]\n\n    def _has_traffic_light(self, lane) -&gt; bool:\n        \"\"\"Check if OSI centerline lane has traffic light.\"\"\"\n        return hasattr(lane, \"trafficlight\") and lane.trafficlight is not None\n\n    def _get_traffic_light(self, lane):\n        \"\"\"Get traffic light object from OSI centerline lane.\"\"\"\n        return lane.trafficlight if self._has_traffic_light(lane) else None\n\n    def _set_lane_on_intersection(self, lane, value: bool):\n        \"\"\"Set the on_intersection attribute for OSI centerline lane.\"\"\"\n        lane.on_intersection = value\n\n    def _set_lane_is_approaching(self, lane, value: bool):\n        \"\"\"Set the is_approaching attribute for OSI centerline lane.\"\"\"\n        lane.is_approaching = value\n\n    def _get_lane_on_intersection(self, lane) -&gt; bool:\n        \"\"\"Get the on_intersection status of OSI centerline lane.\"\"\"\n        return lane.on_intersection if hasattr(lane, \"on_intersection\") else False\n\n    def init_intersections(self):\n        \"\"\"\n        Initializes the intersections in the map.\n        Args:\n            None\n        Returns:\n            None\n        \"\"\"\n        self.create_lane_dict()\n        self.get_lane_successors_and_predecessors()\n        self.parallel_lane_dict = self.create_parallel_lane_dict()\n        self.get_intersecting_lanes()\n        self.set_lane_trafficlights()\n        self.graph_intersection_detection()\n        self.G = add_lanexy_to_graph(self.G, self.lanes)\n        self.set_intersection_idx()\n\n        if self.do_combine_intersections:\n            self.add_non_intersecting_lanes_to_intersection()\n            self.combine_intersections()\n            self.set_intersection_idx()\n            self.create_intersection_dict()\n\n        self.create_lane_segment_dict()\n        self.find_isolated_connections()\n        self.create_lane_segment_dict()\n        self.check_if_all_lanes_are_on_segment()\n        self.update_segment_ids()\n        self.create_lane_segment_dict()\n        self.update_road_ids()\n        self.set_lane_intersection_relation()\n\n        # from pathlib import Path\n        # #Plot the graph G with x and y coordinates of the lanes\n        # plot_graph(self.G , Path(\"/scenario-center-playground/scenarios/\") / \"graph_plot.pdf\")\n\n    def update_road_ids(self):\n        \"\"\"\n        Updates the road_ids of the lane to the segment ID\n        \"\"\"\n        updates_needed = []\n        old_to_new_mapping = {}\n\n        # First pass: identify what needs to be updated\n        for lane_idx, lane in self.lanes.items():\n            lane_id = lane.idx.lane_id\n            if lane_id in self.lane_segment_dict and self.lane_segment_dict[lane_id].segment is not None:\n                new_road_id = self.lane_segment_dict[lane_id].segment.idx\n                if lane.idx.road_id != new_road_id:\n                    new_idx = lane.idx._replace(road_id=new_road_id)\n                    updates_needed.append((lane_idx, lane, new_idx))\n                    old_to_new_mapping[lane_idx] = new_idx\n\n        # Second pass: apply updates efficiently\n        for old_idx, lane, new_idx in updates_needed:\n            # Update the lane object in place\n            lane.idx = new_idx\n\n            # Only modify dictionary if the key actually changed\n            if old_idx != new_idx:\n                self.lanes[new_idx] = lane\n                del self.lanes[old_idx]\n\n        # Third pass: update all predecessor and successor references\n        for lane in self.lanes.values():\n            # Update predecessor references\n            updated_predecessors = []\n            for pred_id in lane.predecessor_ids:\n                if pred_id in old_to_new_mapping:\n                    updated_predecessors.append(old_to_new_mapping[pred_id])\n                else:\n                    updated_predecessors.append(pred_id)\n            lane.predecessor_ids = updated_predecessors\n\n            # Update successor references\n            updated_successors = []\n            for succ_id in lane.successor_ids:\n                if succ_id in old_to_new_mapping:\n                    updated_successors.append(old_to_new_mapping[succ_id])\n                else:\n                    updated_successors.append(succ_id)\n            lane.successor_ids = updated_successors\n\n        # Fourth pass: update internal dictionaries that track relationships\n        self.lane_dict = {lane.idx.lane_id: lane for lane in self.lanes.values()}\n        self.get_lane_successors_and_predecessors()\n\n    def update_segment_ids(self):\n        \"Updates the segment IDs of the map segmentation\"\n        self.segments = self.intersections + self.isolated_connections\n        for i, segment in enumerate(self.segments):\n            segment.idx = i\n            segment.set_trafficlight()\n\n    def create_parallel_lane_dict(self):\n        \"\"\"\n        Creates a dictionary mapping each lane's lane_id to the lane ids which are parallel to it\n        Args:\n            None\n        Returns:\n            dict: A dictionary mapping each lane's lane_id to the lane ids which are parallel to it.\n        \"\"\"\n        lane_dict = {lane.idx.lane_id: [] for lane in self.lanes.values()}\n\n        # Precompute lane directions for faster comparisons\n        lane_directions = {}\n        lane_centerlines = []\n        lane_ids = []\n\n        for lane in self.lanes.values():\n            coords = np.array(lane.centerline.coords)\n            direction = coords[-1] - coords[0]\n            lane_directions[lane.idx.lane_id] = direction / np.linalg.norm(direction)\n            lane_centerlines.append(lane.centerline)\n            lane_ids.append(lane.idx.lane_id)\n\n        if not lane_centerlines:\n            return lane_dict\n\n        # Use original centerlines for spatial index, buffer only when needed\n        tree = STRtree(lane_centerlines)\n\n        for i, lane in enumerate(self.lanes.values()):\n            lane_id = lane.idx.lane_id\n\n            # Create buffer only when querying, not storing it\n            buffer_geom = lane.centerline.buffer(10)\n            candidates = tree.query(buffer_geom)\n\n            # Clear the buffer immediately after use\n            del buffer_geom\n\n            for idx in candidates:\n                other_lane_id = lane_ids[idx]\n                if other_lane_id == lane_id:\n                    continue\n\n                # Compare directions using dot product\n                dir1 = lane_directions[lane_id]\n                dir2 = lane_directions[other_lane_id]\n                dot_product = np.clip(np.abs(np.dot(dir1, dir2)), -1.0, 1.0)\n                angle_deg = np.degrees(np.arccos(dot_product))\n\n                if angle_deg &lt; 10:\n                    lane_dict[lane_id].append(other_lane_id)\n\n        return lane_dict\n\n    def trajectory_segment_detection(self, trajectory):\n        \"\"\"\n        Splits a trajectory into segments based on the lane it is located on\n\n        Args:\n            trajectory (np.ndarray): A NumPy array of shape (n, 3) representing the trajectory, where each row is a (frame, x, y) coordinate.\n\n        Returns:\n            list: A list of tuples, where each tuple contains a segment of the trajectory and the segment it intersects with.\n        \"\"\"\n        segments = []\n        current_segment = []\n        xy = trajectory[:, 1:3]  # Extract x and y coordinates\n        sts = self.locator.xys2sts(xy)\n        lane_ids = sts[\"roadlane_id\"].to_numpy()\n        segment_idx = [self.lane_segment_dict[lane_id.lane_id].segment.idx for lane_id in lane_ids]\n\n        trajectory = np.column_stack((trajectory[:, 0], trajectory[:, 1], trajectory[:, 2], lane_ids, segment_idx))\n\n        # Create spatial index for intersection polygons\n        intersection_polygons = []\n        intersection_ids = []\n        buffer = 5\n\n        for segment in self.segments:\n            if segment.type == MapSegmentType.JUNCTION and hasattr(segment, \"polygon\"):\n                intersection_polygons.append(segment.polygon.buffer(buffer))\n                intersection_ids.append(segment.idx)\n\n        if intersection_polygons:\n            # Use spatial index for efficient intersection queries\n            tree = STRtree(intersection_polygons)\n\n            # Process points in batches for better performance\n            for i, (frame, x, y, _, _) in enumerate(trajectory):\n                point = Point(x, y)\n\n                # Query spatial index instead of checking all polygons\n                candidates = tree.query(point)\n\n                for idx in candidates:\n                    if intersection_polygons[idx].contains(point):\n                        trajectory[i, 4] = intersection_ids[idx]\n                        break\n\n        # Rest of the method for creating segments\n        prev_seg_id = -1\n        for i, (frame, x, y, _, segment_idx) in enumerate(trajectory):\n            if prev_seg_id == segment_idx:\n                current_segment.append((frame, x, y))\n            else:\n                if current_segment:\n                    segments.append((np.array(current_segment), self.segments[prev_seg_id]))\n                current_segment = [(frame, x, y)]\n                prev_seg_id = segment_idx\n\n        if current_segment:\n            segments.append((np.array(current_segment), self.segments[prev_seg_id]))\n\n        return segments\n\n    def get_intersecting_lanes(self, buffer: float = None):\n        \"\"\"\n        Returns a dictionary mapping each lane's lane_id to an array of lane ids it intersects with.\n\n        Args:\n            lanes (list): Array of lane objects, each with an `idx` and `centerline` attribute.\n\n        Returns:\n            dict: A dictionary where keys are lane ids and values are arrays of intersecting lane ids.\n        \"\"\"\n        if buffer is None:\n            buffer = self.lane_buffer\n\n        # Create spatial index directly from centerlines\n        lane_centerlines = []\n        lane_ids = []\n\n        for lane in self.lanes.values():\n            lane_centerlines.append(lane.centerline)\n            lane_ids.append(lane.idx.lane_id)\n\n        if not lane_centerlines:\n            self.intersecting_lanes_dict = {}\n            return {}\n\n        tree = STRtree(lane_centerlines)\n\n        # Pre-compute lane relationships for faster lookup\n        successors_set = {lane_id: set(successors) for lane_id, successors in self.lane_successors_dict.items()}\n        predecessors_set = {lane_id: set(predecessors) for lane_id, predecessors in self.lane_predecessors_dict.items()}\n        parallel_set = {lane_id: set(parallel) for lane_id, parallel in self.parallel_lane_dict.items()}\n\n        intersecting_lanes = {}\n        for i, lane in enumerate(self.lanes.values()):\n            lane_id = lane.idx.lane_id\n\n            # Query spatial index with buffered geometry\n            buffered_centerline = lane.centerline.buffer(buffer)\n            candidates = tree.query(buffered_centerline)\n\n            intersecting_lanes[lane_id] = []\n            for idx in candidates:\n                candidate_id = lane_ids[idx]\n                if (\n                    candidate_id != lane_id\n                    and candidate_id not in successors_set[lane_id]\n                    and candidate_id not in predecessors_set[lane_id]\n                    and candidate_id not in parallel_set[lane_id]\n                    and buffered_centerline.intersects(lane_centerlines[idx])\n                ):\n                    # Only buffer and test intersection for valid candidates\n                    intersecting_lanes[lane_id].append(candidate_id)\n\n        self.intersecting_lanes_dict = intersecting_lanes\n        return intersecting_lanes\n\n    def graph_intersection_detection(self):\n        \"\"\"\n        Detects intersections in a graph of lanes based on their intersections, successors, and predecessors.\n\n        Args:\n            lane_dict (dict): A dictionary where keys are lane indices and values are arrays of intersecting lane indices.\n            lane_successors (dict): A dictionary where keys are lane indices and values are arrays of successor lane indices.\n            lane_predecessors (dict): A dictionary where keys are lane indices and values are arrays of predecessor lane indices.\n\n        Returns:\n            list: A list of intersections, where each intersection is a set of lane indices.\n        \"\"\"\n        # Create a Graph using networkx\n        G = nx.Graph()\n\n        # Add nodes and edges to the graph. If a lane has a intersection, add the lanes as nodes and the intersection as an edge\n        # Add edges directly (nodes are added automatically)\n        for lane_id, intersecting_lanes in self.intersecting_lanes_dict.items():\n            G.add_edges_from((lane_id, other_lane) for other_lane in intersecting_lanes)\n\n        intersections = []\n        for inter in nx.connected_components(G):\n            # Convert lane_ids back to lane objects\n            intersection_lanes = [self.lane_dict[i] for i in inter]\n            intersection = Intersection(intersection_lanes, concave_hull_ratio=self.concave_hull_ratio)\n            intersections.append(intersection)\n\n        self.intersections = intersections\n        self.G = G\n        return intersections, G\n\n    def combine_intersections(self):\n        \"\"\"A function that revieves a list with idx [[1,2] , [4,5,6] , ...] of intersections that need to be combined.\n        It will combine all those intersections and will then update all intersections in the map_segmentation class.\n\n        Args:\n            intersection_list (list): A list of lists, where each inner list contains the indices of intersections to be combined.\n\n        Returns:\n            None\n        \"\"\"\n\n        # Check for intersections that can be combined:\n        combined_intersections = []\n\n        # Create spatial index of all intersection polygons\n        for intersection in self.intersections:\n            if (\n                not hasattr(intersection, \"_buffered_polygon\")\n                or intersection._buffer_value != self.intersection_overlap_buffer\n            ):\n                intersection._buffered_polygon = intersection.polygon.buffer(self.intersection_overlap_buffer)\n                intersection._buffer_value = self.intersection_overlap_buffer\n\n        polygons = [intersection._buffered_polygon for intersection in self.intersections]\n        if polygons:\n            tree = STRtree(polygons)\n\n            # Find overlapping intersections efficiently\n            for i, intersection in enumerate(self.intersections):\n                buffered_poly = polygons[i]\n                candidates = tree.query(buffered_poly)\n\n                for j in candidates:\n                    if i != j and buffered_poly.intersects(polygons[j]):\n                        combined_intersections.append([i, j])\n        final_combined = self.find_resulting_intersections(combined_intersections)\n        new_intersections = []\n        visited = set()\n\n        for combination in final_combined:\n            combined_lanes = []\n            for idx in combination:\n                if idx not in visited:\n                    visited.add(idx)\n                    combined_lanes.extend(self.intersections[idx].lanes)\n\n            new_intersections.append(Intersection(combined_lanes, concave_hull_ratio=self.concave_hull_ratio))\n\n        # Add unvisited intersections\n        for i, intersection in enumerate(self.intersections):\n            if i not in visited:\n                new_intersections.append(intersection)\n\n        self.intersections = new_intersections\n\n    def intersections_overlap(self, intersection1, intersection2, buffer: float = None):\n        \"\"\"\n        Check if two intersections overlap.\n\n        Args:\n            intersection1 (Intersection): The first intersection object.\n            intersection2 (Intersection): The second intersection object.\n\n        Returns:\n            bool: True if the intersections overlap, False otherwise.\n        \"\"\"\n        if buffer is None:\n            buffer = self.intersection_overlap_buffer\n\n        # Use cached buffers if available\n        if not hasattr(intersection1, \"_buffered_polygon\") or intersection1._buffer_value != buffer:\n            intersection1._buffered_polygon = intersection1.polygon.buffer(buffer)\n            intersection1._buffer_value = buffer\n\n        if not hasattr(intersection2, \"_buffered_polygon\") or intersection2._buffer_value != buffer:\n            intersection2._buffered_polygon = intersection2.polygon.buffer(buffer)\n            intersection2._buffer_value = buffer\n\n        return intersection1.polygon.buffer(buffer).intersects(intersection2.polygon.buffer(buffer))\n\n    def combine_intersection_on_polygon(self, intersection1, intersection2):\n        \"\"\"\n        Combine two intersections into one if they overlap.\n        Args:\n            intersection1 (Intersection): The first intersection object.\n            intersection2 (Intersection): The second intersection object.\n        Returns:\n            Intersection: The combined intersection object if they overlap, None otherwise.\n        \"\"\"\n        if self.intersections_overlap(intersection1, intersection2):\n            # Create a new intersection object with the lanes from both intersections\n            combined_intersection = Intersection(\n                intersection1.lanes + intersection2.lanes, concave_hull_ratio=self.concave_hull_ratio\n            )\n\n            return combined_intersection\n        else:\n            return None\n\n    def find_resulting_intersections(self, intersection_pairs):\n        G = nx.Graph()\n        G.add_edges_from(intersection_pairs)\n        return [list(component) for component in nx.connected_components(G)]\n\n    def set_intersection_idx(self):\n        \"\"\"\n        Sets the index for each intersection in the list of intersections.\n        Args:\n            None\n        Returns:\n            None\n        \"\"\"\n        for i, intersection in enumerate(self.intersections + self.isolated_connections):\n            intersection.idx = i\n\n    def create_intersection_dict(self):\n        \"\"\"Creats a dictionary where the key is the intersection id and the value is the intersection object.\n        Args:\n            None\n        Returns:\n            None\n        \"\"\"\n        intersection_dict = {}\n        for i, intersection in enumerate(self.intersections):\n            intersection_dict[intersection.idx] = intersection\n        self.intersection_dict = intersection_dict\n        return intersection_dict\n\n    def add_non_intersecting_lanes_to_intersection(self):\n        \"\"\"Add all lanes that are within the intersection polygon to the intersection object.\n        Args:\n            None\n        Returns:\n            None\n        \"\"\"\n        for intersection in self.intersections:\n            intersection.update_polygon()\n\n            # Collect all lanes to add before modifying the intersection\n            lanes_to_add = []\n            buffered_polygon = intersection.polygon.buffer(self.lane_buffer)\n\n            for lane in self.lanes.values():\n                lane_id = lane.idx.lane_id\n                if (\n                    lane_id not in intersection.lane_ids\n                    and self.lane_segment_dict[lane_id].segment is None\n                    and buffered_polygon.contains(lane.centerline)\n                ):\n                    lanes_to_add.append(lane)\n\n            # Add all lanes at once and update polygon only once\n            if lanes_to_add:\n                intersection.add_lane(lanes=lanes_to_add, update_polygon=True)  # Assuming bulk add method\n\n    def create_lane_segment_dict(self):\n        \"\"\"\n        Create a dictionary mapping lane IDs to their segment information.\n        Args:\n            None\n        Returns:\n            lane_segment_dict (dict): A dictionary mapping lane IDs to their segment information.\n        \"\"\"\n        segment_name = nt(\"SegmentName\", [\"lane_id\", \"segment_idx\", \"segment\"])\n        segment_list = self.intersections + self.isolated_connections\n\n        # Initialize with None values more efficiently\n        lane_segment_dict = {lane_id: segment_name(lane_id, None, None) for lane_id in self.lane_dict.keys()}\n\n        for segment in segment_list:\n            for lane in segment.lanes:\n                lane_id = lane.idx.lane_id\n\n                # Single lookup with caching\n                current_entry = lane_segment_dict.get(lane_id)\n                if current_entry is None:\n                    continue\n\n                if current_entry.segment is None:\n                    # Lane not assigned to any segment yet\n                    lane_segment_dict[lane_id] = segment_name(lane_id, segment.idx, segment)\n                elif current_entry.segment_idx != segment.idx:\n                    # Conflict: lane already assigned to different segment\n                    logger.warning(\n                        f\"Lane {lane_id} already in segment {current_entry.segment_idx}, \"\n                        f\"cannot assign to segment {segment.idx}\"\n                    )\n\n        self.lane_segment_dict = lane_segment_dict\n\n    def create_non_intersecting_lane_graph(self):\n        \"\"\"Create a graph with each lane which is not part of a intersection as a node and the edges are the successors and predecessors of the lanes.\n        Args:\n            None\n        Returns:\n            G (networkx.Graph): A graph with each lane as a node and the edges are the successors and predecessors of the lanes.\n        \"\"\"\n        G = nx.Graph()\n        for lane in self.lanes.values():\n            lane_id = lane.idx.lane_id\n            if lane_id not in self.lane_segment_dict or self.lane_segment_dict[lane_id].segment is None:\n                G.add_node(lane_id)\n                for successor in self.lane_successors_dict[lane_id]:\n                    if successor not in self.lane_segment_dict or self.lane_segment_dict[successor].segment is None:\n                        G.add_edge(lane_id, successor)\n                for predecessor in self.lane_predecessors_dict[lane_id]:\n                    if predecessor not in self.lane_segment_dict or self.lane_segment_dict[predecessor].segment is None:\n                        G.add_edge(lane_id, predecessor)\n        return G\n\n    def find_isolated_connections(self):\n        \"\"\"Find all isolated strings of connections in the graph. Then Check if any of those lanes would be part of an intersection.\n        Args:\n            None\n        Returns:\n            isolated_connections (list): A list of lists, where each inner list contains the indices of lanes that are part of an isolated connection.\n        \"\"\"\n        G = self.create_non_intersecting_lane_graph()\n        isolated_connections = []\n        new_connections = []\n        for component in nx.connected_components(G):\n            if len(component) &gt; 0:\n                isolated_connections.append(\n                    ConnectionSegment(\n                        [self.lane_dict[i] for i in component], concave_hull_ratio=self.concave_hull_ratio\n                    )\n                )\n        # Check if any of the lanes in the isolated connections are part of an intersection\n        for connection in isolated_connections:\n            pre = False\n            suc = False\n            for lane_id in connection.lane_ids:\n                # Check if the lane has a predecessor or successor that is part of an intersection\n                for successor in self.lane_successors_dict[lane_id]:\n                    if successor in self.lane_segment_dict and self.lane_segment_dict[successor].segment is not None:\n                        connection.intersection_idxs.add(self.lane_segment_dict[successor].segment_idx)\n                        suc = True\n                for predecessor in self.lane_predecessors_dict[lane_id]:\n                    if (\n                        predecessor in self.lane_segment_dict\n                        and self.lane_segment_dict[predecessor].segment is not None\n                    ):\n                        connection.intersection_idxs.add(self.lane_segment_dict[predecessor].segment_idx)\n                        pre = True\n\n            if len(connection.intersection_idxs) == 1 and pre and suc:\n                # There is a predecessor and a successor that are part of an intersection so the connection is part of the intersection:\n                # Add all the lanes to the intersection:\n                for lane_id in connection.lane_ids:\n                    self.intersection_dict[list(connection.intersection_idxs)[0]].lanes.append(self.lane_dict[lane_id])\n                    self.intersection_dict[list(connection.intersection_idxs)[0]].lane_ids.append(lane_id)\n                    self.intersection_dict[list(connection.intersection_idxs)[0]].update_polygon()\n            else:\n                new_connections.append(connection)\n\n        isolated_connections = new_connections\n        # Create ConnectionSegment for all lanes, that are on multiple intersections:\n\n        isolated_connections = self.combine_isolated_connections(isolated_connections)\n        return isolated_connections\n\n    def combine_isolated_connections(self, isolated_connections):\n        \"\"\"Check if any of the isolated connections are connecting the same intersections.\n        If yes, then combine them into one connection.\n        Args:\n            isolated_connections (list): A list of ConnectionSegment objects representing isolated connections.\n        Returns:\n            isolated_connections (list): A list of ConnectionSegment objects representing the combined isolated connections.\n        \"\"\"\n        if not isolated_connections:\n            return []\n\n        # Group connections by their intersection indices for efficient comparison\n        connections_by_intersections = {}\n        for i, connection in enumerate(isolated_connections):\n            key = frozenset(connection.intersection_idxs)\n            if key not in connections_by_intersections:\n                connections_by_intersections[key] = []\n            connections_by_intersections[key].append(i)\n\n        combined_connections = []\n\n        # Process each group of connections with same intersection indices\n        for intersection_set, connection_indices in connections_by_intersections.items():\n            if len(connection_indices) &gt; 1:\n                if len(intersection_set) &gt; 1:\n                    # Multiple intersections: combine all connections\n                    for i in range(len(connection_indices)):\n                        for j in range(i + 1, len(connection_indices)):\n                            combined_connections.append([connection_indices[i], connection_indices[j]])\n                else:\n                    # Single intersection: check distance\n                    connections_to_check = [isolated_connections[idx] for idx in connection_indices]\n                    for i in range(len(connections_to_check)):\n                        for j in range(i + 1, len(connections_to_check)):\n                            if connections_to_check[i].polygon.distance(connections_to_check[j].polygon) &lt; 5:\n                                combined_connections.append([connection_indices[i], connection_indices[j]])\n\n        # Rest of the method remains the same\n        final_combined = self.find_resulting_intersections(combined_connections)\n        new_connections = []\n        visited = set()\n\n        for combination in final_combined:\n            combined_lanes = []\n            for idx in combination:\n                if idx not in visited:\n                    visited.add(idx)\n                    combined_lanes.extend(isolated_connections[idx].lanes)\n            new_connections.append(ConnectionSegment(combined_lanes, concave_hull_ratio=self.concave_hull_ratio))\n\n        # Add unvisited connections\n        for i, connection in enumerate(isolated_connections):\n            if i not in visited:\n                new_connections.append(connection)\n\n        self.isolated_connections = new_connections\n        return self.isolated_connections\n\n    def set_lane_intersection_relation(self):\n        \"\"\"\n        Sets the attribute lane.is_approaching true if the lane is connecting to an intersection.\n        Sets the attribute lane.on_intersection true if the lane is part of an intersection.\n        \"\"\"\n        for lane in self.lanes.values():\n            self._set_lane_on_intersection(lane, False)\n            self._set_lane_is_approaching(lane, False)\n\n        # Process intersection lanes and their predecessors efficiently\n        for intersection in self.intersections:\n            # Mark intersection lanes\n            for lane in intersection.lanes:\n                lane_id = self._get_lane_id(lane)\n                if lane_id in self.lanes:\n                    self._set_lane_on_intersection(self.lanes[lane_id], True)\n\n                # Process predecessors for each lane in the intersection\n                for predecessor_id in self._get_lane_predecessors(lane):\n                    if predecessor_id in self.lane_dict:\n                        predecessor = self.lane_dict[predecessor_id]\n                        if not self._get_lane_on_intersection(predecessor):\n                            self._set_lane_is_approaching(predecessor, True)\n\n    def set_lane_trafficlights(self):\n        \"\"\"\n        Sets the traffic lights for each lane of the map.\n        \"\"\"\n        # Create spatial index for lane centerlines\n        lane_centerlines = [lane.centerline for lane in self.lanes.values()]\n        lane_objects = list(self.lanes.values())\n\n        tree = STRtree(lane_centerlines)\n\n        for tl_idx in self.trafficlight:\n            traffic_light_found = False\n\n            # Create traffic light position point\n            tl_point = Point(self.trafficlight[tl_idx].base.position.x, self.trafficlight[tl_idx].base.position.y)\n\n            # Use spatial index to find candidate lanes\n            candidates = tree.nearest(tl_point)\n\n            if candidates:\n                lane = lane_objects[candidates]\n                lane.traffic_light = self.trafficlight[tl_idx]\n                traffic_light_found = True\n\n            if not traffic_light_found:\n                logger.warning(f\"Traffic light {self.trafficlight[tl_idx].id} not found in any lane\")\n\n    def plot(\n        self,\n        output_plot: Path = None,\n        trajectory=None,\n        plot_lane_ids=False,\n        plot_intersection_polygons=False,\n        plot_connection_polygons=False,\n    ):\n        \"\"\"\n        Plots the intersections and saves the plot to the specified output path.\n        A Trajectory can be given to plot it on the map. The Trajectory should be a numpy array of shape (n,3) where each row is (frame, x, y)\n        Args:\n            output_plot (Path): Path to a folder where the plot will be saved. If None, the plot will be shown instead.\n            trajectory (numpy.ndarray): The trajectory to be plotted. If None, no trajectory will be plotted.\n            plot_lane_ids (bool): Whether to plot lane IDs on the map.\n            plot_intersection_polygons (bool): Whether to plot intersection polygons.\n            plot_connection_polygons (bool): Whether to plot connection polygons.\n        Returns:\n            None\n        \"\"\"\n        # Plot the map by plotting all the centerlines:\n        fig, ax = plt.subplots(1, 1)\n        ax.set_aspect(1)\n\n        for lane in self.lanes.values():\n            c = \"blue\"\n            if lane.on_intersection:\n                c = \"green\"\n            elif lane.is_approaching:\n                c = \"orange\"\n            else:\n                c = \"black\"\n            ax.plot(*lane.centerline.xy, color=c, alpha=0.3, zorder=-10)\n\n        if plot_lane_ids:\n            lane_midpoints = [\n                (lane.idx, lane.centerline.interpolate(0.5, normalized=True)) for lane in self.lanes.values()\n            ]\n            for lane_id, midpoint in lane_midpoints:\n                ax.annotate(lane_id, xy=(midpoint.x, midpoint.y), fontsize=2, color=\"black\")\n\n        for inter in self.intersections:\n            ax.annotate(inter.idx, xy=inter.get_center_point(), fontsize=2, color=\"black\")\n\n            if plot_intersection_polygons:\n                # Plot the polygon into the intersection\n                inter.update_polygon()\n                ax.plot(*inter.polygon.exterior.xy, color=\"red\", alpha=0.5, zorder=10)\n\n        for combi in self.isolated_connections:\n            ax.annotate(combi.idx, xy=combi.get_center_point(), fontsize=2, color=\"black\")\n            # Plot the polygon into the intersection\n            if plot_connection_polygons:\n                combi.update_polygon()\n                try:\n                    ax.plot(*combi.polygon.exterior.xy, color=\"blue\", alpha=0.5, zorder=10)\n                except:\n                    logger.warning(f\"Connection {combi.idx} has no polygon\")\n                    pass\n\n        for tl_idx in self.trafficlight:\n            position = shapely.Point(\n                self.trafficlight[tl_idx].base.position.x, self.trafficlight[tl_idx].base.position.y\n            )\n            ax.plot(\n                position.x,\n                position.y,\n                marker=\"o\",\n                color=\"red\",\n                markersize=2,\n                label=f\"Traffic Light {self.trafficlight[tl_idx].id}\",\n            )\n\n        # Plot the trajectory if it is given\n        if trajectory is not None:\n            plt.plot(\n                trajectory[:, 1],\n                trajectory[:, 2],\n                color=\"yellow\",\n                alpha=0.8,\n                linewidth=3,\n                label=\"Host Vehicle Trajectory\",\n            )\n\n            # Mark start and end points\n            plt.plot(trajectory[0, 1], trajectory[0, 2], \"go\", markersize=10, label=\"Start\")\n            plt.plot(trajectory[-1, 1], trajectory[-1, 2], \"ro\", markersize=10, label=\"End\")\n\n        ax.set_xlim(*ax.get_xlim())\n        ax.set_ylim(*ax.get_ylim())\n        plt.title(\"Map with Intersections\")\n        plt.xlabel(\"X Coordinate (m)\", fontsize=12)\n        plt.ylabel(\"Y Coordinate (m)\", fontsize=12)\n        plt.legend()\n        plt.grid(True, alpha=0.3)\n        plt.axis(\"equal\")\n        if output_plot is None:\n            plt.show()\n        else:\n            if isinstance(output_plot, Path):\n                output_plot.mkdir(parents=True, exist_ok=True)\n                plt.savefig(output_plot / \"Map_with_Intersection.pdf\")\n            else:\n                isinstance(output_plot, str)\n                output_path = Path(output_plot)\n                if output_path.is_dir():\n                    output_path.mkdir(parents=True, exist_ok=True)\n                    plt.savefig(output_path / \"Map_with_Intersection.pdf\")\n                elif output_path.suffix == \".pdf\":\n                    output_path.parent.mkdir(parents=True, exist_ok=True)\n                    plt.savefig(output_path)\n        plt.close()\n\n    def plot_intersections(self, output_plot: Path):\n        \"\"\"\n        Plots all intersections and saves them to the output path.\n        Args:\n            output_plot (Path): Path to a folder where the plots will be saved.\n        Returns:\n            None\n        \"\"\"\n        for i, intersection in enumerate(self.intersections):\n            intersection.plot(output_plot)\n        for i, connection in enumerate(self.isolated_connections):\n            connection.plot(output_plot)\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation.add_non_intersecting_lanes_to_intersection","title":"<code>add_non_intersecting_lanes_to_intersection()</code>","text":"<p>Add all lanes that are within the intersection polygon to the intersection object. Args:     None Returns:     None</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def add_non_intersecting_lanes_to_intersection(self):\n    \"\"\"Add all lanes that are within the intersection polygon to the intersection object.\n    Args:\n        None\n    Returns:\n        None\n    \"\"\"\n    for intersection in self.intersections:\n        intersection.update_polygon()\n\n        # Collect all lanes to add before modifying the intersection\n        lanes_to_add = []\n        buffered_polygon = intersection.polygon.buffer(self.lane_buffer)\n\n        for lane in self.lanes.values():\n            lane_id = lane.idx.lane_id\n            if (\n                lane_id not in intersection.lane_ids\n                and self.lane_segment_dict[lane_id].segment is None\n                and buffered_polygon.contains(lane.centerline)\n            ):\n                lanes_to_add.append(lane)\n\n        # Add all lanes at once and update polygon only once\n        if lanes_to_add:\n            intersection.add_lane(lanes=lanes_to_add, update_polygon=True)  # Assuming bulk add method\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation.combine_intersection_on_polygon","title":"<code>combine_intersection_on_polygon(intersection1, intersection2)</code>","text":"<p>Combine two intersections into one if they overlap. Args:     intersection1 (Intersection): The first intersection object.     intersection2 (Intersection): The second intersection object. Returns:     Intersection: The combined intersection object if they overlap, None otherwise.</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def combine_intersection_on_polygon(self, intersection1, intersection2):\n    \"\"\"\n    Combine two intersections into one if they overlap.\n    Args:\n        intersection1 (Intersection): The first intersection object.\n        intersection2 (Intersection): The second intersection object.\n    Returns:\n        Intersection: The combined intersection object if they overlap, None otherwise.\n    \"\"\"\n    if self.intersections_overlap(intersection1, intersection2):\n        # Create a new intersection object with the lanes from both intersections\n        combined_intersection = Intersection(\n            intersection1.lanes + intersection2.lanes, concave_hull_ratio=self.concave_hull_ratio\n        )\n\n        return combined_intersection\n    else:\n        return None\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation.combine_intersections","title":"<code>combine_intersections()</code>","text":"<p>A function that revieves a list with idx [[1,2] , [4,5,6] , ...] of intersections that need to be combined. It will combine all those intersections and will then update all intersections in the map_segmentation class.</p> <p>Parameters:</p> Name Type Description Default <code>intersection_list</code> <code>list</code> <p>A list of lists, where each inner list contains the indices of intersections to be combined.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def combine_intersections(self):\n    \"\"\"A function that revieves a list with idx [[1,2] , [4,5,6] , ...] of intersections that need to be combined.\n    It will combine all those intersections and will then update all intersections in the map_segmentation class.\n\n    Args:\n        intersection_list (list): A list of lists, where each inner list contains the indices of intersections to be combined.\n\n    Returns:\n        None\n    \"\"\"\n\n    # Check for intersections that can be combined:\n    combined_intersections = []\n\n    # Create spatial index of all intersection polygons\n    for intersection in self.intersections:\n        if (\n            not hasattr(intersection, \"_buffered_polygon\")\n            or intersection._buffer_value != self.intersection_overlap_buffer\n        ):\n            intersection._buffered_polygon = intersection.polygon.buffer(self.intersection_overlap_buffer)\n            intersection._buffer_value = self.intersection_overlap_buffer\n\n    polygons = [intersection._buffered_polygon for intersection in self.intersections]\n    if polygons:\n        tree = STRtree(polygons)\n\n        # Find overlapping intersections efficiently\n        for i, intersection in enumerate(self.intersections):\n            buffered_poly = polygons[i]\n            candidates = tree.query(buffered_poly)\n\n            for j in candidates:\n                if i != j and buffered_poly.intersects(polygons[j]):\n                    combined_intersections.append([i, j])\n    final_combined = self.find_resulting_intersections(combined_intersections)\n    new_intersections = []\n    visited = set()\n\n    for combination in final_combined:\n        combined_lanes = []\n        for idx in combination:\n            if idx not in visited:\n                visited.add(idx)\n                combined_lanes.extend(self.intersections[idx].lanes)\n\n        new_intersections.append(Intersection(combined_lanes, concave_hull_ratio=self.concave_hull_ratio))\n\n    # Add unvisited intersections\n    for i, intersection in enumerate(self.intersections):\n        if i not in visited:\n            new_intersections.append(intersection)\n\n    self.intersections = new_intersections\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation.combine_isolated_connections","title":"<code>combine_isolated_connections(isolated_connections)</code>","text":"<p>Check if any of the isolated connections are connecting the same intersections. If yes, then combine them into one connection. Args:     isolated_connections (list): A list of ConnectionSegment objects representing isolated connections. Returns:     isolated_connections (list): A list of ConnectionSegment objects representing the combined isolated connections.</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def combine_isolated_connections(self, isolated_connections):\n    \"\"\"Check if any of the isolated connections are connecting the same intersections.\n    If yes, then combine them into one connection.\n    Args:\n        isolated_connections (list): A list of ConnectionSegment objects representing isolated connections.\n    Returns:\n        isolated_connections (list): A list of ConnectionSegment objects representing the combined isolated connections.\n    \"\"\"\n    if not isolated_connections:\n        return []\n\n    # Group connections by their intersection indices for efficient comparison\n    connections_by_intersections = {}\n    for i, connection in enumerate(isolated_connections):\n        key = frozenset(connection.intersection_idxs)\n        if key not in connections_by_intersections:\n            connections_by_intersections[key] = []\n        connections_by_intersections[key].append(i)\n\n    combined_connections = []\n\n    # Process each group of connections with same intersection indices\n    for intersection_set, connection_indices in connections_by_intersections.items():\n        if len(connection_indices) &gt; 1:\n            if len(intersection_set) &gt; 1:\n                # Multiple intersections: combine all connections\n                for i in range(len(connection_indices)):\n                    for j in range(i + 1, len(connection_indices)):\n                        combined_connections.append([connection_indices[i], connection_indices[j]])\n            else:\n                # Single intersection: check distance\n                connections_to_check = [isolated_connections[idx] for idx in connection_indices]\n                for i in range(len(connections_to_check)):\n                    for j in range(i + 1, len(connections_to_check)):\n                        if connections_to_check[i].polygon.distance(connections_to_check[j].polygon) &lt; 5:\n                            combined_connections.append([connection_indices[i], connection_indices[j]])\n\n    # Rest of the method remains the same\n    final_combined = self.find_resulting_intersections(combined_connections)\n    new_connections = []\n    visited = set()\n\n    for combination in final_combined:\n        combined_lanes = []\n        for idx in combination:\n            if idx not in visited:\n                visited.add(idx)\n                combined_lanes.extend(isolated_connections[idx].lanes)\n        new_connections.append(ConnectionSegment(combined_lanes, concave_hull_ratio=self.concave_hull_ratio))\n\n    # Add unvisited connections\n    for i, connection in enumerate(isolated_connections):\n        if i not in visited:\n            new_connections.append(connection)\n\n    self.isolated_connections = new_connections\n    return self.isolated_connections\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation.create_intersection_dict","title":"<code>create_intersection_dict()</code>","text":"<p>Creats a dictionary where the key is the intersection id and the value is the intersection object. Args:     None Returns:     None</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def create_intersection_dict(self):\n    \"\"\"Creats a dictionary where the key is the intersection id and the value is the intersection object.\n    Args:\n        None\n    Returns:\n        None\n    \"\"\"\n    intersection_dict = {}\n    for i, intersection in enumerate(self.intersections):\n        intersection_dict[intersection.idx] = intersection\n    self.intersection_dict = intersection_dict\n    return intersection_dict\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation.create_lane_segment_dict","title":"<code>create_lane_segment_dict()</code>","text":"<p>Create a dictionary mapping lane IDs to their segment information. Args:     None Returns:     lane_segment_dict (dict): A dictionary mapping lane IDs to their segment information.</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def create_lane_segment_dict(self):\n    \"\"\"\n    Create a dictionary mapping lane IDs to their segment information.\n    Args:\n        None\n    Returns:\n        lane_segment_dict (dict): A dictionary mapping lane IDs to their segment information.\n    \"\"\"\n    segment_name = nt(\"SegmentName\", [\"lane_id\", \"segment_idx\", \"segment\"])\n    segment_list = self.intersections + self.isolated_connections\n\n    # Initialize with None values more efficiently\n    lane_segment_dict = {lane_id: segment_name(lane_id, None, None) for lane_id in self.lane_dict.keys()}\n\n    for segment in segment_list:\n        for lane in segment.lanes:\n            lane_id = lane.idx.lane_id\n\n            # Single lookup with caching\n            current_entry = lane_segment_dict.get(lane_id)\n            if current_entry is None:\n                continue\n\n            if current_entry.segment is None:\n                # Lane not assigned to any segment yet\n                lane_segment_dict[lane_id] = segment_name(lane_id, segment.idx, segment)\n            elif current_entry.segment_idx != segment.idx:\n                # Conflict: lane already assigned to different segment\n                logger.warning(\n                    f\"Lane {lane_id} already in segment {current_entry.segment_idx}, \"\n                    f\"cannot assign to segment {segment.idx}\"\n                )\n\n    self.lane_segment_dict = lane_segment_dict\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation.create_non_intersecting_lane_graph","title":"<code>create_non_intersecting_lane_graph()</code>","text":"<p>Create a graph with each lane which is not part of a intersection as a node and the edges are the successors and predecessors of the lanes. Args:     None Returns:     G (networkx.Graph): A graph with each lane as a node and the edges are the successors and predecessors of the lanes.</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def create_non_intersecting_lane_graph(self):\n    \"\"\"Create a graph with each lane which is not part of a intersection as a node and the edges are the successors and predecessors of the lanes.\n    Args:\n        None\n    Returns:\n        G (networkx.Graph): A graph with each lane as a node and the edges are the successors and predecessors of the lanes.\n    \"\"\"\n    G = nx.Graph()\n    for lane in self.lanes.values():\n        lane_id = lane.idx.lane_id\n        if lane_id not in self.lane_segment_dict or self.lane_segment_dict[lane_id].segment is None:\n            G.add_node(lane_id)\n            for successor in self.lane_successors_dict[lane_id]:\n                if successor not in self.lane_segment_dict or self.lane_segment_dict[successor].segment is None:\n                    G.add_edge(lane_id, successor)\n            for predecessor in self.lane_predecessors_dict[lane_id]:\n                if predecessor not in self.lane_segment_dict or self.lane_segment_dict[predecessor].segment is None:\n                    G.add_edge(lane_id, predecessor)\n    return G\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation.create_parallel_lane_dict","title":"<code>create_parallel_lane_dict()</code>","text":"<p>Creates a dictionary mapping each lane's lane_id to the lane ids which are parallel to it Args:     None Returns:     dict: A dictionary mapping each lane's lane_id to the lane ids which are parallel to it.</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def create_parallel_lane_dict(self):\n    \"\"\"\n    Creates a dictionary mapping each lane's lane_id to the lane ids which are parallel to it\n    Args:\n        None\n    Returns:\n        dict: A dictionary mapping each lane's lane_id to the lane ids which are parallel to it.\n    \"\"\"\n    lane_dict = {lane.idx.lane_id: [] for lane in self.lanes.values()}\n\n    # Precompute lane directions for faster comparisons\n    lane_directions = {}\n    lane_centerlines = []\n    lane_ids = []\n\n    for lane in self.lanes.values():\n        coords = np.array(lane.centerline.coords)\n        direction = coords[-1] - coords[0]\n        lane_directions[lane.idx.lane_id] = direction / np.linalg.norm(direction)\n        lane_centerlines.append(lane.centerline)\n        lane_ids.append(lane.idx.lane_id)\n\n    if not lane_centerlines:\n        return lane_dict\n\n    # Use original centerlines for spatial index, buffer only when needed\n    tree = STRtree(lane_centerlines)\n\n    for i, lane in enumerate(self.lanes.values()):\n        lane_id = lane.idx.lane_id\n\n        # Create buffer only when querying, not storing it\n        buffer_geom = lane.centerline.buffer(10)\n        candidates = tree.query(buffer_geom)\n\n        # Clear the buffer immediately after use\n        del buffer_geom\n\n        for idx in candidates:\n            other_lane_id = lane_ids[idx]\n            if other_lane_id == lane_id:\n                continue\n\n            # Compare directions using dot product\n            dir1 = lane_directions[lane_id]\n            dir2 = lane_directions[other_lane_id]\n            dot_product = np.clip(np.abs(np.dot(dir1, dir2)), -1.0, 1.0)\n            angle_deg = np.degrees(np.arccos(dot_product))\n\n            if angle_deg &lt; 10:\n                lane_dict[lane_id].append(other_lane_id)\n\n    return lane_dict\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation.find_isolated_connections","title":"<code>find_isolated_connections()</code>","text":"<p>Find all isolated strings of connections in the graph. Then Check if any of those lanes would be part of an intersection. Args:     None Returns:     isolated_connections (list): A list of lists, where each inner list contains the indices of lanes that are part of an isolated connection.</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def find_isolated_connections(self):\n    \"\"\"Find all isolated strings of connections in the graph. Then Check if any of those lanes would be part of an intersection.\n    Args:\n        None\n    Returns:\n        isolated_connections (list): A list of lists, where each inner list contains the indices of lanes that are part of an isolated connection.\n    \"\"\"\n    G = self.create_non_intersecting_lane_graph()\n    isolated_connections = []\n    new_connections = []\n    for component in nx.connected_components(G):\n        if len(component) &gt; 0:\n            isolated_connections.append(\n                ConnectionSegment(\n                    [self.lane_dict[i] for i in component], concave_hull_ratio=self.concave_hull_ratio\n                )\n            )\n    # Check if any of the lanes in the isolated connections are part of an intersection\n    for connection in isolated_connections:\n        pre = False\n        suc = False\n        for lane_id in connection.lane_ids:\n            # Check if the lane has a predecessor or successor that is part of an intersection\n            for successor in self.lane_successors_dict[lane_id]:\n                if successor in self.lane_segment_dict and self.lane_segment_dict[successor].segment is not None:\n                    connection.intersection_idxs.add(self.lane_segment_dict[successor].segment_idx)\n                    suc = True\n            for predecessor in self.lane_predecessors_dict[lane_id]:\n                if (\n                    predecessor in self.lane_segment_dict\n                    and self.lane_segment_dict[predecessor].segment is not None\n                ):\n                    connection.intersection_idxs.add(self.lane_segment_dict[predecessor].segment_idx)\n                    pre = True\n\n        if len(connection.intersection_idxs) == 1 and pre and suc:\n            # There is a predecessor and a successor that are part of an intersection so the connection is part of the intersection:\n            # Add all the lanes to the intersection:\n            for lane_id in connection.lane_ids:\n                self.intersection_dict[list(connection.intersection_idxs)[0]].lanes.append(self.lane_dict[lane_id])\n                self.intersection_dict[list(connection.intersection_idxs)[0]].lane_ids.append(lane_id)\n                self.intersection_dict[list(connection.intersection_idxs)[0]].update_polygon()\n        else:\n            new_connections.append(connection)\n\n    isolated_connections = new_connections\n    # Create ConnectionSegment for all lanes, that are on multiple intersections:\n\n    isolated_connections = self.combine_isolated_connections(isolated_connections)\n    return isolated_connections\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation.get_intersecting_lanes","title":"<code>get_intersecting_lanes(buffer=None)</code>","text":"<p>Returns a dictionary mapping each lane's lane_id to an array of lane ids it intersects with.</p> <p>Parameters:</p> Name Type Description Default <code>lanes</code> <code>list</code> <p>Array of lane objects, each with an <code>idx</code> and <code>centerline</code> attribute.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary where keys are lane ids and values are arrays of intersecting lane ids.</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def get_intersecting_lanes(self, buffer: float = None):\n    \"\"\"\n    Returns a dictionary mapping each lane's lane_id to an array of lane ids it intersects with.\n\n    Args:\n        lanes (list): Array of lane objects, each with an `idx` and `centerline` attribute.\n\n    Returns:\n        dict: A dictionary where keys are lane ids and values are arrays of intersecting lane ids.\n    \"\"\"\n    if buffer is None:\n        buffer = self.lane_buffer\n\n    # Create spatial index directly from centerlines\n    lane_centerlines = []\n    lane_ids = []\n\n    for lane in self.lanes.values():\n        lane_centerlines.append(lane.centerline)\n        lane_ids.append(lane.idx.lane_id)\n\n    if not lane_centerlines:\n        self.intersecting_lanes_dict = {}\n        return {}\n\n    tree = STRtree(lane_centerlines)\n\n    # Pre-compute lane relationships for faster lookup\n    successors_set = {lane_id: set(successors) for lane_id, successors in self.lane_successors_dict.items()}\n    predecessors_set = {lane_id: set(predecessors) for lane_id, predecessors in self.lane_predecessors_dict.items()}\n    parallel_set = {lane_id: set(parallel) for lane_id, parallel in self.parallel_lane_dict.items()}\n\n    intersecting_lanes = {}\n    for i, lane in enumerate(self.lanes.values()):\n        lane_id = lane.idx.lane_id\n\n        # Query spatial index with buffered geometry\n        buffered_centerline = lane.centerline.buffer(buffer)\n        candidates = tree.query(buffered_centerline)\n\n        intersecting_lanes[lane_id] = []\n        for idx in candidates:\n            candidate_id = lane_ids[idx]\n            if (\n                candidate_id != lane_id\n                and candidate_id not in successors_set[lane_id]\n                and candidate_id not in predecessors_set[lane_id]\n                and candidate_id not in parallel_set[lane_id]\n                and buffered_centerline.intersects(lane_centerlines[idx])\n            ):\n                # Only buffer and test intersection for valid candidates\n                intersecting_lanes[lane_id].append(candidate_id)\n\n    self.intersecting_lanes_dict = intersecting_lanes\n    return intersecting_lanes\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation.graph_intersection_detection","title":"<code>graph_intersection_detection()</code>","text":"<p>Detects intersections in a graph of lanes based on their intersections, successors, and predecessors.</p> <p>Parameters:</p> Name Type Description Default <code>lane_dict</code> <code>dict</code> <p>A dictionary where keys are lane indices and values are arrays of intersecting lane indices.</p> required <code>lane_successors</code> <code>dict</code> <p>A dictionary where keys are lane indices and values are arrays of successor lane indices.</p> required <code>lane_predecessors</code> <code>dict</code> <p>A dictionary where keys are lane indices and values are arrays of predecessor lane indices.</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>A list of intersections, where each intersection is a set of lane indices.</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def graph_intersection_detection(self):\n    \"\"\"\n    Detects intersections in a graph of lanes based on their intersections, successors, and predecessors.\n\n    Args:\n        lane_dict (dict): A dictionary where keys are lane indices and values are arrays of intersecting lane indices.\n        lane_successors (dict): A dictionary where keys are lane indices and values are arrays of successor lane indices.\n        lane_predecessors (dict): A dictionary where keys are lane indices and values are arrays of predecessor lane indices.\n\n    Returns:\n        list: A list of intersections, where each intersection is a set of lane indices.\n    \"\"\"\n    # Create a Graph using networkx\n    G = nx.Graph()\n\n    # Add nodes and edges to the graph. If a lane has a intersection, add the lanes as nodes and the intersection as an edge\n    # Add edges directly (nodes are added automatically)\n    for lane_id, intersecting_lanes in self.intersecting_lanes_dict.items():\n        G.add_edges_from((lane_id, other_lane) for other_lane in intersecting_lanes)\n\n    intersections = []\n    for inter in nx.connected_components(G):\n        # Convert lane_ids back to lane objects\n        intersection_lanes = [self.lane_dict[i] for i in inter]\n        intersection = Intersection(intersection_lanes, concave_hull_ratio=self.concave_hull_ratio)\n        intersections.append(intersection)\n\n    self.intersections = intersections\n    self.G = G\n    return intersections, G\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation.init_intersections","title":"<code>init_intersections()</code>","text":"<p>Initializes the intersections in the map. Args:     None Returns:     None</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def init_intersections(self):\n    \"\"\"\n    Initializes the intersections in the map.\n    Args:\n        None\n    Returns:\n        None\n    \"\"\"\n    self.create_lane_dict()\n    self.get_lane_successors_and_predecessors()\n    self.parallel_lane_dict = self.create_parallel_lane_dict()\n    self.get_intersecting_lanes()\n    self.set_lane_trafficlights()\n    self.graph_intersection_detection()\n    self.G = add_lanexy_to_graph(self.G, self.lanes)\n    self.set_intersection_idx()\n\n    if self.do_combine_intersections:\n        self.add_non_intersecting_lanes_to_intersection()\n        self.combine_intersections()\n        self.set_intersection_idx()\n        self.create_intersection_dict()\n\n    self.create_lane_segment_dict()\n    self.find_isolated_connections()\n    self.create_lane_segment_dict()\n    self.check_if_all_lanes_are_on_segment()\n    self.update_segment_ids()\n    self.create_lane_segment_dict()\n    self.update_road_ids()\n    self.set_lane_intersection_relation()\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation.intersections_overlap","title":"<code>intersections_overlap(intersection1, intersection2, buffer=None)</code>","text":"<p>Check if two intersections overlap.</p> <p>Parameters:</p> Name Type Description Default <code>intersection1</code> <code>Intersection</code> <p>The first intersection object.</p> required <code>intersection2</code> <code>Intersection</code> <p>The second intersection object.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the intersections overlap, False otherwise.</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def intersections_overlap(self, intersection1, intersection2, buffer: float = None):\n    \"\"\"\n    Check if two intersections overlap.\n\n    Args:\n        intersection1 (Intersection): The first intersection object.\n        intersection2 (Intersection): The second intersection object.\n\n    Returns:\n        bool: True if the intersections overlap, False otherwise.\n    \"\"\"\n    if buffer is None:\n        buffer = self.intersection_overlap_buffer\n\n    # Use cached buffers if available\n    if not hasattr(intersection1, \"_buffered_polygon\") or intersection1._buffer_value != buffer:\n        intersection1._buffered_polygon = intersection1.polygon.buffer(buffer)\n        intersection1._buffer_value = buffer\n\n    if not hasattr(intersection2, \"_buffered_polygon\") or intersection2._buffer_value != buffer:\n        intersection2._buffered_polygon = intersection2.polygon.buffer(buffer)\n        intersection2._buffer_value = buffer\n\n    return intersection1.polygon.buffer(buffer).intersects(intersection2.polygon.buffer(buffer))\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation.plot","title":"<code>plot(output_plot=None, trajectory=None, plot_lane_ids=False, plot_intersection_polygons=False, plot_connection_polygons=False)</code>","text":"<p>Plots the intersections and saves the plot to the specified output path. A Trajectory can be given to plot it on the map. The Trajectory should be a numpy array of shape (n,3) where each row is (frame, x, y) Args:     output_plot (Path): Path to a folder where the plot will be saved. If None, the plot will be shown instead.     trajectory (numpy.ndarray): The trajectory to be plotted. If None, no trajectory will be plotted.     plot_lane_ids (bool): Whether to plot lane IDs on the map.     plot_intersection_polygons (bool): Whether to plot intersection polygons.     plot_connection_polygons (bool): Whether to plot connection polygons. Returns:     None</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def plot(\n    self,\n    output_plot: Path = None,\n    trajectory=None,\n    plot_lane_ids=False,\n    plot_intersection_polygons=False,\n    plot_connection_polygons=False,\n):\n    \"\"\"\n    Plots the intersections and saves the plot to the specified output path.\n    A Trajectory can be given to plot it on the map. The Trajectory should be a numpy array of shape (n,3) where each row is (frame, x, y)\n    Args:\n        output_plot (Path): Path to a folder where the plot will be saved. If None, the plot will be shown instead.\n        trajectory (numpy.ndarray): The trajectory to be plotted. If None, no trajectory will be plotted.\n        plot_lane_ids (bool): Whether to plot lane IDs on the map.\n        plot_intersection_polygons (bool): Whether to plot intersection polygons.\n        plot_connection_polygons (bool): Whether to plot connection polygons.\n    Returns:\n        None\n    \"\"\"\n    # Plot the map by plotting all the centerlines:\n    fig, ax = plt.subplots(1, 1)\n    ax.set_aspect(1)\n\n    for lane in self.lanes.values():\n        c = \"blue\"\n        if lane.on_intersection:\n            c = \"green\"\n        elif lane.is_approaching:\n            c = \"orange\"\n        else:\n            c = \"black\"\n        ax.plot(*lane.centerline.xy, color=c, alpha=0.3, zorder=-10)\n\n    if plot_lane_ids:\n        lane_midpoints = [\n            (lane.idx, lane.centerline.interpolate(0.5, normalized=True)) for lane in self.lanes.values()\n        ]\n        for lane_id, midpoint in lane_midpoints:\n            ax.annotate(lane_id, xy=(midpoint.x, midpoint.y), fontsize=2, color=\"black\")\n\n    for inter in self.intersections:\n        ax.annotate(inter.idx, xy=inter.get_center_point(), fontsize=2, color=\"black\")\n\n        if plot_intersection_polygons:\n            # Plot the polygon into the intersection\n            inter.update_polygon()\n            ax.plot(*inter.polygon.exterior.xy, color=\"red\", alpha=0.5, zorder=10)\n\n    for combi in self.isolated_connections:\n        ax.annotate(combi.idx, xy=combi.get_center_point(), fontsize=2, color=\"black\")\n        # Plot the polygon into the intersection\n        if plot_connection_polygons:\n            combi.update_polygon()\n            try:\n                ax.plot(*combi.polygon.exterior.xy, color=\"blue\", alpha=0.5, zorder=10)\n            except:\n                logger.warning(f\"Connection {combi.idx} has no polygon\")\n                pass\n\n    for tl_idx in self.trafficlight:\n        position = shapely.Point(\n            self.trafficlight[tl_idx].base.position.x, self.trafficlight[tl_idx].base.position.y\n        )\n        ax.plot(\n            position.x,\n            position.y,\n            marker=\"o\",\n            color=\"red\",\n            markersize=2,\n            label=f\"Traffic Light {self.trafficlight[tl_idx].id}\",\n        )\n\n    # Plot the trajectory if it is given\n    if trajectory is not None:\n        plt.plot(\n            trajectory[:, 1],\n            trajectory[:, 2],\n            color=\"yellow\",\n            alpha=0.8,\n            linewidth=3,\n            label=\"Host Vehicle Trajectory\",\n        )\n\n        # Mark start and end points\n        plt.plot(trajectory[0, 1], trajectory[0, 2], \"go\", markersize=10, label=\"Start\")\n        plt.plot(trajectory[-1, 1], trajectory[-1, 2], \"ro\", markersize=10, label=\"End\")\n\n    ax.set_xlim(*ax.get_xlim())\n    ax.set_ylim(*ax.get_ylim())\n    plt.title(\"Map with Intersections\")\n    plt.xlabel(\"X Coordinate (m)\", fontsize=12)\n    plt.ylabel(\"Y Coordinate (m)\", fontsize=12)\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.axis(\"equal\")\n    if output_plot is None:\n        plt.show()\n    else:\n        if isinstance(output_plot, Path):\n            output_plot.mkdir(parents=True, exist_ok=True)\n            plt.savefig(output_plot / \"Map_with_Intersection.pdf\")\n        else:\n            isinstance(output_plot, str)\n            output_path = Path(output_plot)\n            if output_path.is_dir():\n                output_path.mkdir(parents=True, exist_ok=True)\n                plt.savefig(output_path / \"Map_with_Intersection.pdf\")\n            elif output_path.suffix == \".pdf\":\n                output_path.parent.mkdir(parents=True, exist_ok=True)\n                plt.savefig(output_path)\n    plt.close()\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation.plot_intersections","title":"<code>plot_intersections(output_plot)</code>","text":"<p>Plots all intersections and saves them to the output path. Args:     output_plot (Path): Path to a folder where the plots will be saved. Returns:     None</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def plot_intersections(self, output_plot: Path):\n    \"\"\"\n    Plots all intersections and saves them to the output path.\n    Args:\n        output_plot (Path): Path to a folder where the plots will be saved.\n    Returns:\n        None\n    \"\"\"\n    for i, intersection in enumerate(self.intersections):\n        intersection.plot(output_plot)\n    for i, connection in enumerate(self.isolated_connections):\n        connection.plot(output_plot)\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation.set_intersection_idx","title":"<code>set_intersection_idx()</code>","text":"<p>Sets the index for each intersection in the list of intersections. Args:     None Returns:     None</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def set_intersection_idx(self):\n    \"\"\"\n    Sets the index for each intersection in the list of intersections.\n    Args:\n        None\n    Returns:\n        None\n    \"\"\"\n    for i, intersection in enumerate(self.intersections + self.isolated_connections):\n        intersection.idx = i\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation.set_lane_intersection_relation","title":"<code>set_lane_intersection_relation()</code>","text":"<p>Sets the attribute lane.is_approaching true if the lane is connecting to an intersection. Sets the attribute lane.on_intersection true if the lane is part of an intersection.</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def set_lane_intersection_relation(self):\n    \"\"\"\n    Sets the attribute lane.is_approaching true if the lane is connecting to an intersection.\n    Sets the attribute lane.on_intersection true if the lane is part of an intersection.\n    \"\"\"\n    for lane in self.lanes.values():\n        self._set_lane_on_intersection(lane, False)\n        self._set_lane_is_approaching(lane, False)\n\n    # Process intersection lanes and their predecessors efficiently\n    for intersection in self.intersections:\n        # Mark intersection lanes\n        for lane in intersection.lanes:\n            lane_id = self._get_lane_id(lane)\n            if lane_id in self.lanes:\n                self._set_lane_on_intersection(self.lanes[lane_id], True)\n\n            # Process predecessors for each lane in the intersection\n            for predecessor_id in self._get_lane_predecessors(lane):\n                if predecessor_id in self.lane_dict:\n                    predecessor = self.lane_dict[predecessor_id]\n                    if not self._get_lane_on_intersection(predecessor):\n                        self._set_lane_is_approaching(predecessor, True)\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation.set_lane_trafficlights","title":"<code>set_lane_trafficlights()</code>","text":"<p>Sets the traffic lights for each lane of the map.</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def set_lane_trafficlights(self):\n    \"\"\"\n    Sets the traffic lights for each lane of the map.\n    \"\"\"\n    # Create spatial index for lane centerlines\n    lane_centerlines = [lane.centerline for lane in self.lanes.values()]\n    lane_objects = list(self.lanes.values())\n\n    tree = STRtree(lane_centerlines)\n\n    for tl_idx in self.trafficlight:\n        traffic_light_found = False\n\n        # Create traffic light position point\n        tl_point = Point(self.trafficlight[tl_idx].base.position.x, self.trafficlight[tl_idx].base.position.y)\n\n        # Use spatial index to find candidate lanes\n        candidates = tree.nearest(tl_point)\n\n        if candidates:\n            lane = lane_objects[candidates]\n            lane.traffic_light = self.trafficlight[tl_idx]\n            traffic_light_found = True\n\n        if not traffic_light_found:\n            logger.warning(f\"Traffic light {self.trafficlight[tl_idx].id} not found in any lane\")\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation.trajectory_segment_detection","title":"<code>trajectory_segment_detection(trajectory)</code>","text":"<p>Splits a trajectory into segments based on the lane it is located on</p> <p>Parameters:</p> Name Type Description Default <code>trajectory</code> <code>ndarray</code> <p>A NumPy array of shape (n, 3) representing the trajectory, where each row is a (frame, x, y) coordinate.</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>A list of tuples, where each tuple contains a segment of the trajectory and the segment it intersects with.</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def trajectory_segment_detection(self, trajectory):\n    \"\"\"\n    Splits a trajectory into segments based on the lane it is located on\n\n    Args:\n        trajectory (np.ndarray): A NumPy array of shape (n, 3) representing the trajectory, where each row is a (frame, x, y) coordinate.\n\n    Returns:\n        list: A list of tuples, where each tuple contains a segment of the trajectory and the segment it intersects with.\n    \"\"\"\n    segments = []\n    current_segment = []\n    xy = trajectory[:, 1:3]  # Extract x and y coordinates\n    sts = self.locator.xys2sts(xy)\n    lane_ids = sts[\"roadlane_id\"].to_numpy()\n    segment_idx = [self.lane_segment_dict[lane_id.lane_id].segment.idx for lane_id in lane_ids]\n\n    trajectory = np.column_stack((trajectory[:, 0], trajectory[:, 1], trajectory[:, 2], lane_ids, segment_idx))\n\n    # Create spatial index for intersection polygons\n    intersection_polygons = []\n    intersection_ids = []\n    buffer = 5\n\n    for segment in self.segments:\n        if segment.type == MapSegmentType.JUNCTION and hasattr(segment, \"polygon\"):\n            intersection_polygons.append(segment.polygon.buffer(buffer))\n            intersection_ids.append(segment.idx)\n\n    if intersection_polygons:\n        # Use spatial index for efficient intersection queries\n        tree = STRtree(intersection_polygons)\n\n        # Process points in batches for better performance\n        for i, (frame, x, y, _, _) in enumerate(trajectory):\n            point = Point(x, y)\n\n            # Query spatial index instead of checking all polygons\n            candidates = tree.query(point)\n\n            for idx in candidates:\n                if intersection_polygons[idx].contains(point):\n                    trajectory[i, 4] = intersection_ids[idx]\n                    break\n\n    # Rest of the method for creating segments\n    prev_seg_id = -1\n    for i, (frame, x, y, _, segment_idx) in enumerate(trajectory):\n        if prev_seg_id == segment_idx:\n            current_segment.append((frame, x, y))\n        else:\n            if current_segment:\n                segments.append((np.array(current_segment), self.segments[prev_seg_id]))\n            current_segment = [(frame, x, y)]\n            prev_seg_id = segment_idx\n\n    if current_segment:\n        segments.append((np.array(current_segment), self.segments[prev_seg_id]))\n\n    return segments\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation.update_road_ids","title":"<code>update_road_ids()</code>","text":"<p>Updates the road_ids of the lane to the segment ID</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def update_road_ids(self):\n    \"\"\"\n    Updates the road_ids of the lane to the segment ID\n    \"\"\"\n    updates_needed = []\n    old_to_new_mapping = {}\n\n    # First pass: identify what needs to be updated\n    for lane_idx, lane in self.lanes.items():\n        lane_id = lane.idx.lane_id\n        if lane_id in self.lane_segment_dict and self.lane_segment_dict[lane_id].segment is not None:\n            new_road_id = self.lane_segment_dict[lane_id].segment.idx\n            if lane.idx.road_id != new_road_id:\n                new_idx = lane.idx._replace(road_id=new_road_id)\n                updates_needed.append((lane_idx, lane, new_idx))\n                old_to_new_mapping[lane_idx] = new_idx\n\n    # Second pass: apply updates efficiently\n    for old_idx, lane, new_idx in updates_needed:\n        # Update the lane object in place\n        lane.idx = new_idx\n\n        # Only modify dictionary if the key actually changed\n        if old_idx != new_idx:\n            self.lanes[new_idx] = lane\n            del self.lanes[old_idx]\n\n    # Third pass: update all predecessor and successor references\n    for lane in self.lanes.values():\n        # Update predecessor references\n        updated_predecessors = []\n        for pred_id in lane.predecessor_ids:\n            if pred_id in old_to_new_mapping:\n                updated_predecessors.append(old_to_new_mapping[pred_id])\n            else:\n                updated_predecessors.append(pred_id)\n        lane.predecessor_ids = updated_predecessors\n\n        # Update successor references\n        updated_successors = []\n        for succ_id in lane.successor_ids:\n            if succ_id in old_to_new_mapping:\n                updated_successors.append(old_to_new_mapping[succ_id])\n            else:\n                updated_successors.append(succ_id)\n        lane.successor_ids = updated_successors\n\n    # Fourth pass: update internal dictionaries that track relationships\n    self.lane_dict = {lane.idx.lane_id: lane for lane in self.lanes.values()}\n    self.get_lane_successors_and_predecessors()\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.MapOsiCenterlineSegmentation.update_segment_ids","title":"<code>update_segment_ids()</code>","text":"<p>Updates the segment IDs of the map segmentation</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def update_segment_ids(self):\n    \"Updates the segment IDs of the map segmentation\"\n    self.segments = self.intersections + self.isolated_connections\n    for i, segment in enumerate(self.segments):\n        segment.idx = i\n        segment.set_trafficlight()\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.SegmentOsiCenterline","title":"<code>SegmentOsiCenterline</code>","text":"<p>               Bases: <code>Segment</code></p> <p>Segment implementation for OSI centerline-based maps.</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>class SegmentOsiCenterline(Segment):\n    \"\"\"Segment implementation for OSI centerline-based maps.\"\"\"\n\n    def _get_lane_id(self, lane):\n        return lane.idx.lane_id\n\n    def _get_lane_geometry(self, lane) -&gt; shapely.LineString:\n        return lane.centerline\n\n    def set_trafficlight(self):\n        trafficlight = []\n        for lane in self.lanes:\n            if hasattr(lane, \"trafficlight\") and lane.trafficlight:\n                trafficlight.append(lane.trafficlight)\n        self.trafficlights = trafficlight\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.add_lanexy_to_graph","title":"<code>add_lanexy_to_graph(G, lanes)</code>","text":"<p>Adds lane coordinates to the graph as node attributes.</p> <p>Parameters:</p> Name Type Description Default <code>G</code> <code>Graph</code> <p>The graph to which lane coordinates will be added.</p> required <code>lanes</code> <code>dict</code> <p>A dictionary of lane objects.</p> required <p>Returns:</p> Type Description <p>networkx.Graph: The updated graph with lane coordinates as node attributes.</p> Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def add_lanexy_to_graph(G: nx.Graph, lanes):\n    \"\"\"\n    Adds lane coordinates to the graph as node attributes.\n\n    Args:\n        G (networkx.Graph): The graph to which lane coordinates will be added.\n        lanes (dict): A dictionary of lane objects.\n\n    Returns:\n        networkx.Graph: The updated graph with lane coordinates as node attributes.\n    \"\"\"\n    for lane in lanes.values():\n        if lane.idx.lane_id in G.nodes:\n            G.nodes[lane.idx.lane_id][\"x\"] = shapely.centroid(lane.centerline).x\n            G.nodes[lane.idx.lane_id][\"y\"] = shapely.centroid(lane.centerline).y\n    return G\n</code></pre>"},{"location":"api/#omega_prime.maposicenterlinesegmentation.plot_graph","title":"<code>plot_graph(G, output)</code>","text":"<p>Plots the graph with lane coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>G</code> <code>Graph</code> <p>The graph to be plotted.</p> required <code>Path</code> <code>str or Path</code> <p>The file path to save the plot.</p> required Source code in <code>omega_prime/maposicenterlinesegmentation.py</code> <pre><code>def plot_graph(G: nx.Graph, output: Path):\n    \"\"\"\n    Plots the graph with lane coordinates.\n\n    Args:\n        G (networkx.Graph): The graph to be plotted.\n        Path (str or Path): The file path to save the plot.\n    \"\"\"\n    pos = {node: (data[\"x\"], data[\"y\"]) for node, data in G.nodes(data=True)}\n    nx.draw(G, pos, with_labels=True, node_size=10, font_size=5)\n    plt.title(\"Intersection Graph\")\n    plt.xlabel(\"X Coordinate\")  # Add label for the x-axis\n    plt.ylabel(\"Y Coordinate\")  # Add label for the y-axis\n    plt.grid(True)  # Optional: Add a grid for better visualization\n    plt.savefig(Path)\n    plt.close()  # Close the plot to free memory\n</code></pre>"},{"location":"cli/","title":"CLI","text":""},{"location":"cli/#omega-prime","title":"omega-prime","text":"<p>No description available</p>"},{"location":"cli/#usage","title":"Usage","text":"<p><code>omega-prime [OPTIONS] COMMAND [ARGS]...</code></p>"},{"location":"cli/#arguments","title":"Arguments","text":"<p>No arguments available</p>"},{"location":"cli/#options","title":"Options","text":"Name Description Required Default <code>--install-completion</code> Install completion for the current shell. No - <code>--show-completion</code> Show completion for the current shell, to copy it or customize the installation. No - <code>--help</code> Show this message and exit. No -"},{"location":"cli/#commands","title":"Commands","text":"Name Description <code>from-lxd</code> Convert datasets from LevelXData to... <code>from-osi</code> Convert from ASAM OSI GroundTruth trace. <code>from-csv</code> Convert from csv table according to schema <code>validate</code> Check an omega-prime file for... <code>to-odr</code> Extracts the ASAM OpenDRIVE file from the... <code>to-parquet</code> Converts MCAP or OSI omega-prime into a... <code>visualize</code> Visualize an omega-prime recording using... <code>attach-odr</code> Attach an ASAM OpenDRIVE (.xodr) map to an..."},{"location":"cli/#subcommands","title":"Subcommands","text":""},{"location":"cli/#omega-prime-from-lxd","title":"<code>omega-prime from-lxd</code>","text":"<p>Convert datasets from LevelXData to omega-prime.</p>"},{"location":"cli/#usage_1","title":"Usage","text":"<p><code>omega-prime from-lxd [OPTIONS] DATASET_PATH OUTPUT_PATH</code></p>"},{"location":"cli/#arguments_1","title":"Arguments","text":"Name Description Required <code>DATASET_PATH</code> Root of the dataset Yes <code>OUTPUT_PATH</code> In which folder to write the created omega-prime files Yes"},{"location":"cli/#options_1","title":"Options","text":"Name Description Required Default <code>--n-workers INTEGER</code> Set to -1 for n_cpus-1 workers.  [default: 1] No - <code>--save-as-parquet / --no-save-as-parquet</code> If activated, omega-prime recordings will be stored as parquet files instead of mcap (use for large recordings). Will loose information in OSI that are not mandatory in omega-prime.  [default: no-save-as-parquet] No - <code>--skip-existing / --no-skip-existing</code> Only convert not yet converted files  [default: no-skip-existing] No - <code>--write-log / --no-write-log</code> Write a log file with the conversion process  [default: no-write-log] No - <code>--help</code> Show this message and exit. No -"},{"location":"cli/#omega-prime-from-osi","title":"<code>omega-prime from-osi</code>","text":"<p>Convert from ASAM OSI GroundTruth trace.</p>"},{"location":"cli/#usage_2","title":"Usage","text":"<p><code>omega-prime from-osi [OPTIONS] INPUT OUTPUT</code></p>"},{"location":"cli/#arguments_2","title":"Arguments","text":"Name Description Required <code>INPUT</code> Path to ASAM OSI trace file (either <code>.osi</code> or <code>.mcap</code>) Yes <code>OUTPUT</code> Desired filename of omega file Yes"},{"location":"cli/#options_2","title":"Options","text":"Name Description Required Default <code>--map-path FILE</code> Path to ASAM OpenDRIVE xml to use as map No - <code>--validate / --no-validate</code> [default: validate] No - <code>--help</code> Show this message and exit. No -"},{"location":"cli/#omega-prime-from-csv","title":"<code>omega-prime from-csv</code>","text":"<p>Convert from csv table according to schema</p>"},{"location":"cli/#usage_3","title":"Usage","text":"<p><code>omega-prime from-csv [OPTIONS] INPUT OUTPUT</code></p>"},{"location":"cli/#arguments_3","title":"Arguments","text":"Name Description Required <code>INPUT</code> Path to csv according to omega moving object csv schema Yes <code>OUTPUT</code> Desired filename of omega file Yes"},{"location":"cli/#options_3","title":"Options","text":"Name Description Required Default <code>--odr FILE</code> Path to ASAM OpenDRIVE xml to use as map No - <code>--validate / --no-validate</code> [default: validate] No - <code>--help</code> Show this message and exit. No -"},{"location":"cli/#omega-prime-validate","title":"<code>omega-prime validate</code>","text":"<p>Check an omega-prime file for specification conformance.</p>"},{"location":"cli/#usage_4","title":"Usage","text":"<p><code>omega-prime validate [OPTIONS] INPUT</code></p>"},{"location":"cli/#arguments_4","title":"Arguments","text":"Name Description Required <code>INPUT</code> Path to omega file to validate Yes"},{"location":"cli/#options_4","title":"Options","text":"Name Description Required Default <code>--help</code> Show this message and exit. No -"},{"location":"cli/#omega-prime-to-odr","title":"<code>omega-prime to-odr</code>","text":"<p>Extracts the ASAM OpenDRIVE file from the omega-prime file.</p>"},{"location":"cli/#usage_5","title":"Usage","text":"<p><code>omega-prime to-odr [OPTIONS] INPUT [OUTPUT]</code></p>"},{"location":"cli/#arguments_5","title":"Arguments","text":"Name Description Required <code>INPUT</code> Path to the omega-prime mcap file. Yes <code>[OUTPUT]</code> Where to store the ASAM OpenDRIVE file. If None or directory, stored filename will be used. No"},{"location":"cli/#options_5","title":"Options","text":"Name Description Required Default <code>--help</code> Show this message and exit. No -"},{"location":"cli/#omega-prime-to-parquet","title":"<code>omega-prime to-parquet</code>","text":"<p>Converts MCAP or OSI omega-prime into a parquet file (beneficial for faster loading of large data).</p>"},{"location":"cli/#usage_6","title":"Usage","text":"<p><code>omega-prime to-parquet [OPTIONS] INPUT [OUTPUT]</code></p>"},{"location":"cli/#arguments_6","title":"Arguments","text":"Name Description Required <code>INPUT</code> Path to the omega-prime mcap file. Yes <code>[OUTPUT]</code> Where to store the parquet file. If None or directory, stored filename will be used. No"},{"location":"cli/#options_6","title":"Options","text":"Name Description Required Default <code>--help</code> Show this message and exit. No -"},{"location":"cli/#omega-prime-visualize","title":"<code>omega-prime visualize</code>","text":"<p>Visualize an omega-prime recording using Altair. Opens interactive plot in browser.</p>"},{"location":"cli/#usage_7","title":"Usage","text":"<p><code>omega-prime visualize [OPTIONS] INPUT</code></p>"},{"location":"cli/#arguments_7","title":"Arguments","text":"Name Description Required <code>INPUT</code> [required] No"},{"location":"cli/#options_7","title":"Options","text":"Name Description Required Default <code>--height INTEGER</code> [default: 500] No - <code>--width INTEGER</code> [default: 1600] No - <code>--start-frame INTEGER</code> [default: 0] No - <code>--end-frame INTEGER</code> [default: -1] No - <code>--plot-map / --no-plot-map</code> [default: plot-map] No - <code>--use-vegafusion / --no-use-vegafusion</code> [default: no-use-vegafusion] No - <code>--help</code> Show this message and exit. No -"},{"location":"cli/#omega-prime-attach-odr","title":"<code>omega-prime attach-odr</code>","text":"<p>Attach an ASAM OpenDRIVE (.xodr) map to an existing omega-prime recording and write a new file.</p>"},{"location":"cli/#usage_8","title":"Usage","text":"<p><code>omega-prime attach-odr [OPTIONS] INPUT ODR</code></p>"},{"location":"cli/#arguments_8","title":"Arguments","text":"Name Description Required <code>INPUT</code> Path to existing omega-prime file (.mcap or .parquet) Yes <code>ODR</code> Path to ASAM OpenDRIVE .xodr file Yes"},{"location":"cli/#options_8","title":"Options","text":"Name Description Required Default <code>--output PATH</code> Output path (.mcap or .parquet). If not provided, uses '_with_odr.' in the same directory. No - <code>--help</code> Show this message and exit. No -"},{"location":"library/","title":"Overview","text":""},{"location":"library/#recordings-and-map-data","title":"Recordings and Map Data","text":"<p>The omega-prime library has two major components, the <code>Recording</code> and the <code>Map</code>. The <code>Recording</code> stores the dynamic object information and the map object. A recording is a continuous traffic observation and usually corresponds to an OSI trace or an MCAP recording. The dynamic object information is stored in the attribute <code>df</code> (for DataFrame) as a single polars DataFrame, where each row corresponds to the observation of a single moving object at a specific point in time. A convenience function to access this data in an object oriented manner are the <code>MovingObject</code> stored in <code>moving_objects</code> attribute of the <code>Recording</code>. For most operations, it is recommended to use the DataFrame stored in <code>df</code> directly, as polars provides a fast and flexible API for data manipulation. See the Polars user guide for more information on how to use polars DataFrames. The object polygons for each timestamp are accessible as shapely objects in the <code>polygon</code> column or as <code>polars_st</code> geometries in the <code>geometry</code> column. It is recommended to make use of <code>polars_st</code> as much as possible instead of <code>shapely</code> since <code>polars_st</code> can utilize the benefits of using a DataFrame more effectively.</p> <pre><code>flowchart TB\n\n    subgraph recording [Recording]\n        rec_map[map]@{ shape: doc }\n        df@{ shape: win-pane }\n        moving_objects@{ shape: docs } \n    end\n    df -.- moving_objects\n\n    rec_map --&gt; map\n    subgraph map [Map]\n        lane_boundaries@{ shape: docs }\n        lanes@{ shape: docs }\n    end\n\n    subgraph lane [Lane]\n        centerline\n        lane_polygon[polygon]\n        right_boundary_id@{ shape: doc }\n        left_boundary_id@{ shape: doc }\n    end\n\n    subgraph lane_boundary [LaneBoundary]\n        polyline\n    end\n    lanes --&gt; lane\n    lane_boundaries --&gt; lane_boundary\n    right_boundary_id --&gt; lane_boundary\n    left_boundary_id --&gt; lane_boundary\n    polyline -.- lane_polygon\n\n    subgraph moving_object [MovingObject]\n\n    end\n    moving_objects --&gt; moving_object</code></pre> <p>The <code>Map</code> stores the static map information, i.e., lanes and lane boundaries. Lanes and lane boundaries are derived form the ASAM OSI definition and are also corresponding to the concept of lanelets in Lanelet2. When working with the map data in python, the geometries of the map are represented through polygons or polylines (for boundaries and centerlines) using shapely.</p> <p><code>MovingObject</code>, <code>Lane</code> and <code>LaneBoundary</code> each have types and additional information corresponding to ASAM OSI definitions. The library uses betterosi as a python implementation of ASAM OSI.</p> <p>The omega-prime specification suggests the usage of ASAM OpenDRIVE maps as map data. This is supported through the <code>MapOdr</code> subclass of <code>Map</code>.  Additionally, this library provides subclasses for ASAM OSI maps through <code>MapOsi</code> and <code>MapOsiCenterline</code>, where the latter does not provide lane polygons and lane boundaries (which is needed for some datasets). In the future, <code>MapLanelet</code> will provide support for Lanelet2 maps. Thus, a key benefit of using this library is the unified interface to work with different map formats.</p> <p>See Tutorials / Introduction for examples of how to use omega-prime.</p>"},{"location":"library/#converters","title":"Converters","text":"<p>The class <code>omega_prime.converters.DatasetConverter</code> aids in defining converters that transform existing data sources into the omega-prime format. For guidance on how to implement your own converter you can have a look at the <code>LxdConverter</code>, which translates the LevelXData datasets into omega-prime. Additionally, you can have a look at omega-prime-trajdata to convert many motion prediction datasets into the omega-prime format. Examples of datasets that can be converted with <code>omega-prime-trajdata</code> into omega-prime are NuPlan, NuScene, Argoverse2 and Waymo Open Dataset - Motion. Here, the class <code>TrajdataConverter</code> implements the <code>DatasetConverter</code>.</p> <p>Data that is available as ASAM OpenDRIVE and ASAM OSI traces does not need a conversion an can be directly used with <code>omega-prime</code>. Many simulation tools such as esmini or CARLA through Carla-OSI-Service support the logging of simulation data as OSI traces. These can be directly read in and analyzed with the omega-prime library.</p>"},{"location":"library/#locator","title":"Locator","text":"<p>The <code>Locator</code> uses the <code>Map</code> object to locate <code>MovingObject</code>s or any polygon or coordinate onto the <code>Lane</code>s of the map. The <code>Locator</code> can assign lane occupancy to objects and derive s-t-coordinate (Frenet coordinates).</p> <p>See Tutorials / Locator for examples of how to use the <code>Locator</code>.</p>"},{"location":"library/#metrics","title":"Metrics","text":"<p>The <code>MetricsManager</code> makes use of Polars feature of lazy evaulation to enable efficient computation of many, possible, dependent metrics. The metrics computation can be defined by subclassing <code>Metric</code> or, more easily by using the decorator <code>@omega_prime.metrics.metric</code> a function that computes your metric based on the <code>Recording.df</code>. Moreover, the <code>Metric</code> lets you define dependencies between metrics, e.g., <code>distance_traveled</code> needs to be computed to compute <code>timegaps</code>.  The <code>MetricsManager</code> then handles the dependencies automatically, and makes sure only the things you actually need are computed.</p> <p>See Tutorials / Metrics for examples of how to define and use the metric utilities.</p>"},{"location":"omega_prime_specification/","title":"Data Model & Specification","text":""},{"location":"omega_prime_specification/#introduction","title":"Introduction","text":"<p>In the context of SYNERGIES, Scenario Source Data (SSD) corresponds to the data that is provided to WP5 for scenario identification and extraction. Such data can stem from multiple sources: in-traffic-vehicle data collection, fixed or mobile (e.g., drones) roadside observations, dynamic accident reconstruction, but also generative AI, traffic simulation... WP5 itself will also develop multiple approaches to generate scenarios from data. To facilitate interoperability between multiple data sources and multiple scenarios' creation approaches, a standardization of Scenario Source Data needs to be defined, both in terms of content and in terms of container, i.e., format.</p> <p>The format itself is called OMEGA-PRIME. It relies on existing ASAM standards, namely ASAM OpenDRIVE and ASAM Open Simulation Interface. Those allow, respectively, to represent the infrastructure and traffic participants' type, trajectories, and state. The OMEGA-PRIME format also specifies MCAP as the container in which ASAM OpenDRIVE maps and Open Simulation Interface messages are stored (or, in the case of map information, optionally linked to) in a file.</p> <p>Those standards are very flexible, and not all information that can be represented using ASAM OpenDrive and ASAM Open Simulation Interface are required for scenario identification and extraction. Those standards also allow characterizing the same traffic situation in multiple ways, and, especially in the case of Open Simulation Interface, can represent multiple kinds of data.</p> <p>This document therefore defines which features from the aforementioned standards need to be used, and how they should be used, to create a valid OMEGA-PRIME file.</p> <p>It also defines requirements on the content of Scenario Source Data itself, in order to meet sufficient quality for scenario identification and extraction.</p> <p>Notes:</p> <ul> <li>This specification corresponds to a \"least common denominator\", i.e., what is directly needed for scenario identification and extraction, and just that.   Since the underlying standards allow representing and storing more information, users are free to use additional features at their discretion, for their own needs, as long as they respect the minimum set of rules herein defined.</li> <li>In the event that the underlying standards are insufficient, either in terms of features or in terms of documentation (e.g., clarity), the intention of the authors is to collaborate with the standards' maintainers to upstream necessary changes and extensions, rather than inventing yet another incompletely compatible format.</li> </ul>"},{"location":"omega_prime_specification/#requirements-on-scenario-source-data","title":"Requirements on Scenario Source Data","text":"<p>Scenario Source Data contains the following information:</p> <ul> <li>The infrastructure, in the form of a static map,</li> <li>A succession of time-stamped observations of:</li> <li>Environmental conditions (precipitation, illumination, visibility),</li> <li>Properties, states and kinematics of dynamic elements (i.e., traffic participants).</li> </ul> <p>Necessary fields for those categories of information are listed in the subsequent chapter.</p> <p>More importantly, Scenario Source Data shall correspond to consolidated / ground truth data. This implies that raw sensor data is out of the scope of this specification and cannot be accepted as Scenario Source Data. Rather:</p> <ul> <li>Dynamic elements must be consolidated over time:</li> <li>Successive observations of the same traffic participant must be linked by a unique identifier,</li> <li>A traffic participant's classification cannot change over time,</li> <li>Properties describing a traffic participant's shape (i.e.\u00a0its bounding box dimensions) cannot change over time, with the only accepted exception being when the actual participant's shape did change (e.g.\u00a0door opening).</li> <li>They must be properly positioned in relation to the static map.</li> </ul> <p>The creation of such consolidated / ground truth data from raw observations requires complex processing and, in some instance, manual annotation, that depend on the nature of the original data. Such processing may include sensor fusion, object detection and tracking, mapping, geo-referencing... All those operations are out of the scope of this document but need to be performed before Scenario Source Data can be stored and exchanged using OMEGA-PRIME.</p>"},{"location":"omega_prime_specification/#omega-prime-specification","title":"OMEGA-PRIME specification","text":""},{"location":"omega_prime_specification/#rationale-for-the-choice-of-the-underlying-standards","title":"Rationale for the choice of the underlying standards","text":"<p>There exists a multitude of data models and formats that cover the aforementioned information, a selection of established data models and formats is listed below:</p> Name Dynamic Elements Static Map Environmental Information Traffic Light ASAM OSI \u2705 \u2705 \u2705 \u2705 ASAM OpenDRIVE \u2705 Lanelet2 \u2705 Hi-Drive CDF \u2705 OMEGAFormat \u2705 \u2705 \u2705 \u2705 <p>Since it is advisable to base the definitions of data model and data format on already established ones, ASAM OSI 3.7.0 lends itself for the representation of dynamic elements since it is already heavily used for co-simulation data exchange by different simulation platforms. ASAM OpenDRIVE 1.8.1 is the most common non-proprietary standard for defining maps for simulation. Therefore, it should be used to define static maps. The usage of OpenDRIVE is already supported by OSI and has the additional benefit, that OpenDRIVE maps can be directly used in simulation tools and there exists tooling around creating such maps. OSI itself does not enforce what signals have to be set and not what quality those signals need to have (There exists the qc-framework for defining rules on these formats). The OMEGAFormat, which has been defined in the VVMethods project specifically for the task of storing traffic data for the validation of automated vehicles, already established such requirements. Therefore, we propose to remodel the OMEGAFormat through usage of ASAM OSI and ASAM OpenDRIVE. In the following the resulting SSD Specification OMEGA-PRIME is presented.</p>"},{"location":"omega_prime_specification/#omega-prime-specification_1","title":"OMEGA-PRIME Specification","text":"<p>OMEGA-PRIME defines a data model and data format for scenario source data through an extension of ASAM OSI, under usage of ASAM OpenDRIVE. Especially for ASAM OSI it defines the exchange of such files and mandatory signals and quality for the use case of scenario identification and generation. The specification has the explicit goal to upstream extensions made to existing formats when possible.</p> <p>The following sections describe the specification. First, the coordinate system is explained. Then the representation of moving objects through ASAM OSI Ground Truth messages is defined. Lastly, the usage of ASAM OpenDRIVE for information on the map level is specified. Accuracy requirements of signals are derived from the OMEGAFormat.</p>"},{"location":"omega_prime_specification/#coordinate-systems","title":"Coordinate Systems","text":"<p>ASAM OSI and ASAM OpenDRIVE are harmonized in terms of their inertial coordinate system specification (handedness, axis directions and rotation order). The OpenDRIVE 'inertial coordinate system' is defined in the same way as OSI\u2019s 'global coordinate system', relying on the ISO 8855 standard. Both OpenDRIVE and ASAM OSI define further context-related coordinate systems (e.g. road reference line coordinate system in OpenDRIVE, sensor or object coordinate system in OSI). Each standard's documentation must be consulted when working with data structures using these coordinate systems.</p>"},{"location":"omega_prime_specification/#geo-reference","title":"Geo Reference","text":"<p>For both OSI and OpenDRIVE the inertial coordinate system\u2019s origin can be mapped to a geographic coordinate system using PROJ transformations in a harmonized way. Both standards allow the definition of a PROJ-string and a corresponding offset. The offset parameter offers a position (x, y, z) and an orientation offset (yaw/heading). It is recommended by both standards to set the orientation offset to 0. For OMEGA-PRIME real-world datasets, both PROJ-string and offset must be given in every frame of the ASAM OSI GroundTruth message as well as in the ASAM OpenDRIVE map.</p> <p>Note: Pay attention that even if it moves from one observation to the next, this coordinate system never encompasses velocity. Therefore, relative measurements of velocities from a moving observer must not be directly stored in the GroundTruth message but have to be processed first.</p> <p></p> <p>Figure 1: Geo-reference and coordinate system in ASAM OpenDRIVE and ASAM OSI</p>"},{"location":"omega_prime_specification/#dynamic-information","title":"Dynamic Information","text":"<p>For representing object-list based trajectory information of moving elements and the dynamic information of traffic signs, OMEGA-PRIME utilizes ASAM OSI GroundTruth messages. Each GroundTruth message defines one point in time. The dynamic extent of the SSD is therefore be represented through a sequence of OSI GroundTruth messages. To appropriately cover highly dynamic contexts found in urban environments, OMEGA-PRIME sets a minimum required frequency of 10Hz on those messages. Unless stated otherwise, the fields listed in the following table are mandatory in each of the OSI GroundTruth messages. Detailed info about the signal content are found in the ASAM OSI documentation. Additional fields, e.g. as defined in the Open Simulation Interface, are optional. To represent a corresponding sequence of weather observations the OSI message <code>environmental_conditions</code> (contained in OSI GroundTruth) can be filled. The column 'Minimal Accuracy' indicates the desired accuracy of the signal in relation to the real world.</p>"},{"location":"omega_prime_specification/#note-on-field-presence-in-protobuf","title":"Note on Field Presence in Protobuf","text":"<p>With all proto fields being intentionally marked as <code>optional</code> in OSI, field presence is tracked independent of the protobuf version (proto2, proto3). Though, the default value handling (in the case of unset fields) might still cause confusion, e.g., basic type fields are deserialized using their default value (0 for numeric types, false for booleans, zero-valued enumerator for enums, zero-length value for strings, bytes and repeated fields) even if they weren't set during serialization. Hence, to know if a field was intentionally set, the presence checking functionality of the corresponding protobuf implementation (if implemented) can be used. Example: <code>osi3::MovingObject::VehicleClassification::has_trailer</code> is not a mandatory field in the OMEGA-PRIME format. If <code>has_trailer</code> was not set during serialization, it will still resolve to its basic type's default value (<code>false</code>) when deserializing/reading the value. This could theoretically be interpreted to mean that the <code>has_trailer</code> field has been left blank on purpose to indicate <code>false</code> for a reader. Though, it could be checked if the field was actually intendedly set to false using the field presence checking functionality (e.g. <code>msg.HasField('foo')</code> in Python).</p> Signal hierarchy Data model and type Minimal Accuracy map_reference <p>str</p> <p>Content depends on the chosen map association option (see 'OMEGA-PRIME Format Specification').</p> country_code int [3 digit ISO country code (e.g. germany=276,usa=840)]. version InterfaceVersion . version_major int . version_minor int . version_patch int proj_frame_offset GroundTruthProjFrameOffset 0,2 m . position Vector3D 0,2 m . yaw float 0,035 rad (2\u00b0) proj_string <p>str [PROJ coordinate transformation software library]</p> <p>Mandatory for real world data; Can be omitted for simulation data.</p> timestamp Timestamp (total time is combination of seconds and nanos) . nanos int . seconds int host_vehicle_id Identifier . value int moving_object list[MovingObject] . id Identifier . . value int . base BaseMoving . . dimension Dimension3D . . . x float [m] 0,2 m . . . y float [m] 0,2 m . . . z float [m] 0,2 m . . position Vector3D . . . x float [m] 0,2 m . . . y float [m] 0,2 m . . . z float [m] 0,2 m . . orientation Orientation3D . . . roll float [rad] 0,035 rad (2\u00b0) . . . pitch float [rad] 0,035 rad (2\u00b0) . . . yaw float [rad] 0,035 rad (2\u00b0) . . velocity Vector3D 0,1 m/s . . acceleration Vector3D 0,1 m/s^2 . type <p>MovingObjectType</p> <p>(Other, Vehicle, Pedestrian, Animal)</p> . vehicle_classification MovingObjectVehicleClassification . . type <p>MovingObjectVehicleClassificationType</p> <p>(Other, car, delivery van, semitrailer, trailer, motorbike, bicycle, bus, tram, train, wheelchair, standup scooter)</p> . . role <p>MovingObjectVehicleClassificationRole</p> <p>(Other, civil, ambulance, fire, police, public transport, road assistance, garbage  collectin, road construction, military)</p> traffic_light list[TrafficLight] . id Identifier . . value int . base (optional) <p>BaseStationary</p> <p> The position of traffic lights is given in the associated OpenDRIVE map file. If optionally given in the OSI message, it must match the corresponding data in the map file. The association between OSI and OpenDRIVE objects is established using the 'source_reference' field. </p> . classification TrafficLightClassification . . color <p>TrafficLightClassificationColor</p> <p>(Other, red, yellow, green, blue, white)</p> . . icon <p>TrafficLightClassificationIcon</p> <p>(Other, none, arrow_straight_ahead, arrow_left, arrow_diag_left, arrow_straight_ahead_left, arrow_right, ...)</p> . . mode <p>TrafficLightClassificationMode</p> <p>(Other, off, constant, flashing, counting)</p> . . counter float . . is_out_of_servcie bool . source_reference <p>list[ExternalReference]</p> <p>The source reference maps the dynamic OSI traffic light information to the static traffic light information in the OpenDRIVE map.</p>"},{"location":"omega_prime_specification/#static-information","title":"Static Information","text":"<p>The static map information is defined through ASAM OpenDRIVE 1.8.1. The map should contain information on the roads all observed traffic participants are moving on and the respective lanes. This includes information on the junction and road object positions defined by ASAM OpenDRIVE. See the ASAM OpenDRIVE specification on data model and format definitions. When real-world data is represented, the deviation of the modelled geometries to the real-world counterparts should not be larger than 0.2m.</p>"},{"location":"omega_prime_specification/#omega-prime-format-specification","title":"OMEGA-PRIME Format Specification","text":"<p>The OMEGA-PRIME MCAP multi-channel trace file format is a binary file format that allows for storing a serialized specified subset of an OSI GroundTruth message stream, along with additional meta-data, OpenDRIVE map data and other related data streams.</p> <p>OMEGA-PRIME is based on the OSI MCAP multi-channel trace file format and therefore is a specialization with additional constraints and requirements. Hence, any valid OMEGA-PRIME multi-channel trace file is also a valid OSI MCAP file, but not the other way around. This means that an OMEGA-PRIME MCAP file must comply with all constraints and requirements defined in the OSI MCAP format specification. This includes general file writing requirements (e.g. chunk indexing), mandatory file-global metadata definitions (e.g., OSI version, zero time, authors, data sources) as well as mandatory channel-specific metadata for the OSI GroundTruth channel.</p> <p>The following rules apply to OMEGA-PRIME multi-channel trace files:</p> <ul> <li>The OMEGA-PRIME OSI GroundTruth message stream must be stored as a compliant OSI channel as specified by the OSI MCAP format specification.</li> <li>The channel name of the OMEGA-PRIME OSI GroundTruth data must be <code>\\ground_truth</code>.</li> <li>The OMEGA-PRIME OSI GroundTruth message interface must comply with the required subset as defined in the table in section 'Dynamic Information'.</li> <li>The version of the OMEGA-PRIME OSI GroundTruth messages must be &gt;=3.7.0.</li> <li>The message frequency of consecutive OMEGA-PRIME OSI GroundTruth messages must be 10Hz or higher.</li> </ul> <p>The OMEGA-PRIME format specifies two options to store the associated ASAM OpenDRIVE map data:</p> <ul> <li>Option A: Additional MCAP channel which holds a protobuf-encoded message containing a map reference string and the associated ASAM OpenDRIVE map data as specified in the section 'Option A'. </li> <li>Option B: Additional ASAM OpenDRIVE XML file located in the same folder as the OSI GroundTruth MCAP file as specified in the section 'Option B'.</li> </ul> <p>The following rules apply independent of the chosen option: -   The version of the OpenDRIVE map data must be 1.8.1.</p> <p>The following sections specify the rules depending on the chosen option.</p>"},{"location":"omega_prime_specification/#option-a-self-contained-package","title":"Option A: Self-contained Package","text":"<p>Storing map data with object data in a single file has the benefit that there is no chance that the association gets lost or is unclear. This is especially relevant for the exchange of data between parties. Therefore, we suggest storing the map information also in the MCAP file.</p> <p>The OpenDRIVE map should be stored in the MCAP topic <code>/ground_truth_map</code> with the proto MapASAMOpenDRIVE message (specified below). In <code>open_drive_xml</code> store the string content of an OpenDRIVE XML file. <code>map_reference</code> must match the <code>map_reference</code> in the GroundTruth message.</p> <p><pre><code>package osi3;\nmessage MapAsamOpenDrive\n{\n\u00a0 \u00a0 optional  string map_reference = 1;\n\u00a0 \u00a0 optional  string open_drive_xml_content = 2;\n}\n</code></pre>  Figure 2: File structure of OMEGA-PRIME self-contained package - scenario source data file.</p>"},{"location":"omega_prime_specification/#option-b-one-map-multiple-recordings","title":"Option B: One Map \u2013 Multiple Recordings","text":"<p>On the data provider side, it could be useful to just store an instance of the map once, when you have multiple recordings of the same map. This can be useful in settings where you are still iterating the map and do not want to update it in many places. If you use this option, the map file has to be in the same directory (or zip archive level) as the MCAP file and <code>map_reference</code> in the Ground Truth messages must be set to the filename of the ASAM OpenDRIVE file.</p>"},{"location":"omega_prime_specification/#technical-notes","title":"Technical Notes","text":""},{"location":"omega_prime_specification/#why-is-asam-opendrive-used-instead-of-osi-physicallanes-and-laneboundaries-directly","title":"Why is ASAM OpenDRIVE used instead of OSI PhysicalLanes and LaneBoundaries directly?","text":"<p>OSI itself has the option to represent information on lanes and their boundaries. Unfortunately, creating map information in such a way is not widely known and used. Additionally, despite many simulation frameworks providing such data for co-simulation, there is no known, especially no freely available simulation framework, that can take such data as input for creating the virtual worlds in simulation. Currently, the most widely used map format for feeding simulator is OpenDRIVE. Therefore, we define OpenDRIVE as required.</p> <p>On Downstream Tasks of the Scenario Source Data Format, it could be useful to also have the map information directly in OSI. Since it is not useful for every partner to create tooling for this on their own and different interpretations of standards could cause discrepancy.</p>"},{"location":"omega_prime_specification/#how-does-osmp-relate-to-osi-and-omega-prime","title":"How does OSMP relate to OSI and OMEGA-PRIME?","text":"<p>OSMP is the OSI Sensor Model Packaging. It defines how Functional Mock-up Units (FMU) (e.g., Environmental effect model, sensor model, logical models, \u2026) can communicate with the simulation. The communication is performed via OSI messages. Since OMEGA-PRIME also relies on OSI, feeding such models from it is trivial. OMEGA-PRIME is a data model and serialization format; therefore, it does not need to know about any intricacies of OSMP. That would be part of a tool that takes OMEGA-PRIME data and replays it to some models (like generating a OSMPGroundTruthInit from OMEGA-PRIME).</p> <p>The same holds true for a \u201cdynamic view port\u201d. In some cases, OSMP models might be overburdened, if the amount of data provided to them is too large. Therefore, there exist approaches to first filter a relevant subset of data and provide only this subset to the OSMP model. That would be a task of a tooling that reads in OMEGA-PRIME. The OMEGA-PRIME specification should not have such a view port since the goal is to store the \u201cGround truth\u201d and all available information.</p> <p>OSMP might require that the static information is also send and every timestep. This is not respected in OMEGA-PRIME, since, again, OMEGA-PRIME is a serialization format for data exchange and storage. It is task of a reading/parsing tool to take the OMEGA-PRIME and create valid OSMP communication from that. The task is expected to be trivial since OMEGA-PRIME eavily relies on the ASAM OSI specification.</p>"},{"location":"map_segmentation/map_segmentation/","title":"Map Segmentation (omega_prime.map_segmentation)","text":"<p>This document describes the MapSegmentation system used to group map lanes into semantic segments (junctions and non-junction road segments), attach traffic lights, and offer utilities for plotting and trajectory-to-segment mapping.</p> <p>It covers: - Architecture and class hierarchy - What the classes do and the data they expect - The step-by-step processing pipeline - Algorithms and thresholds used - Public API surface and typical usage - Assumptions, limitations, and edge cases</p>"},{"location":"map_segmentation/map_segmentation/#overview","title":"Overview","text":"<p>The map segmentation system uses an abstract base class pattern to support different map types (e.g., OSI full maps, OSI centerline-only maps). The core abstractions are:</p> <ul> <li><code>MapSegmentation</code> (ABC): Base class defining the segmentation pipeline and common operations</li> <li><code>Segment</code> (ABC): Base class for map segments (junctions, connections, etc.)</li> <li><code>MapOsiCenterlineSegmentation</code>: Concrete implementation for OSI centerline maps</li> <li><code>SegmentOsiCenterline</code>: Concrete segment implementation for OSI centerline maps</li> <li><code>Intersection</code> and <code>ConnectionSegment</code>: Specialized segment types</li> </ul>"},{"location":"map_segmentation/map_segmentation/#segment-types","title":"Segment Types","text":"<p>MapSegmentation clusters lanes into segments of type: - JUNCTION (intersections): groups of lanes whose buffered geometries intersect - STRAIGHT (connection segments): connected components of lanes outside junctions - Other types exist in the enum but are not currently assigned by the code (e.g., RAMP_ON, RAMP_OFF, ROUNDABOUT)</p> <p>Each segment has a polygon generated from lane centerlines (concave hull) and may have traffic lights attached. The system also: - Marks lanes as <code>on_intersection</code> or <code>is_approaching</code> (predecessors of intersection lanes) - Assigns traffic lights to nearest lanes - Optionally updates lane <code>road_id</code> to the segment ID - Splits trajectories into segment-wise chunks - Provides plotting utilities for quick inspection</p>"},{"location":"map_segmentation/map_segmentation/#architecture","title":"Architecture","text":""},{"location":"map_segmentation/map_segmentation/#abstract-base-classes","title":"Abstract Base Classes","text":"<p>The system is built on two abstract base classes in <code>mapsegment.py</code>:</p>"},{"location":"map_segmentation/map_segmentation/#segment-abc","title":"<code>Segment</code> (ABC)","text":"<p>Base class for all segment types. Defines abstract methods that must be implemented by concrete segment classes: - <code>_get_lane_id(lane)</code>: Extract lane ID from a lane object - <code>_get_lane_geometry(lane)</code>: Extract geometry (LineString) from a lane object - <code>set_trafficlight()</code>: Set traffic lights for the segment</p> <p>Common functionality provided: - Polygon computation with caching (concave hull with fallback to convex hull) - Lane management (<code>add_lane</code>, lane IDs tracking) - Center point calculation - Time interval analysis for road users on segment</p>"},{"location":"map_segmentation/map_segmentation/#mapsegmentation-abc","title":"<code>MapSegmentation</code> (ABC)","text":"<p>Base class for map segmentation implementations. Defines abstract methods for map-type-specific operations.</p> <p>Common functionality provided: - Lane dictionary creation - Successor/predecessor mapping - Validation that all lanes are assigned to segments</p>"},{"location":"map_segmentation/map_segmentation/#concrete-implementations-for-osi-centerline-maps","title":"Concrete Implementations for OSI Centerline Maps","text":"<p>In <code>maposicenterlinesegmentation.py</code>:</p>"},{"location":"map_segmentation/map_segmentation/#segmentosicenterline","title":"<code>SegmentOsiCenterline</code>","text":"<p>Concrete implementation of <code>Segment</code> for OSI centerline maps.</p>"},{"location":"map_segmentation/map_segmentation/#maposicenterlinesegmentation","title":"<code>MapOsiCenterlineSegmentation</code>","text":"<p>Concrete implementation of <code>MapSegmentation</code> for OSI centerline maps. Implements all abstract methods and provides the full segmentation pipeline including: - Parallel lane detection using spatial indexing - Intersection detection via graph analysis - Connection segment identification - Road ID updates - Trajectory segmentation</p>"},{"location":"map_segmentation/map_segmentation/#intersection-and-connectionsegment","title":"<code>Intersection</code> and <code>ConnectionSegment</code>","text":"<p>Specialized segment classes extending <code>SegmentOsiCenterline</code>: - <code>Intersection</code>: Represents junction segments (type = JUNCTION) - <code>ConnectionSegment</code>: Represents connection segments (type = STRAIGHT), also tracks which intersections it connects</p>"},{"location":"map_segmentation/map_segmentation/#inputs-and-data-model","title":"Inputs and Data Model","text":"<p>The constructor expects a <code>recording</code> object with at least: - <code>recording.map</code>: provides <code>map.lanes</code> (iterable of lane objects) - <code>recording.traffic_light_states</code>: mapping of traffic light states over time (used to discover static traffic lights)</p>"},{"location":"map_segmentation/map_segmentation/#lane-object-requirements-for-osi-centerline-implementation","title":"Lane Object Requirements (for OSI Centerline implementation)","text":"<p>Lane objects are assumed to provide: - <code>lane.idx</code>: a key/index object with fields: <code>.lane_id</code> (unique lane identifier) and <code>.road_id</code> (road grouping id) - <code>lane.centerline</code>: a shapely LineString geometry in meters - <code>lane.successor_ids</code> and <code>lane.predecessor_ids</code>: each item is either a lane ID or an object with <code>.lane_id</code> - Optional attributes set/used by MapSegmentation: <code>lane.on_intersection</code>, <code>lane.is_approaching</code>, and <code>lane.trafficlight</code></p> <p>Note: Different map types may have different lane object requirements. Concrete implementations define how to extract this information via the abstract methods.</p> <p>Coordinate system and units: - All XY coordinates are in meters in a consistent local frame.</p>"},{"location":"map_segmentation/map_segmentation/#configuration-parameters","title":"Configuration Parameters","text":"<p>Constructor parameters (with defaults) for <code>MapOsiCenterlineSegmentation</code>: - <code>lane_buffer</code> (float, default 0.3 m): buffer used to detect intersecting lanes (geometric proximity) - <code>intersection_overlap_buffer</code> (float, default 1.0 m): buffer used to determine when two intersections should be merged - <code>concave_hull_ratio</code> (float, default 0.3): ratio parameter for concave hull polygon generation (range 0-1, where 0 is convex hull and 1 is maximally concave)</p> <p>The base <code>MapSegmentation</code> class also accepts: - <code>concave_hull_ratio</code> (float, default 0.3): passed through to all segment instances for polygon generation</p> <p>Internal thresholds/constants: - Parallel lane search radius: 10 m (buffer around a lane when searching for parallels) - Parallel lane angle threshold: &lt; 10 degrees between centerline directions - Trajectory re-segmentation buffer around intersections: 5 m - Combine isolated connections connecting the same single intersection if polygon distance &lt; 5 m</p>"},{"location":"map_segmentation/map_segmentation/#segments-and-polygons","title":"Segments and Polygons","text":"<p>Each segment is represented by a <code>Segment</code> base class with the following structure: - Holds <code>lanes</code>, <code>lane_ids</code>, <code>trafficlights</code>, <code>idx</code>, <code>type</code> - Computes a polygon once and caches it; polygon is a concave hull of the union of lane centerlines - <code>create_segment_polygon()</code> / <code>update_polygon()</code> maintain cache consistency - Uses abstract methods <code>_get_lane_id()</code> and <code>_get_lane_geometry()</code> to extract lane-specific information</p> <p>Specializations: - <code>Intersection(SegmentOsiCenterline)</code>: <code>type = JUNCTION</code> - <code>ConnectionSegment(SegmentOsiCenterline)</code>: <code>type = STRAIGHT</code>; also tracks <code>intersection_idxs</code> it connects</p> <p>Polygon generation uses <code>concave_hull</code> with ratio <code>0.3</code>. The polygon is re-built when lanes change. If concave hull fails, it falls back to convex hull.</p> <p>Extensibility: To support a new map type, create: 1. A concrete <code>Segment</code> subclass implementing the three abstract methods 2. A concrete <code>MapSegmentation</code> subclass implementing the nine abstract methods 3. Optionally, specialized segment types (like <code>Intersection</code> and <code>ConnectionSegment</code> for OSI centerline maps)</p>"},{"location":"map_segmentation/map_segmentation/#algorithms-and-key-details","title":"Algorithms and Key Details","text":"<ul> <li>Parallel lane detection</li> <li> <p>For each lane, build a 10 m buffer around its centerline, query STRtree of original centerlines, then compare direction vectors (angle &lt; 10\u00b0) to mark as parallel.</p> </li> <li> <p>Intersecting lanes (potential junction membership)</p> </li> <li> <p>For each lane, create a <code>lane_buffer</code>-sized buffer and query STRtree for nearby lanes. Exclude successors, predecessors, and parallels. If candidate centerline intersects the buffer, it is considered intersecting.</p> </li> <li> <p>Intersection detection and merging</p> </li> <li>Build a graph where nodes are lanes and edges indicate geometric intersection; connected components form <code>Intersection</code> objects.</li> <li>Merge intersections whose polygons overlap when buffered by <code>intersection_overlap_buffer</code> to avoid fragmented junctions.</li> <li> <p>Add non-intersecting lanes that are contained within the buffered intersection polygon.</p> </li> <li> <p>Connection segments</p> </li> <li>For lanes not assigned to intersections, build a graph linking successors and predecessors; connected components form <code>ConnectionSegment</code> objects.</li> <li> <p>If multiple connection components connect the same pair(s) of intersections, merge them. If they relate to a single intersection, merge when polygons are within 5 m.</p> </li> <li> <p>Traffic lights</p> </li> <li> <p>From <code>recording.traffic_light_states</code>, unique traffic lights are collected and assigned to the nearest lane (via STRtree nearest query on centerlines).</p> </li> <li> <p>Trajectory segmentation</p> </li> <li><code>trajectory_segment_detection(trajectory)</code> maps a timestamped trajectory (n x 3: frame/time, x, y) to lane IDs via <code>Locator.xys2sts</code>, then to segment indices, and refines intersection assignment using buffered intersection polygons. Returns a list of tuples (trajectory_chunk, segment_object).</li> </ul>"},{"location":"map_segmentation/map_segmentation/#public-api-summary","title":"Public API Summary","text":""},{"location":"map_segmentation/map_segmentation/#base-classes-for-extension","title":"Base Classes (for extension)","text":"<ul> <li><code>MapSegmentation(recording)</code> (ABC)</li> <li>Abstract base class for map segmentation implementations.</li> <li>Subclasses must implement 9 abstract methods for map-type-specific operations.</li> <li> <p>Provides common functionality: lane dictionaries, successor/predecessor mapping, validation.</p> </li> <li> <p><code>Segment(lanes, idx=None)</code> (ABC)</p> </li> <li>Abstract base class for segment implementations.</li> <li>Subclasses must implement 3 abstract methods for lane-specific operations.</li> <li>Provides polygon computation, caching, lane management, and road user analysis.</li> </ul>"},{"location":"map_segmentation/map_segmentation/#concrete-implementation-for-osi-centerline-maps","title":"Concrete Implementation for OSI Centerline Maps","text":"<ul> <li><code>MapOsiCenterlineSegmentation(recording, lane_buffer=0.3, intersection_overlap_buffer=1.0, concave_hull_ratio=0.3)</code></li> <li>Create a segmentation object from a recording/map with OSI centerline lanes.</li> <li>Implements all abstract methods from <code>MapSegmentation</code>.</li> <li> <p><code>concave_hull_ratio</code>: Controls the shape of segment polygons (0=convex, 1=maximally concave).</p> </li> <li> <p><code>init_intersections()</code></p> </li> <li> <p>Run the full pipeline to populate intersections, connections, polygons, lane flags, traffic light mapping, and segment indices.</p> </li> <li> <p><code>trajectory_segment_detection(trajectory: np.ndarray) -&gt; list[(np.ndarray, Segment)]</code></p> </li> <li> <p>Split a time-ordered trajectory into segment-wise chunks; each chunk is an array of (time, x, y).</p> </li> <li> <p><code>plot(output_plot=None, trajectory=None, plot_lane_ids=False, plot_intersection_polygons=False, plot_connection_polygons=False)</code></p> </li> <li> <p>Plot lanes and segments; optionally render polygons and annotate IDs. If <code>output_plot</code> is a Path, saves a PDF.</p> </li> <li> <p><code>plot_intersections(output_plot)</code></p> </li> <li>Plot each intersection/connection into separate PDFs.</li> </ul>"},{"location":"map_segmentation/map_segmentation/#segment-classes","title":"Segment Classes","text":"<ul> <li><code>SegmentOsiCenterline(lanes, idx=None, concave_hull_ratio=0.3)</code></li> <li> <p>Concrete segment implementation for OSI centerline maps.</p> </li> <li> <p><code>Intersection(lanes, idx=None, concave_hull_ratio=0.3)</code></p> </li> <li> <p>Specialized segment for junctions (extends <code>SegmentOsiCenterline</code>).</p> </li> <li> <p><code>ConnectionSegment(lanes, idx=None, concave_hull_ratio=0.3)</code></p> </li> <li>Specialized segment for connections (extends <code>SegmentOsiCenterline</code>).</li> </ul>"},{"location":"map_segmentation/map_segmentation/#assumptions-and-limitations","title":"Assumptions and Limitations","text":"<ul> <li>Geometry and units</li> <li>Coordinates are meters in a consistent local frame; lane centerlines are valid shapely LineStrings.</li> <li> <p>The concave hull at ratio 0.3 yields sensible junction polygons; highly irregular geometries may need tuning.</p> </li> <li> <p>Topology</p> </li> <li>Successor/predecessor IDs are consistent with lane IDs (or objects exposing <code>.lane_id</code>).</li> <li> <p>Parallel lanes share a similar direction; 10\u00b0 threshold may not capture very slight divergence or reversible lanes.</p> </li> <li> <p>Spatial thresholds</p> </li> <li><code>lane_buffer</code> (default 0.3 m) controls when lanes are deemed intersecting; maps with larger lane spacing may need higher values.</li> <li> <p><code>intersection_overlap_buffer</code> (default 1.0 m) controls intersection merging; too small can fragment, too large can over-merge.</p> </li> <li> <p>Traffic lights</p> </li> <li> <p>Assignment is nearest-centerline based. Complex lane-level signal mapping is out of scope.</p> </li> <li> <p>Road ID updates</p> </li> <li> <p><code>update_road_ids()</code> reassigns <code>lane.idx.road_id</code> to the segment index, modifies <code>lane.idx</code> and updates dict keys and successor/predecessor references. If external code relies on original road IDs or lane indices as dict keys, ensure compatibility before enabling this behavior downstream.</p> </li> <li> <p>Performance</p> </li> <li> <p>Uses STRtree spatial indices for near-neighbor queries. Still, very large maps may require tuning buffer sizes.</p> </li> <li> <p>Robustness and warnings</p> </li> <li>If a lane is encountered in more than one segment, a warning is printed and the assignment is not duplicated.</li> <li> <p>If no lanes or traffic lights exist, the pipeline degrades gracefully (empty structures).</p> </li> <li> <p>Map type specific implementations</p> </li> <li>Currently, only OSI centerline maps are fully implemented (<code>MapOsiCenterlineSegmentation</code>).</li> <li>To support other map types, implement the abstract methods in new subclasses of <code>MapSegmentation</code> and <code>Segment</code>.</li> </ul>"},{"location":"map_segmentation/map_segmentation/#edge-cases-to-consider","title":"Edge Cases to Consider","text":"<ul> <li>Empty map (no lanes): all data structures remain empty; plotting produces a blank map.</li> <li>Degenerate or extremely short centerlines: parallel detection and hull computation can be unstable; ensure valid geometries.</li> <li>Very dense lane networks: increase <code>lane_buffer</code> and <code>intersection_overlap_buffer</code> prudently to avoid over-fragmentation.</li> <li>Miswired predecessors/successors: can impact approaching-lane marking and connection grouping.</li> <li>Trajectories straddling polygon boundaries: buffered checks attempt to align intersection membership; adjust <code>buffer=5</code> in <code>trajectory_segment_detection</code> if needed.</li> </ul>"},{"location":"map_segmentation/map_segmentation/#extensibility-notes","title":"Extensibility Notes","text":"<ul> <li>Supporting new map types</li> <li>Create a concrete <code>Segment</code> subclass implementing:<ul> <li><code>_get_lane_id(lane)</code>: Extract lane ID</li> <li><code>_get_lane_geometry(lane)</code>: Extract lane geometry (LineString)</li> <li><code>set_trafficlight()</code>: Set traffic lights for the segment</li> </ul> </li> <li>Create a concrete <code>MapSegmentation</code> subclass implementing:<ul> <li><code>_get_lane_id(lane)</code>: Extract lane ID</li> <li><code>_get_lane_centerline(lane)</code>: Extract centerline</li> <li><code>_get_lane_successors(lane)</code>: Extract successor IDs</li> <li><code>_get_lane_predecessors(lane)</code>: Extract predecessor IDs</li> <li><code>_has_traffic_light(lane)</code>: Check for traffic light</li> <li><code>_get_traffic_light(lane)</code>: Get traffic light object</li> <li><code>_set_lane_on_intersection(lane, value)</code>: Set intersection flag</li> <li><code>_set_lane_is_approaching(lane, value)</code>: Set approaching flag</li> <li><code>_get_lane_on_intersection(lane)</code>: Get intersection status</li> </ul> </li> <li> <p>Optionally override methods like <code>init_intersections()</code> if the pipeline needs customization.</p> </li> <li> <p>Additional segment types</p> </li> <li> <p>The enum <code>MapSegmentType</code> includes non-used types (ramp_on, ramp_off, roundabout). You can add classifiers to set <code>segment.type</code> based on topology/geometry.</p> </li> <li> <p>Alternative polygon generation</p> </li> <li> <p>Swap concave hull for convex hull or buffered union, or adapt concave hull ratio per segment size by overriding <code>_compute_segment_polygon()</code> in your <code>Segment</code> subclass.</p> </li> <li> <p>Better traffic light mapping</p> </li> <li> <p>Replace nearest-lane heuristic with spatial joins to stop lines or explicit topology by overriding <code>set_lane_trafficlights()</code>.</p> </li> <li> <p>Visualization</p> </li> <li>Add tiled basemaps or interactive inspection leveraging geopandas/folium if appropriate by extending the <code>plot()</code> methods.</li> </ul>"},{"location":"notebooks/tutorial/","title":"Inroduction","text":"In\u00a0[\u00a0]: Copied! <pre>import omega_prime\n\nr = omega_prime.Recording.from_file(\n    \"../../example_files/pedestrian.osi\", map_path=\"../../example_files/fabriksgatan.xodr\", apply_proj=False\n)\nr.to_mcap(\"example.mcap\")\n</pre> import omega_prime  r = omega_prime.Recording.from_file(     \"../../example_files/pedestrian.osi\", map_path=\"../../example_files/fabriksgatan.xodr\", apply_proj=False ) r.to_mcap(\"example.mcap\") <p>If you have large amount of data (e.g., 32.000 objects over a whole day), we suggest using the Apache Parquet file format to store omega-prime data. To do so run the following</p> In\u00a0[11]: Copied! <pre>r.to_parquet(\"example.parquet\")\n</pre> r.to_parquet(\"example.parquet\") <p>Parquet files created with the method can be loaded with the <code>from_file</code> function</p> In\u00a0[12]: Copied! <pre>r = omega_prime.Recording.from_file(\"example.parquet\")\n</pre> r = omega_prime.Recording.from_file(\"example.parquet\") <p>You can also directly create a recording from object data in table form (we use polars). Create a table <code>df</code> like the following:</p> total_nanos idx x y z vel_x vel_y vel_z acc_x acc_y acc_z length width height roll pitch yaw type role subtype 0 0 42.6987 -69.8783 0.75 -2.04032 9.78964 0 0 0 0 5.04 2 1.5 0 0 1.77627 2 0 4 0 1 35.6784 -23.5705 0.923 0 0 0 0 0 0 0.6 0.5 1.8 0 0 1.7984 3 -1 -1 3.3e+07 0 42.6306 -69.5554 0.75 -2.04288 9.78896 0 -0.0774077 -0.020523 0 5.04 2 1.5 0 0 1.7768 2 0 4 3.3e+07 1 35.6784 -23.5705 0.923 0 0 0 0 0 0 0.6 0.5 1.8 0 0 1.7984 3 -1 -1 6.6e+07 0 42.5623 -69.2325 0.75 -2.04801 9.7879 0 -0.155563 -0.0323452 0 5.04 2 1.5 0 0 1.77732 2 0 4 6.6e+07 1 35.6784 -23.5705 0.923 0 0 0 0 0 0 0.6 0.5 1.8 0 0 1.7984 3 -1 -1 <p><code>type</code>, <code>subtyp</code> and <code>role</code> have to be integers and correspond to the enumerations <code>betterosi.MovingObjectType</code>, <code>betterosi.MovingObjectVehicleClassificationType</code> and <code>betterosi.MovingObjectVehicleClassificationRole</code>. The <code>role</code> and <code>subtype</code> have to be <code>-1</code> when the <code>type</code> is not of <code>TYPE_VEHICLE</code>.</p> <p>The enumartions are defined as shown below.</p> In\u00a0[13]: Copied! <pre>import betterosi\n\nprint(f\"MovingObjectType: { ({o.name: o.value for o in betterosi.MovingObjectType}) }\")\nprint(\n    f\"MovingObjectVehicleClassificationType: { ({o.name: o.value for o in betterosi.MovingObjectVehicleClassificationType}) }\"\n)\nprint(\n    f\"MovingObjectVehicleClassificationRole: { ({o.name: o.value for o in betterosi.MovingObjectVehicleClassificationRole}) }\"\n)\n</pre> import betterosi  print(f\"MovingObjectType: { ({o.name: o.value for o in betterosi.MovingObjectType}) }\") print(     f\"MovingObjectVehicleClassificationType: { ({o.name: o.value for o in betterosi.MovingObjectVehicleClassificationType}) }\" ) print(     f\"MovingObjectVehicleClassificationRole: { ({o.name: o.value for o in betterosi.MovingObjectVehicleClassificationRole}) }\" ) <pre>MovingObjectType: {'UNKNOWN': 0, 'OTHER': 1, 'VEHICLE': 2, 'PEDESTRIAN': 3, 'ANIMAL': 4}\nMovingObjectVehicleClassificationType: {'UNKNOWN': 0, 'OTHER': 1, 'SMALL_CAR': 2, 'COMPACT_CAR': 3, 'CAR': 4, 'LUXURY_CAR': 5, 'DELIVERY_VAN': 6, 'HEAVY_TRUCK': 7, 'SEMITRACTOR': 16, 'SEMITRAILER': 8, 'TRAILER': 9, 'MOTORBIKE': 10, 'BICYCLE': 11, 'BUS': 12, 'TRAM': 13, 'TRAIN': 14, 'WHEELCHAIR': 15, 'STANDUP_SCOOTER': 17}\nMovingObjectVehicleClassificationRole: {'UNKNOWN': 0, 'OTHER': 1, 'CIVIL': 2, 'AMBULANCE': 3, 'FIRE': 4, 'POLICE': 5, 'PUBLIC_TRANSPORT': 6, 'ROAD_ASSISTANCE': 7, 'GARBAGE_COLLECTION': 8, 'ROAD_CONSTRUCTION': 9, 'MILITARY': 10}\n</pre> In\u00a0[14]: Copied! <pre>import polars as pl\n\nimport omega_prime\n\ndf = pl.read_csv(\"../../example_files/example.csv\")\nr = omega_prime.Recording(df=df, map=omega_prime.MapOdr.from_file(\"../../example_files/fabriksgatan.xodr\"))\n</pre> import polars as pl  import omega_prime  df = pl.read_csv(\"../../example_files/example.csv\") r = omega_prime.Recording(df=df, map=omega_prime.MapOdr.from_file(\"../../example_files/fabriksgatan.xodr\")) In\u00a0[15]: Copied! <pre>import omega_prime\n</pre> import omega_prime <p>By default the map information is not parsed. For parsing the map we utilize pyxodr. To directly parse the map you have to set <code>parse_map=True</code>.</p> In\u00a0[16]: Copied! <pre>r = omega_prime.Recording.from_file(\"example.mcap\", parse_map=True, apply_proj=False)\nax = r.plot()\nax.set_xlim(-20, 50)\nax.set_ylim(-75, 20)\n</pre> r = omega_prime.Recording.from_file(\"example.mcap\", parse_map=True, apply_proj=False) ax = r.plot() ax.set_xlim(-20, 50) ax.set_ylim(-75, 20) Out[16]: <pre>(-75.0, 20.0)</pre> In\u00a0[17]: Copied! <pre>ax = r.plot_frame(10)\nax.set_xlim(-20, 50)\nax.set_ylim(-75, 20)\n</pre> ax = r.plot_frame(10) ax.set_xlim(-20, 50) ax.set_ylim(-75, 20) Out[17]: <pre>(-75.0, 20.0)</pre> In\u00a0[18]: nbval-ignore-output nbval-skip Copied! <pre>r.plot_altair(start_frame=0, end_frame=400, metric_column=\"vel_y\", idx=0)\n</pre> r.plot_altair(start_frame=0, end_frame=400, metric_column=\"vel_y\", idx=0) Out[18]: In\u00a0[19]: nbval-ignore-output Copied! <pre>r.map\n</pre> r.map Out[19]: <pre>&lt;omega_prime.map_odr.MapOdr at 0x1a4592b8310&gt;</pre> In\u00a0[20]: nbval-ignore-output Copied! <pre>r.moving_objects\n</pre> r.moving_objects Out[20]: <pre>{0: &lt;omega_prime.recording.MovingObject at 0x1a49e847450&gt;,\n 1: &lt;omega_prime.recording.MovingObject at 0x1a4a021f110&gt;}</pre> In\u00a0[21]: Copied! <pre>r.interpolate(hz=10)\nr.interpolate(new_nanos=[0, int(1e8), int(2e8), int(3e8)])\n</pre> r.interpolate(hz=10) r.interpolate(new_nanos=[0, int(1e8), int(2e8), int(3e8)]) In\u00a0[3]: nbval-ignore-output Copied! <pre>!omega-prime --help\n</pre> !omega-prime --help <pre>                                                                               \n Usage: omega-prime [OPTIONS] COMMAND [ARGS]...                                \n                                                                               \n\u250c\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 --install-completion          Install completion for the current shell.     \u2502\n\u2502 --show-completion             Show completion for the current shell, to     \u2502\n\u2502                               copy it or customize the installation.        \u2502\n\u2502 --help                        Show this message and exit.                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u250c\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 from-lxd     Convert datasets from LevelXData to omega-prime.               \u2502\n\u2502 from-osi     Convert from ASAM OSI GroundTruth trace.                       \u2502\n\u2502 from-csv     Convert from csv table according to schema                     \u2502\n\u2502 validate     Check an omega-prime file for specification conformance.       \u2502\n\u2502 to-odr       Extracts the ASAM OpenDRIVE file from the omega-prime file.    \u2502\n\u2502 to-parquet   Converts MCAP or OSI omega-prime into a parquet file           \u2502\n\u2502              (beneficial for faster loading of large data).                 \u2502\n\u2502 visualize    Visualize an omega-prime recording using Altair. Opens         \u2502\n\u2502              interactive plot in browser.                                   \u2502\n\u2502 attach-odr   Attach an ASAM OpenDRIVE (.xodr) map to an existing            \u2502\n\u2502              omega-prime recording and write a new file.                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n</pre> In\u00a0[4]: nbval-ignore-output Copied! <pre>!omega-prime from-osi --help\n</pre> !omega-prime from-osi --help <pre>                                                                               \n Usage: omega-prime from-osi [OPTIONS] INPUT OUTPUT                            \n                                                                               \n Convert from ASAM OSI GroundTruth trace.                                      \n                                                                               \n\u250c\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 *    input       FILE  Path to ASAM OSI trace file (either `.osi` or        \u2502\n\u2502                        `.mcap`)                                             \u2502\n\u2502                        [required]                                           \u2502\n\u2502 *    output      FILE  Desired filename of omega file [required]            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u250c\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 --map-path                     FILE  Path to ASAM OpenDRIVE xml to use as   \u2502\n\u2502                                      map                                    \u2502\n\u2502 --validate    --no-validate          [default: validate]                    \u2502\n\u2502 --help                               Show this message and exit.            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n</pre> In\u00a0[2]: nbval-ignore-output Copied! <pre>!omega-prime from-osi ./../../example_files/pedestrian.osi example.mcap --map-path ./../../example_files/fabriksgatan.xodr\n</pre> !omega-prime from-osi ./../../example_files/pedestrian.osi example.mcap --map-path ./../../example_files/fabriksgatan.xodr In\u00a0[6]: nbval-ignore-output Copied! <pre>!omega-prime from-csv --help\n</pre> !omega-prime from-csv --help <pre>                                                                               \n Usage: omega-prime from-csv [OPTIONS] INPUT OUTPUT                            \n                                                                               \n Convert from csv table according to schema                                    \n                                                                               \n\u250c\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 *    input       FILE  Path to csv according to omega moving object csv     \u2502\n\u2502                        schema                                               \u2502\n\u2502                        [required]                                           \u2502\n\u2502 *    output      FILE  Desired filename of omega file [required]            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u250c\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 --odr                          FILE  Path to ASAM OpenDRIVE xml to use as   \u2502\n\u2502                                      map                                    \u2502\n\u2502 --validate    --no-validate          [default: validate]                    \u2502\n\u2502 --help                               Show this message and exit.            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n</pre> In\u00a0[7]: nbval-ignore-output Copied! <pre>!omega-prime from-csv ./../../example_files/example.csv example.mcap --odr ./../../example_files/fabriksgatan.xodr\n</pre> !omega-prime from-csv ./../../example_files/example.csv example.mcap --odr ./../../example_files/fabriksgatan.xodr In\u00a0[8]: nbval-ignore-output Copied! <pre>!omega-prime validate --help\n</pre> !omega-prime validate --help <pre>                                                                               \n Usage: omega-prime validate [OPTIONS] INPUT                                   \n                                                                               \n Check an omega-prime file for specification conformance.                      \n                                                                               \n\u250c\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 *    input      FILE  Path to omega file to validate [required]             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u250c\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 --help          Show this message and exit.                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n</pre> In\u00a0[9]: nbval-ignore-output Copied! <pre>!omega-prime validate ./example.mcap\n</pre> !omega-prime validate ./example.mcap <pre>File example.mcap is valid.\n</pre>"},{"location":"notebooks/tutorial/#omega-prime-tutorial-for-using-the-python-library","title":"omega-prime: Tutorial for using the python library\u00b6","text":""},{"location":"notebooks/tutorial/#create-omega-prime-files","title":"Create omega-prime files\u00b6","text":"<p>To create files in accordance with the omega-prime specification, you need the map information as ASAM OpenDRIVE XML and the infomration on dynamic elements as ASAM OSI GroundTruth messages. Alternatively, the information on dynamic elements can be provided as a table.</p>"},{"location":"notebooks/tutorial/#create-from-asam-osi","title":"Create from ASAM OSI\u00b6","text":"<p>The following code creates a omega-prime file from an ASAM OSI trace file (e.g., created from esmini (see example_files/README.md)) and an ASAM OpenDRIVE map.</p>"},{"location":"notebooks/tutorial/#create-from-table","title":"Create from table\u00b6","text":""},{"location":"notebooks/tutorial/#read-and-plot-omega-prime-file","title":"Read and plot omega-prime file\u00b6","text":""},{"location":"notebooks/tutorial/#plot-using-altair","title":"Plot using Altair\u00b6","text":"<p>You can create interactive plots with altair using <code>plot_altair</code> function of the recording. If using the the function in a non notebook environment use <code>import altair as alt; alt.renderers.enable(\"browser\")</code> to enable blotting in a browser and call <code>.show()</code> on the resulting chart.</p>"},{"location":"notebooks/tutorial/#file-validation","title":"File Validation\u00b6","text":"<p>By default, data is validated on file reading which takes time. to skip validation read the file with <code>omega_prime.Recording.from_file(..., validate=False)</code></p>"},{"location":"notebooks/tutorial/#interpolation","title":"Interpolation\u00b6","text":"<p>A simple (angle aware) linear (nearest neighbour for classification type data) interpolation function is build in</p>"},{"location":"notebooks/tutorial/#cli-usage","title":"CLI usage\u00b6","text":""},{"location":"notebooks/tutorial/#create-omega-file-from-asam-osi-and-asam-opendrive","title":"Create Omega file from ASAM OSI and ASAM OpenDRIVE\u00b6","text":""},{"location":"notebooks/tutorial/#create-omega-file-from-csv-and-asam-opendrive","title":"Create Omega file from CSV and ASAM OpenDRIVE\u00b6","text":""},{"location":"notebooks/tutorial/#validation-check-of-omega-file","title":"Validation check of omega file\u00b6","text":""},{"location":"notebooks/tutorial_locator/","title":"Locator","text":"In\u00a0[1]: Copied! <pre>import omega_prime\nimport numpy as np\n</pre> import omega_prime import numpy as np In\u00a0[\u00a0]: Copied! <pre>r = omega_prime.Recording.from_file(\n    \"../../example_files/pedestrian.osi\", map_path=\"../../example_files/fabriksgatan.xodr\", apply_proj=False\n)\n</pre> r = omega_prime.Recording.from_file(     \"../../example_files/pedestrian.osi\", map_path=\"../../example_files/fabriksgatan.xodr\", apply_proj=False ) In\u00a0[3]: Copied! <pre>locator = omega_prime.Locator.from_map(r.map)\n</pre> locator = omega_prime.Locator.from_map(r.map) In\u00a0[4]: nbval-ignore-output Copied! <pre>mv = r.moving_objects[1]\nmv\n</pre> mv = r.moving_objects[1] mv Out[4]: <pre>&lt;omega_prime.recording.MovingObject at 0x1e92d67d910&gt;</pre> In\u00a0[16]: nbval-ignore-output Copied! <pre>sts = locator.locate_mv(mv)\nprint(\n    f\"s[0]: {np.asarray(sts.s[0])}\\nt[0]: {np.asarray(sts.t[0])}\\nroadlane_id[0]: {np.asarray(sts.roadlane_id[0])}\\ntime[0]: {np.asarray(sts.time[0])}\"\n)\n</pre> sts = locator.locate_mv(mv) print(     f\"s[0]: {np.asarray(sts.s[0])}\\nt[0]: {np.asarray(sts.t[0])}\\nroadlane_id[0]: {np.asarray(sts.roadlane_id[0])}\\ntime[0]: {np.asarray(sts.time[0])}\" ) <pre>s[0]: 14.864804534670384\nt[0]: -0.49999423398891507\nroadlane_id[0]: XodrLaneId(road_id='0', lane_id=3, section_id=0)\ntime[0]: 0\n</pre> In\u00a0[17]: nbval-ignore-output Copied! <pre>sts_poly = locator.locate_mv(mv, use_polygon=True)\nprint(\n    f\"s[0]: {np.asarray(sts_poly.s[0])}\\nt[0]: {np.asarray(sts_poly.t[0])}\\nroadlane_id[0]: {np.asarray(sts_poly.roadlane_id[0])}\\ntime[0]: {np.asarray(sts_poly.time[0])}\"\n)\n</pre> sts_poly = locator.locate_mv(mv, use_polygon=True) print(     f\"s[0]: {np.asarray(sts_poly.s[0])}\\nt[0]: {np.asarray(sts_poly.t[0])}\\nroadlane_id[0]: {np.asarray(sts_poly.roadlane_id[0])}\\ntime[0]: {np.asarray(sts_poly.time[0])}\" ) <pre>s[0]: 14.864804534670384\nt[0]: -0.49999423398891507\nroadlane_id[0]: XodrLaneId(road_id='0', lane_id=3, section_id=0)\ntime[0]: 0\n</pre> In\u00a0[18]: Copied! <pre>derived_xys = locator.sts2xys(sts)\nderived_xys_poly = locator.sts2xys(sts_poly)\nderived_xys_poly.shape\n</pre> derived_xys = locator.sts2xys(sts) derived_xys_poly = locator.sts2xys(sts_poly) derived_xys_poly.shape Out[18]: <pre>(434, 2)</pre> In\u00a0[19]: nbval-ignore-output Copied! <pre>np.max(np.linalg.norm(derived_xys_poly - mv.df[\"x\", \"y\"].to_numpy(), axis=1))\n</pre> np.max(np.linalg.norm(derived_xys_poly - mv.df[\"x\", \"y\"].to_numpy(), axis=1)) Out[19]: <pre>np.float64(2.0727719536908503e-05)</pre> In\u00a0[22]: Copied! <pre># %matplotlib ipympl\n# pip install ipympl\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.patches import Polygon as PltPolygon\n\n_, ax = plt.subplots(1, 1)\n\nfor lid, l in r.map.lanes.items():\n    ax.add_patch(PltPolygon(l.polygon.exterior.coords, fc=\"blue\", alpha=0.2, ec=\"blue\"))\nax.plot(*mv.df[\"x\", \"y\"].to_numpy().T, label=\"xys\", c=\"green\")\nax.plot(*derived_xys_poly.T, label=\"derived_xys_based_on_polygon\", c=\"yellow\", linestyle=\"dashed\")\nax.plot(*derived_xys.T, label=\"derived_xys\", c=\"red\", linestyle=\"dotted\")\nax.autoscale()\nax.set_aspect(1)\nax.legend(loc=\"lower center\")\nax.set_xlim(-10, 50)\nax.set_ylim(-75, 0)\n</pre> # %matplotlib ipympl # pip install ipympl import numpy as np from matplotlib import pyplot as plt from matplotlib.patches import Polygon as PltPolygon  _, ax = plt.subplots(1, 1)  for lid, l in r.map.lanes.items():     ax.add_patch(PltPolygon(l.polygon.exterior.coords, fc=\"blue\", alpha=0.2, ec=\"blue\")) ax.plot(*mv.df[\"x\", \"y\"].to_numpy().T, label=\"xys\", c=\"green\") ax.plot(*derived_xys_poly.T, label=\"derived_xys_based_on_polygon\", c=\"yellow\", linestyle=\"dashed\") ax.plot(*derived_xys.T, label=\"derived_xys\", c=\"red\", linestyle=\"dotted\") ax.autoscale() ax.set_aspect(1) ax.legend(loc=\"lower center\") ax.set_xlim(-10, 50) ax.set_ylim(-75, 0) Out[22]: <pre>(-75.0, 0.0)</pre> In\u00a0[21]: Copied! <pre>sts11 = locator.xys2lane_sts(lane_id=omega_prime.map_odr.XodrLaneId(\"0\", 1, 0), xys=mv.df[\"x\", \"y\"].to_numpy())\nsts11.shape\n</pre> sts11 = locator.xys2lane_sts(lane_id=omega_prime.map_odr.XodrLaneId(\"0\", 1, 0), xys=mv.df[\"x\", \"y\"].to_numpy()) sts11.shape Out[21]: <pre>(434, 2)</pre>"},{"location":"notebooks/tutorial_locator/#create-a-locator-object","title":"Create a Locator object\u00b6","text":""},{"location":"notebooks/tutorial_locator/#locate-an-object-on-the-map","title":"Locate an object on the Map\u00b6","text":""},{"location":"notebooks/tutorial_locator/#precision-loss-of-locator","title":"Precision loss of Locator\u00b6","text":""},{"location":"notebooks/tutorial_map/","title":"Map Segmentation","text":"In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport omega_prime\nfrom pathlib import Path\n\noutput_path = Path.cwd() / \"tutorial_map_output\"\noutput_path.mkdir(parents=True, exist_ok=True)\n\nfile = Path.cwd() / \"../../example_files\" / \"osi_map_example.mcap\"\n</pre> import numpy as np import omega_prime from pathlib import Path  output_path = Path.cwd() / \"tutorial_map_output\" output_path.mkdir(parents=True, exist_ok=True)  file = Path.cwd() / \"../../example_files\" / \"osi_map_example.mcap\" In\u00a0[\u00a0]: Copied! <pre># Load the MCAP file with advanced configuration\nprint(f\"Loading MCAP file: {file.name}\")\nprint(f\"File exists: {file.exists()}\")\n\nif file.exists():\n    # Create recording object with advanced options\n    r = omega_prime.Recording.from_file(\n        filepath=file,\n        split_lanes=False,  # Split lanes\n        split_lanes_length=10,  # Split lanes to a max length of 10 meters\n    )\n\n    print(f\"Recording loaded successfully!\")\n    print(f\"Number of moving objects: {len(r.moving_objects)}\")\n    print(f\"Host vehicle index: {r.host_vehicle_idx}\")\n    print(f\"Map has {len(r.map.lanes)} lanes\")\n    print(\n        f\"Recording duration: {r.moving_objects[r.host_vehicle_idx]._df['total_nanos'].max() - r.moving_objects[r.host_vehicle_idx]._df['total_nanos'].min()} nanoseconds\"\n    )\nelse:\n    print(\"\u26a0\ufe0f  MCAP file not found. Please check the path.\")\n</pre> # Load the MCAP file with advanced configuration print(f\"Loading MCAP file: {file.name}\") print(f\"File exists: {file.exists()}\")  if file.exists():     # Create recording object with advanced options     r = omega_prime.Recording.from_file(         filepath=file,         split_lanes=False,  # Split lanes         split_lanes_length=10,  # Split lanes to a max length of 10 meters     )      print(f\"Recording loaded successfully!\")     print(f\"Number of moving objects: {len(r.moving_objects)}\")     print(f\"Host vehicle index: {r.host_vehicle_idx}\")     print(f\"Map has {len(r.map.lanes)} lanes\")     print(         f\"Recording duration: {r.moving_objects[r.host_vehicle_idx]._df['total_nanos'].max() - r.moving_objects[r.host_vehicle_idx]._df['total_nanos'].min()} nanoseconds\"     ) else:     print(\"\u26a0\ufe0f  MCAP file not found. Please check the path.\") In\u00a0[\u00a0]: Copied! <pre>if file.exists():\n    # Create map segments - this is the core functionality we're demonstrating\n    print(\"\ud83d\uddfa\ufe0f  Creating map segments...\")\n    r.create_mapsegments()\n\n    # Access the mapsegment object\n    mapsegment = r.mapsegment\n\n    # Create locator for coordinate transformations\n    locator = omega_prime.Locator.from_map(r.map)\n\n    print(f\"\u2705 Map segmentation completed!\")\n    print(f\"\ud83d\udccd Locator initialized!\")\n\n    # Display basic information about the map segmentation\n    print(f\"\\n\ud83d\udcca Map Segmentation Summary:\")\n    print(f\"   \u2022 Total intersections detected: {len(mapsegment.intersections)}\")\n    print(f\"   \u2022 Total isolated connections: {len(mapsegment.isolated_connections)}\")\n    print(f\"   \u2022 Total segments: {len(mapsegment.segments)}\")\n    print(f\"   \u2022 Lane buffer size: {mapsegment.lane_buffer}\")\n    print(f\"   \u2022 Intersection overlap buffer: {mapsegment.intersection_overlap_buffer}\")\n\n    # Show intersection details\n    for i, intersection in enumerate(mapsegment.intersections):\n        print(\n            f\"   \ud83d\udea6 Intersection {intersection.idx}: {len(intersection.lanes)} lanes, type: {intersection.type} with {len(intersection.trafficlights)} traffic lights\"\n        )\n\n    # Show connection details\n    for i, connection in enumerate(mapsegment.isolated_connections):\n        print(\n            f\"   \ud83d\udee4\ufe0f  Connection {connection.idx}: {len(connection.lanes)} lanes, type: {connection.type} with {len(connection.trafficlights)} traffic lights\"\n        )\nelse:\n    print(\"\u26a0\ufe0f  Cannot proceed without MCAP file\")\n</pre> if file.exists():     # Create map segments - this is the core functionality we're demonstrating     print(\"\ud83d\uddfa\ufe0f  Creating map segments...\")     r.create_mapsegments()      # Access the mapsegment object     mapsegment = r.mapsegment      # Create locator for coordinate transformations     locator = omega_prime.Locator.from_map(r.map)      print(f\"\u2705 Map segmentation completed!\")     print(f\"\ud83d\udccd Locator initialized!\")      # Display basic information about the map segmentation     print(f\"\\n\ud83d\udcca Map Segmentation Summary:\")     print(f\"   \u2022 Total intersections detected: {len(mapsegment.intersections)}\")     print(f\"   \u2022 Total isolated connections: {len(mapsegment.isolated_connections)}\")     print(f\"   \u2022 Total segments: {len(mapsegment.segments)}\")     print(f\"   \u2022 Lane buffer size: {mapsegment.lane_buffer}\")     print(f\"   \u2022 Intersection overlap buffer: {mapsegment.intersection_overlap_buffer}\")      # Show intersection details     for i, intersection in enumerate(mapsegment.intersections):         print(             f\"   \ud83d\udea6 Intersection {intersection.idx}: {len(intersection.lanes)} lanes, type: {intersection.type} with {len(intersection.trafficlights)} traffic lights\"         )      # Show connection details     for i, connection in enumerate(mapsegment.isolated_connections):         print(             f\"   \ud83d\udee4\ufe0f  Connection {connection.idx}: {len(connection.lanes)} lanes, type: {connection.type} with {len(connection.trafficlights)} traffic lights\"         ) else:     print(\"\u26a0\ufe0f  Cannot proceed without MCAP file\") In\u00a0[\u00a0]: Copied! <pre>if file.exists():\n    print(\"\ud83d\udd0d Exploring Mapsegmentation Capabilities:\")\n\n    # Check if all lanes are assigned to segments\n    all_lanes_assigned = mapsegment.check_if_all_lanes_are_on_segment()\n    print(f\"   \u2705 All lanes assigned to segments: {all_lanes_assigned}\")\n\n    # Analyze lane relationships\n    print(f\"\\n\ud83d\udee3\ufe0f  Lane Analysis:\")\n    print(f\"   \u2022 Total lanes in map: {len(mapsegment.lanes)}\")\n    print(f\"   \u2022 Lane dictionary size: {len(mapsegment.lane_dict)}\")\n    print(f\"   \u2022 Lanes with successors: {len(mapsegment.lane_successors_dict)}\")\n    print(f\"   \u2022 Lanes with predecessors: {len(mapsegment.lane_predecessors_dict)}\")\n\n    # Display sample lane information\n    sample_lane_ids = list(mapsegment.lane_dict.keys())[:2]\n    for lane_id in sample_lane_ids:\n        lane = mapsegment.lane_dict[lane_id]\n        successors = mapsegment.lane_successors_dict.get(lane_id, [])\n        predecessors = mapsegment.lane_predecessors_dict.get(lane_id, [])\n\n        print(f\"   \ud83d\udee4\ufe0f  Lane {lane_id}:\")\n        print(f\"      - Successors: {len(successors)} lanes\")\n        print(f\"      - Predecessors: {len(predecessors)} lanes\")\n\n        # Check if lane is assigned to a segment\n        if lane_id in mapsegment.lane_segment_dict:\n            segment_info = mapsegment.lane_segment_dict[lane_id]\n            if segment_info.segment is not None:\n                print(f\"      - Assigned to segment: {segment_info.segment_idx} (type: {segment_info.segment.type})\")\n            else:\n                print(f\"      - Not assigned to any segment\")\n\n    # Analyze intersections in detail\n    print(f\"\\n\ud83d\udea6 Intersection Details:\")\n    if intersection := mapsegment.intersections[0]:\n        center = intersection.get_center_point()\n        print(f\"   Intersection {intersection.idx}:\")\n        print(f\"      - Center point: ({center[0]:.2f}, {center[1]:.2f})\")\n        print(f\"      - Number of lanes: {len(intersection.lanes)}\")\n        print(f\"      - Lane IDs: {intersection.lane_ids[:5]}...\")  # Show first 5 lane IDs\n        print(f\"      - Polygon area: {intersection.polygon.area:.2f} sq units\")\n\n        # Check for traffic lights\n        if intersection.trafficlights:\n            print(f\"      - Has traffic light: Yes\")\n        else:\n            print(f\"      - Has traffic light: No\")\nelse:\n    print(\"\u26a0\ufe0f  Cannot proceed without MCAP file\")\n</pre> if file.exists():     print(\"\ud83d\udd0d Exploring Mapsegmentation Capabilities:\")      # Check if all lanes are assigned to segments     all_lanes_assigned = mapsegment.check_if_all_lanes_are_on_segment()     print(f\"   \u2705 All lanes assigned to segments: {all_lanes_assigned}\")      # Analyze lane relationships     print(f\"\\n\ud83d\udee3\ufe0f  Lane Analysis:\")     print(f\"   \u2022 Total lanes in map: {len(mapsegment.lanes)}\")     print(f\"   \u2022 Lane dictionary size: {len(mapsegment.lane_dict)}\")     print(f\"   \u2022 Lanes with successors: {len(mapsegment.lane_successors_dict)}\")     print(f\"   \u2022 Lanes with predecessors: {len(mapsegment.lane_predecessors_dict)}\")      # Display sample lane information     sample_lane_ids = list(mapsegment.lane_dict.keys())[:2]     for lane_id in sample_lane_ids:         lane = mapsegment.lane_dict[lane_id]         successors = mapsegment.lane_successors_dict.get(lane_id, [])         predecessors = mapsegment.lane_predecessors_dict.get(lane_id, [])          print(f\"   \ud83d\udee4\ufe0f  Lane {lane_id}:\")         print(f\"      - Successors: {len(successors)} lanes\")         print(f\"      - Predecessors: {len(predecessors)} lanes\")          # Check if lane is assigned to a segment         if lane_id in mapsegment.lane_segment_dict:             segment_info = mapsegment.lane_segment_dict[lane_id]             if segment_info.segment is not None:                 print(f\"      - Assigned to segment: {segment_info.segment_idx} (type: {segment_info.segment.type})\")             else:                 print(f\"      - Not assigned to any segment\")      # Analyze intersections in detail     print(f\"\\n\ud83d\udea6 Intersection Details:\")     if intersection := mapsegment.intersections[0]:         center = intersection.get_center_point()         print(f\"   Intersection {intersection.idx}:\")         print(f\"      - Center point: ({center[0]:.2f}, {center[1]:.2f})\")         print(f\"      - Number of lanes: {len(intersection.lanes)}\")         print(f\"      - Lane IDs: {intersection.lane_ids[:5]}...\")  # Show first 5 lane IDs         print(f\"      - Polygon area: {intersection.polygon.area:.2f} sq units\")          # Check for traffic lights         if intersection.trafficlights:             print(f\"      - Has traffic light: Yes\")         else:             print(f\"      - Has traffic light: No\") else:     print(\"\u26a0\ufe0f  Cannot proceed without MCAP file\") In\u00a0[\u00a0]: Copied! <pre>if file.exists():\n    print(\"\ud83d\ude97 Extracting Host Vehicle Trajectory Data:\")\n\n    # Get host vehicle ID\n    host_id = r.host_vehicle_idx\n    print(f\"   Host vehicle ID: {host_id}\")\n\n    # Extract trajectory data (converting Polars Series to NumPy arrays)\n    host_vehicle = r.moving_objects[host_id]\n\n    x_values = host_vehicle.x.to_numpy()\n    y_values = host_vehicle.y.to_numpy()\n    frame_values = host_vehicle._df[\"frame\"].to_numpy()\n\n    positions = np.column_stack((frame_values, x_values, y_values))\n\n    segments = mapsegment.trajectory_segment_detection(positions)\n\n    # Analyze segment detection results\n    segment_types = {}\n    valid_segments = 0\n    unassigned_segments = 0\n\n    for i, segment in enumerate(segments):\n        if len(segment) &gt; 1 and segment[1] is not None:\n            valid_segments += 1\n            seg_type = segment[1].type if hasattr(segment[1], \"type\") else \"UNKNOWN\"\n            segment_types[seg_type] = segment_types.get(seg_type, 0) + 1\n        else:\n            unassigned_segments += 1\n\n    print(f\"\\n\ud83d\udcc8 Segment Detection Summary:\")\n    print(f\"   \u2022 Valid segments: {valid_segments}\")\n    print(f\"   \u2022 Unassigned segments: {unassigned_segments}\")\n    print(f\"   \u2022 Segment types detected:\")\n    for seg_type, count in segment_types.items():\n        print(f\"     - {seg_type}: {count} segments\")\n\n    # Show detailed segment information\n    print(f\"\\n\ud83d\udd0d Detailed Segment Information (first 10):\")\n    for i, segment in enumerate(segments[:10]):\n        if len(segment) &gt; 1 and segment[1] is not None:\n            seg_obj = segment[1]\n            seg_type = seg_obj.type if hasattr(seg_obj, \"type\") else \"UNKNOWN\"\n            seg_idx = seg_obj.idx if hasattr(seg_obj, \"idx\") else \"N/A\"\n            print(f\"   Segment {i}: ID={seg_idx}, Type={seg_type}\")\n        else:\n            print(f\"   Segment {i}: Unassigned trajectory segment\")\nelse:\n    print(\"\u26a0\ufe0f  Cannot proceed without MCAP file\")\n</pre> if file.exists():     print(\"\ud83d\ude97 Extracting Host Vehicle Trajectory Data:\")      # Get host vehicle ID     host_id = r.host_vehicle_idx     print(f\"   Host vehicle ID: {host_id}\")      # Extract trajectory data (converting Polars Series to NumPy arrays)     host_vehicle = r.moving_objects[host_id]      x_values = host_vehicle.x.to_numpy()     y_values = host_vehicle.y.to_numpy()     frame_values = host_vehicle._df[\"frame\"].to_numpy()      positions = np.column_stack((frame_values, x_values, y_values))      segments = mapsegment.trajectory_segment_detection(positions)      # Analyze segment detection results     segment_types = {}     valid_segments = 0     unassigned_segments = 0      for i, segment in enumerate(segments):         if len(segment) &gt; 1 and segment[1] is not None:             valid_segments += 1             seg_type = segment[1].type if hasattr(segment[1], \"type\") else \"UNKNOWN\"             segment_types[seg_type] = segment_types.get(seg_type, 0) + 1         else:             unassigned_segments += 1      print(f\"\\n\ud83d\udcc8 Segment Detection Summary:\")     print(f\"   \u2022 Valid segments: {valid_segments}\")     print(f\"   \u2022 Unassigned segments: {unassigned_segments}\")     print(f\"   \u2022 Segment types detected:\")     for seg_type, count in segment_types.items():         print(f\"     - {seg_type}: {count} segments\")      # Show detailed segment information     print(f\"\\n\ud83d\udd0d Detailed Segment Information (first 10):\")     for i, segment in enumerate(segments[:10]):         if len(segment) &gt; 1 and segment[1] is not None:             seg_obj = segment[1]             seg_type = seg_obj.type if hasattr(seg_obj, \"type\") else \"UNKNOWN\"             seg_idx = seg_obj.idx if hasattr(seg_obj, \"idx\") else \"N/A\"             print(f\"   Segment {i}: ID={seg_idx}, Type={seg_type}\")         else:             print(f\"   Segment {i}: Unassigned trajectory segment\") else:     print(\"\u26a0\ufe0f  Cannot proceed without MCAP file\") In\u00a0[\u00a0]: Copied! <pre>if file.exists():\n    mapsegment.plot(\n        output_plot=None,\n        trajectory=positions,\n        plot_lane_ids=False,\n        plot_intersection_polygons=True,\n        plot_connection_polygons=False,\n    )\n</pre> if file.exists():     mapsegment.plot(         output_plot=None,         trajectory=positions,         plot_lane_ids=False,         plot_intersection_polygons=True,         plot_connection_polygons=False,     )"},{"location":"notebooks/tutorial_map/#mapsegment-capabilities-demo","title":"MapSegment Capabilities Demo\u00b6","text":"<p>This notebook demonstrates the comprehensive capabilities of the omega-prime <code>Mapsegmentation</code> class for processing autonomous vehicle data. The capabilities include:</p> <ul> <li>Map Segmentation: Analyze and segment road maps into meaningful components</li> <li>Intersection Detection: Automatically detect and classify intersections</li> <li>Trajectory Analysis: Process vehicle trajectories and map them to road segments</li> </ul> <p>The functionality is currently only available for OSI Centerline maps.</p>"},{"location":"notebooks/tutorial_map/#setup-and-imports","title":"Setup and Imports\u00b6","text":"<p>Import necessary libraries and set up the environment.</p> <p>Define paths to data files and output folders.</p>"},{"location":"notebooks/tutorial_map/#read-data-files","title":"Read Data Files\u00b6","text":"<p>Load map and trajectory data from specified files.</p> <p>When using the <code>omega_prime.Recording.from_file</code> method, you can enable advanced options such as lane splitting and polygon computation to enhance the analysis and visualization of the data.</p> <p>Lane Splitting: This feature splits long lane centerlines into shorter segments of a specified maximum length (e.g., 10 meters). It improves processing efficiency, increases granularity for detailed map analysis, and updates lane connections accordingly while removing distant connections.</p>"},{"location":"notebooks/tutorial_map/#map-segmentation-analysis","title":"Map Segmentation Analysis\u00b6","text":"<p>The identified segments can be used to further analyze intersections and connections within the map.</p>"},{"location":"notebooks/tutorial_map/#using-trajectories-with-map-segmentation","title":"Using Trajectories with Map Segmentation\u00b6","text":"<p>If trajectory data is available, it can be integrated with the map segmentation for enhanced analysis. The trajectories are mapped to the identified road segments, allowing for detailed examination of vehicle movements in relation to the road network.</p>"},{"location":"notebooks/tutorial_map/#7-visualize-map-segments-and-trajectories","title":"7. Visualize Map Segments and Trajectories\u00b6","text":"<p>Generate comprehensive visualizations using matplotlib plots and interactive Altair charts.</p> <p>The Class <code>MapSegment</code> provides methods to visualize the map segments along with vehicle trajectories. The visualizations can include lane IDs, intersection polygons, and connection polygons for detailed analysis.</p>"},{"location":"notebooks/tutorial_metrics/","title":"Metrics","text":"<p>First we need some data to compute metrics on. For this we load an omega-prime file from an osi-trace and an OpenDRIVE map.</p> In\u00a0[5]: nbval-ignore-output Copied! <pre>import omega_prime\nimport polars as pl\nimport altair as alt\nimport numpy as np\n\n\nr = omega_prime.Recording.from_file(\n    \"../../example_files/alks_cut-in.osi\", map_path=\"../../example_files/straight_500m.xodr\"\n)\nr.moving_objects\n</pre> import omega_prime import polars as pl import altair as alt import numpy as np   r = omega_prime.Recording.from_file(     \"../../example_files/alks_cut-in.osi\", map_path=\"../../example_files/straight_500m.xodr\" ) r.moving_objects Out[5]: <pre>{0: &lt;omega_prime.recording.MovingObject at 0x214601e03d0&gt;,\n 1: &lt;omega_prime.recording.MovingObject at 0x214601e0550&gt;}</pre> <p>This recording contains two objects. The data of the trajectories is stored in <code>r.df</code> in form of a polars dataframe that has a column for each timestamp, object combination.</p> In\u00a0[6]: nbval-ignore-output Copied! <pre>r.df.head()\n</pre> r.df.head() Out[6]: shape: (5, 26)total_nanosidxxyzvel_xvel_yvel_zacc_xacc_yacc_zlengthwidthheightrollpitchyawtyperolesubtypeframevelacccoordsgeometrypolygoni64i64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64i64i64i64u32f64f64array[f64, (1, 5, 2)]binaryobject0031.4-1.5350.7520.00.00.00.00.00.05.042.01.50.00.00.0204020.00.0[[[33.92, -0.535], [33.92, -2.535], \u2026 [33.92, -0.535]]]b\"\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x8f\\xc2\\xf5@@\\x1e\\x85\\xebQ\\xb8\\x1e\\xe1\\xbf\\x00\\x00\\x00\\x8f\\xc2\\xf5@@H\\xe1z\\x14\\xaeG\\x04\\xc0\\x00\\x00\\x00\\xaeG\\xe1&lt;@H\\xe1z\\x14\\xaeG\\x04\"\u2026POLYGON ((33.919999957084656 -0.5349999999999999, 33.919999957084656 -2.535, 28.87999999523163 -2.535, 28.87999999523163 -0.5349999999999999, 33.919999957084656 -0.5349999999999999))0151.451.5350010.7517.00.0000060.00.00.00.05.042.01.50.00.03.4641e-7204017.00.0[[[53.97, 2.535001], [53.97, 0.535001], \u2026 [53.97, 2.535001]]]b\"\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\xd8\\x16\\x18\\xf3(\\xfcJ@\\xc6\\x0e\\x10\\xcd\\xaeG\\x04@\\xe5\\xe8\\xe7\\xf8(\\xfcJ@N?@4\\xbb\\x1e\\xe1?\\x10\\xe9\\xe7@\\x0awH@\\x9e\\x8e\\xec\\x8a\\xb7\\x1e\\xe1\"\u2026POLYGON ((53.969999682199784 2.5350013752484726, 53.9700003750202 0.5350013752485923, 48.93000041316748 0.5349996293411612, 48.92999972034706 2.5349996293410415, 53.969999682199784 2.5350013752484726))33000000032.06-1.5350.7520.00.00.01.0766e-130.00.05.042.01.50.00.00.0204120.01.0766e-13[[[34.58, -0.535], [34.58, -2.535], \u2026 [34.58, -0.535]]]b\"\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x14\\xaeGp=JA@\\x1e\\x85\\xebQ\\xb8\\x1e\\xe1\\xbf\\x14\\xaeGp=JA@H\\xe1z\\x14\\xaeG\\x04\\xc0(\\\\x8fp=\\x8a=@H\\xe1z\\x14\\xaeG\\x04\"\u2026POLYGON ((34.57999995708465 -0.5349999999999999, 34.57999995708465 -2.535, 29.539999995231625 -2.535, 29.539999995231625 -0.5349999999999999, 34.57999995708465 -0.5349999999999999))33000000152.0111.5350010.7517.00.00.03.0790e-11-0.0001780.05.042.01.50.00.03.4641e-7204117.00.000178[[[54.531, 2.535001], [54.531, 0.535001], \u2026 [54.531, 2.535001]]]b\"\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x03\\x9e.\\xcc\\xf7CK@\\xc6\\x0e\\x10\\xcd\\xaeG\\x04@\\x10p\\xfe\\xd1\\xf7CK@N?@4\\xbb\\x1e\\xe1?;p\\xfe\\x19\\xd9\\xbeH@\\x9e\\x8e\\xec\\x8a\\xb7\\x1e\\xe1\"\u2026POLYGON ((54.530999682199784 2.5350013752484726, 54.5310003750202 0.5350013752485923, 49.49100041316748 0.5349996293411612, 49.49099972034706 2.5349996293410415, 54.530999682199784 2.5350013752484726))66000000032.72-1.5350.7520.00.00.00.00.00.05.042.01.50.00.00.0204220.00.0[[[35.24, -0.535], [35.24, -2.535], \u2026 [35.24, -0.535]]]b\"\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00)\\\\x8fQ\\xb8\\x9eA@\\x1e\\x85\\xebQ\\xb8\\x1e\\xe1\\xbf)\\\\x8fQ\\xb8\\x9eA@H\\xe1z\\x14\\xaeG\\x04\\xc0R\\xb8\\x1e333&gt;@H\\xe1z\\x14\\xaeG\\x04\"\u2026POLYGON ((35.239999957084656 -0.5349999999999999, 35.239999957084656 -2.535, 30.19999999523163 -2.535, 30.19999999523163 -0.5349999999999999, 35.239999957084656 -0.5349999999999999)) <p>If you just want to compute a single metric, you can do it any way you want just using the dataframe. Our experience has shown, that when computing a lot of different metrics or identifing scenarios (which can be seen as a special kind of metric). Often some metrics depend on other metrics or inbetween values and so on. Thats why we suggest using the <code>omega_prime.metrics.MetricManager</code> with <code>omega_prime.metrics.Metric</code>. These help you to define metrics with a single function and settings its outputs and dependencies. Then the manager handles the sorting and execution of these metrics. Key here is, that base you calculation on polars dataframes. Then the metrics manager is able to utilize polars Lazy API to derive an efficient computation of the metrics with minimal double computation.</p> In\u00a0[7]: nbval-ignore-output Copied! <pre>@omega_prime.metrics.metric(computes_properties=[\"test_property\"])\ndef compute_stuff(df, /) -&gt; tuple[pl.LazyFrame, dict[str, pl.LazyFrame]]:\n    return df, {\"test_property\": df.group_by(\"idx\").agg(pl.col(\"idx\").count().alias(\"count\"))}\n\n\ncompute_stuff\n</pre> @omega_prime.metrics.metric(computes_properties=[\"test_property\"]) def compute_stuff(df, /) -&gt; tuple[pl.LazyFrame, dict[str, pl.LazyFrame]]:     return df, {\"test_property\": df.group_by(\"idx\").agg(pl.col(\"idx\").count().alias(\"count\"))}   compute_stuff Out[7]: <pre>Metric(compute_func=&lt;function compute_stuff at 0x000002145FD1ECA0&gt;, computes_columns=[], computes_properties=['test_property'], requires_columns=[], requires_properties=[], computes_intermediate_columns=[], computes_intermediate_properties=[], _parameters=[])</pre> <p>By using the decorator you have turned the simple function into an object of class <code>omega_prime.metrics.Metric</code>. The function must always have as a first argument a dataframe (which when using the MetricsManager is the dataframe of the recording). Then there needs to be a <code>/</code> to ensure that all later parameters can only be accessed through keyword arguments. The function recieves the DataFrame as a LazyFrame. You can do you operations and add columns to the original dataframe (one column per timestep and object combination) and return that as the first value. Not all metrics fit that pattern. In these cases you should add those as a dictonary to the output where the key is an arbitrary name and the value is a polars dataframe. This was done in with the <code>test_property</code>. Make sure that your function always returns <code>df, {...}</code>. The dictonary can be empty if the metric does not create anything fitting it. We call the dictionary entries properties. To let the MetricsManager know which columns the metric is adding to the dataframe or which properties it is going to add we list them in the decorator under <code>computes_columns</code> and <code>computes_properties</code>. Likewise, if our metric function requires columns or properties of other metrics, we must also list them in the decorator. We do that under <code>requires_columns</code> and <code>requires_properties</code>. If your function requires properties of other metrics, you must name them in the function header after the <code>/</code>. Your metric can have other attributes that are also defined in the header of the function after <code>/</code>. These must not be listed in the decorator. We call those parameters. You can set defaults as usual or set no default. If so you need to specify those parameters when actually calling the computation of metrics. Before explaining the metrics manager, lets see how the metric works. By just calling the metrics object:</p> In\u00a0[8]: nbval-ignore-output Copied! <pre>compute_stuff(r.df)\n</pre> compute_stuff(r.df) Out[8]: <pre>(&lt;LazyFrame at 0x214601BFB90&gt;, {'test_property': &lt;LazyFrame at 0x214601BF210&gt;})</pre> <p>We see that it returned the required original dataframe (but automatically turned into a lazy frame) and a dictonary with lazy dataframes. Each metric does that. The <code>MetricManager</code> handles the computation of multiple metrics at ones. We create an object of the MetricManager listing all metrics we want to compute:</p> In\u00a0[9]: Copied! <pre>mm = omega_prime.metrics.MetricManager(\n    metrics=[compute_stuff],\n)\nmm\n</pre> mm = omega_prime.metrics.MetricManager(     metrics=[compute_stuff], ) mm Out[9]: <pre>computes columns: [] - computes properties ['test_property'] - parameters []</pre> <p>We can see that the manager will compute the properties <code>test_property</code> and will not add any columns to the <code>r.df</code> dataframe.</p> In\u00a0[10]: nbval-ignore-output Copied! <pre>df, metrics_dict = mm.compute(r)\nmetrics_dict\n</pre> df, metrics_dict = mm.compute(r) metrics_dict Out[10]: <pre>{'test_property': shape: (2, 2)\n \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n \u2502 idx \u2506 count \u2502\n \u2502 --- \u2506 ---   \u2502\n \u2502 i64 \u2506 u32   \u2502\n \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n \u2502 0   \u2506 305   \u2502\n \u2502 1   \u2506 305   \u2502\n \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518}</pre> <p>The function <code>.compute</code> takes an <code>omega_prime.Recording</code> (and parameters required by the metrics) and, same as the metrics itself, returns the dataframe in <code>r.df</code> and the properties dictionary. But now off course the combined result of all used metrics</p> In\u00a0[11]: nbval-ignore-output Copied! <pre>mm = omega_prime.metrics.MetricManager(\n    metrics=[\n        omega_prime.metrics.timegaps_and_min_timgaps,\n        omega_prime.metrics.vel,\n        omega_prime.metrics.distance_traveled,\n        omega_prime.metrics.p_timegaps_and_min_p_timgaps,\n    ],\n)\nmm\n</pre> mm = omega_prime.metrics.MetricManager(     metrics=[         omega_prime.metrics.timegaps_and_min_timgaps,         omega_prime.metrics.vel,         omega_prime.metrics.distance_traveled,         omega_prime.metrics.p_timegaps_and_min_p_timgaps,     ], ) mm Out[11]: <pre>computes columns: ['vel', 'distance_traveled'] - computes properties ['timegaps', 'min_timegaps', 'p_timegaps', 'min_p_timegaps'] - parameters ['time_buffer=2000000000.0', 'ego_id']</pre> <p>We can see that the <code>MetricsManager</code> will add the columns <code>['vel', 'distance_traveled']</code> to the DataFrame of the recording and return a properties dictionary with the dataframes <code>['timegaps', 'min_timegaps', 'p_timegaps', 'min_p_timegaps']</code>. For the computation of metrics, the parameters <code>time_buffer</code> and <code>ego_id</code> are requried. <code>time_buffer</code> has a default values, wheras we need to set <code>ego_id</code> for each computation. We always use <code>ego_id</code> to define the perspective of the metric we are taking. So <code>ego_id</code> is the idx of the vehicle whos perspective we are taking for the computation of the metric. If set, it is usually the <code>host_vehicle_idx</code>.</p> <p>Internally, the metrics manager derives an ordering of compuation of metrics, that fit the set dependencies. You can plot the derived ordering like:</p> In\u00a0[12]: nbval-ignore-output Copied! <pre>mm.plot_dependencies();\n</pre> mm.plot_dependencies(); <p>Blue are the metrics and green the columns or properties. An arrow from metric to column/property indicates that the metric computes them, whereas the other way around indicates that the metric is depending on those.</p> <p>To compute the metric we just call <code>compute</code> again.</p> In\u00a0[13]: Copied! <pre>df, metrics = mm.compute(r, ego_id=0, time_buffer=10e9)\nlist(metrics.keys())\n</pre> df, metrics = mm.compute(r, ego_id=0, time_buffer=10e9) list(metrics.keys()) Out[13]: <pre>['timegaps', 'min_timegaps', 'p_timegaps', 'min_p_timegaps']</pre> <p>As you can see above, the properties <code>['timegaps', 'min_timegaps', 'p_timegaps', 'min_p_timegaps']</code> were computed by the Manger. And the return DataFrame is the DataFrame from the recording with the columns <code>vel</code> and <code>distance_traveled</code> added.</p> In\u00a0[17]: nbval-ignore-output Copied! <pre>df.head()\n</pre> df.head() Out[17]: shape: (5, 27)total_nanosidxxyzvel_xvel_yvel_zacc_xacc_yacc_zlengthwidthheightrollpitchyawtyperolesubtypeframevelacccoordsgeometrypolygondistance_traveledi64i64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64i64i64i64u32f64f64array[f64, (1, 5, 2)]binaryobjectf640031.4-1.5350.7520.00.00.00.00.00.05.042.01.50.00.00.0204020.00.0[[[33.92, -0.535], [33.92, -2.535], \u2026 [33.92, -0.535]]]b\"\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x8f\\xc2\\xf5@@\\x1e\\x85\\xebQ\\xb8\\x1e\\xe1\\xbf\\x00\\x00\\x00\\x8f\\xc2\\xf5@@H\\xe1z\\x14\\xaeG\\x04\\xc0\\x00\\x00\\x00\\xaeG\\xe1&lt;@H\\xe1z\\x14\\xaeG\\x04\"\u2026POLYGON ((33.919999957084656 -0.5349999999999999, 33.919999957084656 -2.535, 28.87999999523163 -2.535, 28.87999999523163 -0.5349999999999999, 33.919999957084656 -0.5349999999999999))0.00151.451.5350010.7517.00.0000060.00.00.00.05.042.01.50.00.03.4641e-7204017.00.0[[[53.97, 2.535001], [53.97, 0.535001], \u2026 [53.97, 2.535001]]]b\"\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\xd8\\x16\\x18\\xf3(\\xfcJ@\\xc6\\x0e\\x10\\xcd\\xaeG\\x04@\\xe5\\xe8\\xe7\\xf8(\\xfcJ@N?@4\\xbb\\x1e\\xe1?\\x10\\xe9\\xe7@\\x0awH@\\x9e\\x8e\\xec\\x8a\\xb7\\x1e\\xe1\"\u2026POLYGON ((53.969999682199784 2.5350013752484726, 53.9700003750202 0.5350013752485923, 48.93000041316748 0.5349996293411612, 48.92999972034706 2.5349996293410415, 53.969999682199784 2.5350013752484726))0.033000000032.06-1.5350.7520.00.00.01.0766e-130.00.05.042.01.50.00.00.0204120.01.0766e-13[[[34.58, -0.535], [34.58, -2.535], \u2026 [34.58, -0.535]]]b\"\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x14\\xaeGp=JA@\\x1e\\x85\\xebQ\\xb8\\x1e\\xe1\\xbf\\x14\\xaeGp=JA@H\\xe1z\\x14\\xaeG\\x04\\xc0(\\\\x8fp=\\x8a=@H\\xe1z\\x14\\xaeG\\x04\"\u2026POLYGON ((34.57999995708465 -0.5349999999999999, 34.57999995708465 -2.535, 29.539999995231625 -2.535, 29.539999995231625 -0.5349999999999999, 34.57999995708465 -0.5349999999999999))0.6633000000152.0111.5350010.7517.00.00.03.0790e-11-0.0001780.05.042.01.50.00.03.4641e-7204117.00.000178[[[54.531, 2.535001], [54.531, 0.535001], \u2026 [54.531, 2.535001]]]b\"\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x03\\x9e.\\xcc\\xf7CK@\\xc6\\x0e\\x10\\xcd\\xaeG\\x04@\\x10p\\xfe\\xd1\\xf7CK@N?@4\\xbb\\x1e\\xe1?;p\\xfe\\x19\\xd9\\xbeH@\\x9e\\x8e\\xec\\x8a\\xb7\\x1e\\xe1\"\u2026POLYGON ((54.530999682199784 2.5350013752484726, 54.5310003750202 0.5350013752485923, 49.49100041316748 0.5349996293411612, 49.49099972034706 2.5349996293410415, 54.530999682199784 2.5350013752484726))1.22166000000032.72-1.5350.7520.00.00.00.00.00.05.042.01.50.00.00.0204220.00.0[[[35.24, -0.535], [35.24, -2.535], \u2026 [35.24, -0.535]]]b\"\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00)\\\\x8fQ\\xb8\\x9eA@\\x1e\\x85\\xebQ\\xb8\\x1e\\xe1\\xbf)\\\\x8fQ\\xb8\\x9eA@H\\xe1z\\x14\\xaeG\\x04\\xc0R\\xb8\\x1e333&gt;@H\\xe1z\\x14\\xaeG\\x04\"\u2026POLYGON ((35.239999957084656 -0.5349999999999999, 35.239999957084656 -2.535, 30.19999999523163 -2.535, 30.19999999523163 -0.5349999999999999, 35.239999957084656 -0.5349999999999999))1.881 <p>The following plots show the computed timegaps and predictated timegaps for the recording.</p> In\u00a0[15]: nbval-ignore-output Copied! <pre>(\n    alt.Chart(metrics[\"p_timegaps\"]).mark_line().encode(alt.X(\"total_nanos_ego:Q\"), alt.Y(\"p_timegap\"), color=\"idx:N\")\n    + alt.Chart(metrics[\"timegaps\"])\n    .mark_line(strokeDash=[10, 2])\n    .encode(alt.X(\"total_nanos_ego:Q\"), alt.Y(\"timegap\"), color=\"idx:N\")\n    + alt.Chart(metrics[\"min_timegaps\"])\n    .mark_rule(strokeDash=[1, 1])\n    .encode(\n        alt.Y(\"min_timegap\"),\n        color=\"idx:N\",\n    )\n    .properties(title=\"timegap\")\n).interactive()\n</pre> (     alt.Chart(metrics[\"p_timegaps\"]).mark_line().encode(alt.X(\"total_nanos_ego:Q\"), alt.Y(\"p_timegap\"), color=\"idx:N\")     + alt.Chart(metrics[\"timegaps\"])     .mark_line(strokeDash=[10, 2])     .encode(alt.X(\"total_nanos_ego:Q\"), alt.Y(\"timegap\"), color=\"idx:N\")     + alt.Chart(metrics[\"min_timegaps\"])     .mark_rule(strokeDash=[1, 1])     .encode(         alt.Y(\"min_timegap\"),         color=\"idx:N\",     )     .properties(title=\"timegap\") ).interactive() Out[15]: In\u00a0[16]: nbval-ignore-output Copied! <pre>max_nanos = np.max(metrics[\"p_timegaps\"].select(pl.max(\"total_nanos_ego\", \"total_nanos\")).to_numpy())\nmin_nanos = np.min(metrics[\"p_timegaps\"].select(pl.min(\"total_nanos_ego\", \"total_nanos\")).to_numpy())\n\n(\n    alt.Chart(metrics[\"timegaps\"].select(pl.col(\"total_nanos_ego\", \"total_nanos\", \"idx\")))\n    .mark_line(strokeDash=[1, 1])\n    .encode(alt.X(\"total_nanos_ego:Q\"), alt.Y(\"total_nanos:Q\"), color=\"idx:N\")\n    + alt.Chart()\n    .mark_rule(color=\"red\")\n    .encode(x=alt.datum(min_nanos), x2=alt.datum(max_nanos), y2=alt.datum(max_nanos), y=alt.datum(min_nanos))\n    + (\n        alt.Chart(metrics[\"p_timegaps\"].select(pl.col(\"total_nanos_ego\", \"total_nanos\", \"idx\")))\n        .mark_line()\n        .encode(alt.X(\"total_nanos_ego:Q\"), alt.Y(\"total_nanos:Q\"), color=\"idx:N\")\n    )\n).properties(title=\"time of smallest timegap\").interactive()\n</pre> max_nanos = np.max(metrics[\"p_timegaps\"].select(pl.max(\"total_nanos_ego\", \"total_nanos\")).to_numpy()) min_nanos = np.min(metrics[\"p_timegaps\"].select(pl.min(\"total_nanos_ego\", \"total_nanos\")).to_numpy())  (     alt.Chart(metrics[\"timegaps\"].select(pl.col(\"total_nanos_ego\", \"total_nanos\", \"idx\")))     .mark_line(strokeDash=[1, 1])     .encode(alt.X(\"total_nanos_ego:Q\"), alt.Y(\"total_nanos:Q\"), color=\"idx:N\")     + alt.Chart()     .mark_rule(color=\"red\")     .encode(x=alt.datum(min_nanos), x2=alt.datum(max_nanos), y2=alt.datum(max_nanos), y=alt.datum(min_nanos))     + (         alt.Chart(metrics[\"p_timegaps\"].select(pl.col(\"total_nanos_ego\", \"total_nanos\", \"idx\")))         .mark_line()         .encode(alt.X(\"total_nanos_ego:Q\"), alt.Y(\"total_nanos:Q\"), color=\"idx:N\")     ) ).properties(title=\"time of smallest timegap\").interactive() Out[16]:"},{"location":"notebooks/tutorial_metrics/#load-data-and-introduction","title":"Load Data and Introduction\u00b6","text":""},{"location":"notebooks/tutorial_metrics/#create-a-metric","title":"Create a metric\u00b6","text":"<p>You can create a metric by defining a function like the following and decorating it with the <code>@omega_prime.metrics.metric()</code> decorator. create a function that takes the dataframe from a Recording (<code>Recording._df</code>) and returns the same dataframe and a dictonary with additional dataframes (dictionary needs to be always return but can be empty if necessary). Decorate it with <code>@omega_prime.metrics.metric()</code> and add it to your <code>MetricManager</code></p>"},{"location":"notebooks/tutorial_metrics/#metricmanager-with-multiple-metrics","title":"MetricManager with multiple metrics\u00b6","text":"<p>The usefullness of the MetricsManager comes into play, when we use multiple metrics. Omega-prime has already some metrics defined. Lets create a MetricsManager using those:</p>"},{"location":"notebooks/tutorial_projections/","title":"Tutorial projections","text":"<p>Load an example file and show the x and y coordinate values.</p> In\u00a0[1]: Copied! <pre>import omega_prime\n\nr = omega_prime.Recording.from_file(\n    \"../../example_files/alks_cut-in.osi\", map_path=\"../../example_files/straight_500m.xodr\"\n)\ndf = r._df\nprint(df.select([\"total_nanos\", \"idx\", \"x\", \"y\"]).head())\n</pre> import omega_prime  r = omega_prime.Recording.from_file(     \"../../example_files/alks_cut-in.osi\", map_path=\"../../example_files/straight_500m.xodr\" ) df = r._df print(df.select([\"total_nanos\", \"idx\", \"x\", \"y\"]).head())  <pre>shape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 total_nanos \u2506 idx \u2506 x      \u2506 y        \u2502\n\u2502 ---         \u2506 --- \u2506 ---    \u2506 ---      \u2502\n\u2502 i64         \u2506 i64 \u2506 f64    \u2506 f64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0           \u2506 0   \u2506 31.4   \u2506 -1.535   \u2502\n\u2502 0           \u2506 1   \u2506 51.45  \u2506 1.535001 \u2502\n\u2502 33000000    \u2506 0   \u2506 32.06  \u2506 -1.535   \u2502\n\u2502 33000000    \u2506 1   \u2506 52.011 \u2506 1.535001 \u2502\n\u2502 66000000    \u2506 0   \u2506 32.72  \u2506 -1.535   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>Create a constant offset for all timestamps by using <code>key</code>=<code>None</code>.</p> <p>When applying the projections, the values <code>x</code>, <code>y</code>, <code>z</code>, and <code>yaw</code> are overridden to ensure that all plots, etc., use the projected values. The original values are stored under <code>x_original</code>, <code>y_original</code>, <code>z_original</code>, and <code>yaw_original</code>.</p> In\u00a0[2]: Copied! <pre>from omega_prime.map import ProjectionOffset\n\nproj = {\n    None: ProjectionOffset(x=5, y=0, z=0, yaw=0),\n}\n\nr.projections = proj\n\nr.apply_projections()\ndf = r._df\nprint(df.select([\"total_nanos\", \"idx\", \"x\", \"y\", \"x_original\", \"y_original\"]).head())\n</pre> from omega_prime.map import ProjectionOffset  proj = {     None: ProjectionOffset(x=5, y=0, z=0, yaw=0), }  r.projections = proj  r.apply_projections() df = r._df print(df.select([\"total_nanos\", \"idx\", \"x\", \"y\", \"x_original\", \"y_original\"]).head()) <pre>shape: (5, 6)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 total_nanos \u2506 idx \u2506 x      \u2506 y        \u2506 x_original \u2506 y_original \u2502\n\u2502 ---         \u2506 --- \u2506 ---    \u2506 ---      \u2506 ---        \u2506 ---        \u2502\n\u2502 i64         \u2506 i64 \u2506 f64    \u2506 f64      \u2506 f64        \u2506 f64        \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0           \u2506 0   \u2506 36.4   \u2506 -1.535   \u2506 31.4       \u2506 -1.535     \u2502\n\u2502 0           \u2506 1   \u2506 56.45  \u2506 1.535001 \u2506 51.45      \u2506 1.535001   \u2502\n\u2502 33000000    \u2506 0   \u2506 37.06  \u2506 -1.535   \u2506 32.06      \u2506 -1.535     \u2502\n\u2502 33000000    \u2506 1   \u2506 57.011 \u2506 1.535001 \u2506 52.011     \u2506 1.535001   \u2502\n\u2502 66000000    \u2506 0   \u2506 37.72  \u2506 -1.535   \u2506 32.72      \u2506 -1.535     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>When the recording is saved, the original poses are stored. The projections are temporary.</p> In\u00a0[3]: Copied! <pre>r.to_file(\"transformation.mcap\")\n\nt = omega_prime.Recording.from_file(\"transformation.mcap\")\nprint(t._df.select([\"total_nanos\", \"idx\", \"x\", \"y\"]).head())\n</pre> r.to_file(\"transformation.mcap\")  t = omega_prime.Recording.from_file(\"transformation.mcap\") print(t._df.select([\"total_nanos\", \"idx\", \"x\", \"y\"]).head()) <pre>shape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 total_nanos \u2506 idx \u2506 x      \u2506 y        \u2502\n\u2502 ---         \u2506 --- \u2506 ---    \u2506 ---      \u2502\n\u2502 i64         \u2506 i64 \u2506 f64    \u2506 f64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0           \u2506 0   \u2506 31.4   \u2506 -1.535   \u2502\n\u2502 0           \u2506 1   \u2506 51.45  \u2506 1.535001 \u2502\n\u2502 33000000    \u2506 0   \u2506 32.06  \u2506 -1.535   \u2502\n\u2502 33000000    \u2506 1   \u2506 52.011 \u2506 1.535001 \u2502\n\u2502 66000000    \u2506 0   \u2506 32.72  \u2506 -1.535   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre>"},{"location":"notebooks/tutorial_projections/#omega-prime-tutorial-for-using-the-projection-functionality","title":"omega-prime: Tutorial for using the projection functionality\u00b6","text":""}]}